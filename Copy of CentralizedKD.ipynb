{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMGka+t2ehmbl1DkR60utT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbZcy3k5SnKL","executionInfo":{"status":"ok","timestamp":1676605654260,"user_tz":300,"elapsed":324976,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"4f47d8a8-e9cb-411c-d7c6-f21677fe94f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.4.0\n","  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.2/170.2 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras==2.4.0) (1.7.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras==2.4.0) (1.21.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras==2.4.0) (6.0)\n","Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from keras==2.4.0) (2.11.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras==2.4.0) (3.1.0)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.11.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.14.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.30.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (23.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (4.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.11.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.51.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (57.4.0)\n","Collecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (15.0.6.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.19.6)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (23.1.21)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.10,>=2.9\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.4-cp38-cp38-manylinux2010_x86_64.whl (498.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.9,>=2.8\n","  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.9,>=2.8\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.8.3-cp38-cp38-manylinux2010_x86_64.whl (498.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.4/498.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.2-cp38-cp38-manylinux2010_x86_64.whl (498.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.1-cp38-cp38-manylinux2010_x86_64.whl (498.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.7.4-cp38-cp38-manylinux2010_x86_64.whl (496.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.0/496.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.38.4)\n","Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n","  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.7.3-cp38-cp38-manylinux2010_x86_64.whl (495.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.5/495.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.2-cp38-cp38-manylinux2010_x86_64.whl (495.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.5/495.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.1-cp38-cp38-manylinux2010_x86_64.whl (495.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.1/495.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.6/489.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.5-cp38-cp38-manylinux2010_x86_64.whl (464.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.3/464.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.7,>=2.6.0\n","  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.7,>=2.6.0\n","  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.9/462.9 KB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.6.4-cp38-cp38-manylinux2010_x86_64.whl (464.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.3/464.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.3-cp38-cp38-manylinux2010_x86_64.whl (463.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.9/463.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.2-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.6.1-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading tensorflow-2.5.3-cp38-cp38-manylinux2010_x86_64.whl (460.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.4/460.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio~=1.34.0\n","  Downloading grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting numpy>=1.9.1\n","  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting termcolor~=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.25.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.16.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (6.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (2022.12.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.12.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.2.0->keras==2.4.0) (3.2.2)\n","Building wheels for collected packages: termcolor, wrapt\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=7eaf21029b82197d54da85b2dd233cd540c9a933cdd08bc0f1d808657c69019d\n","  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78577 sha256=1dda3daa80d73d89b8dedd1a0173ca8572cc968b780d473eb62988e39ed59416\n","  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n","Successfully built termcolor wrapt\n","Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, keras-nightly, flatbuffers, numpy, grpcio, absl-py, keras-preprocessing, tensorflow, keras\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.4.0\n","    Uninstalling typing_extensions-4.4.0:\n","      Successfully uninstalled typing_extensions-4.4.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.2.0\n","    Uninstalling termcolor-2.2.0:\n","      Successfully uninstalled termcolor-2.2.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.11.0\n","    Uninstalling tensorflow-estimator-2.11.0:\n","      Successfully uninstalled tensorflow-estimator-2.11.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.1.21\n","    Uninstalling flatbuffers-23.1.21:\n","      Successfully uninstalled flatbuffers-23.1.21\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.51.1\n","    Uninstalling grpcio-1.51.1:\n","      Successfully uninstalled grpcio-1.51.1\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.4.0\n","    Uninstalling absl-py-1.4.0:\n","      Successfully uninstalled absl-py-1.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.11.0\n","    Uninstalling tensorflow-2.11.0:\n","      Successfully uninstalled tensorflow-2.11.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.11.0\n","    Uninstalling keras-2.11.0:\n","      Successfully uninstalled keras-2.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","pydantic 1.10.4 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n","jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n","google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 grpcio-1.34.1 keras-2.4.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 numpy-1.19.5 tensorflow-2.5.3 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"]}],"source":["pip install keras==2.4.0"]},{"cell_type":"code","source":["pip install mia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfJa2lN6TLeG","executionInfo":{"status":"ok","timestamp":1676600321276,"user_tz":300,"elapsed":9716,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"7419b59c-a85c-43ce-9d8b-7cf69f34c643"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mia\n","  Downloading mia-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mia) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mia) (1.7.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from mia) (1.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from mia) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mia) (4.64.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->mia) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->mia) (3.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->mia) (3.7.4.3)\n","Building wheels for collected packages: mia\n","  Building wheel for mia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mia: filename=mia-0.1.2-py3-none-any.whl size=11106 sha256=ee573b249b8c4f977680a3bb4d048e3a0f8b8d54c3e7bbf7a81b4f8bd76f167e\n","  Stored in directory: /root/.cache/pip/wheels/c7/fb/77/a632189442690e610b8fad3eea1887996438e0ffc3cdadc039\n","Successfully built mia\n","Installing collected packages: mia\n","Successfully installed mia-0.1.2\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import random\n","import datetime\n","#import tensorflow_privacy\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from tensorflow import keras"],"metadata":{"id":"HJKdTaFGTIEm","executionInfo":{"status":"ok","timestamp":1676604613196,"user_tz":300,"elapsed":281,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["def load_mnist():\n","  \"\"\"Loads MNIST and preprocesses to combine training and validation data.\"\"\"\n","  train, test = tf.keras.datasets.mnist.load_data()\n","  #train, test = tf.keras.datasets.fashion_mnist.load_data()\n","  #train, test = tf.keras.datasets.cifar10.load_data()\n","  train_data, train_labels = train\n","  test_data, test_labels = test\n","\n","  train_data = np.array(train_data, dtype=np.float32) / 255\n","  test_data = np.array(test_data, dtype=np.float32) / 255\n","\n","  train_data = train_data.reshape((train_data.shape[0], 28, 28, 1))\n","  test_data = test_data.reshape((test_data.shape[0], 28, 28, 1))\n","  #train_data = train_data.reshape((train_data.shape[0], 32, 32, 3))\n","  #test_data = test_data.reshape((test_data.shape[0], 32, 32, 3))\n","\n","  train_labels = np.array(train_labels, dtype=np.int32)\n","  test_labels = np.array(test_labels, dtype=np.int32)\n","\n","  #train_labels = np.array(train_labels, dtype=np.int64)\n","  #test_labels = np.array(test_labels, dtype=np.int64)\n","\n","  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n","  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n","\n","  #assert train_data.min() == 0.\n","  #assert train_data.max() == 1.\n","  #assert test_data.min() == 0.\n","  #assert test_data.max() == 1.\n","\n","  return train_data, train_labels, test_data, test_labels"],"metadata":{"id":"3QhVW1NHTWUj","executionInfo":{"status":"ok","timestamp":1676604615080,"user_tz":300,"elapsed":295,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["train_data, train_labels, test_data, test_labels = load_mnist()"],"metadata":{"id":"Ikl8SMpdTZUi","executionInfo":{"status":"ok","timestamp":1676604619427,"user_tz":300,"elapsed":1035,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["cifar_train = train_data, train_labels\n","cifar_test = test_data, test_labels"],"metadata":{"id":"ZyGRFXFITeNB","executionInfo":{"status":"ok","timestamp":1676604621111,"user_tz":300,"elapsed":6,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["CLIENTS = 3\n","SIZE = 10000\n","\n","def get_data(source):   \n","    \n","    all_data = (np.array(source[0][:SIZE*CLIENTS]), source[1][:SIZE*CLIENTS]) \n","    \n","    split_data = []\n","    for s in range(CLIENTS):\n","        start = s*SIZE\n","        end = s*SIZE + SIZE\n","        split_data.append((all_data[0][start:end], all_data[1][start:end]))\n","    \n","    external_data = (np.array(source[0][SIZE*CLIENTS:]), source[1][SIZE*CLIENTS:]) \n","    \n","    return all_data, split_data, external_data"],"metadata":{"id":"LMGF0SKoThFF","executionInfo":{"status":"ok","timestamp":1676604622675,"user_tz":300,"elapsed":484,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["CLIENTS = 3\n","SIZE = 1000\n","\n","def get_test_data(source):   \n","    \n","    all_data = (np.array(source[0][:SIZE*CLIENTS]), source[1][:SIZE*CLIENTS]) \n","    \n","    split_data = []\n","    for s in range(CLIENTS):\n","        start = s*SIZE\n","        end = s*SIZE + SIZE\n","        split_data.append((all_data[0][start:end], all_data[1][start:end]))\n","    \n","    external_data = (np.array(source[0][SIZE*CLIENTS:]), source[1][SIZE*CLIENTS:]) \n","    \n","    return all_data, split_data, external_data"],"metadata":{"id":"djQtTiFSTjW-","executionInfo":{"status":"ok","timestamp":1676604625509,"user_tz":300,"elapsed":284,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["cifar_train_data, cifar_train_fed_data, attacker_data = get_data(cifar_train)"],"metadata":{"id":"ID6r68WyTl2B","executionInfo":{"status":"ok","timestamp":1676604628772,"user_tz":300,"elapsed":839,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["cifar_test_data, cifar_test_fed_data, externat_test_data = get_test_data(cifar_test)"],"metadata":{"id":"2K72iAIfTop3","executionInfo":{"status":"ok","timestamp":1676604630053,"user_tz":300,"elapsed":8,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["def create_compiled_keras_model():\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape=[28, 28, 1]),\n","        tf.keras.layers.Dense(300, activation=\"relu\"),\n","        tf.keras.layers.Dense(100, activation=\"relu\"),\n","        tf.keras.layers.Dense(10, activation=\"softmax\")\n","    ])\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","    model.compile(loss=loss,\n","              optimizer = tf.keras.optimizers.SGD(learning_rate=0.01),\n","              metrics=[\"accuracy\"])\n","    return model"],"metadata":{"id":"DnUsOG3Ei3k-","executionInfo":{"status":"ok","timestamp":1676604631895,"user_tz":300,"elapsed":383,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["teacher_model = create_compiled_keras_model()"],"metadata":{"id":"L4i6inN5utfK","executionInfo":{"status":"ok","timestamp":1676604634366,"user_tz":300,"elapsed":406,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["student_model = create_compiled_keras_model()"],"metadata":{"id":"jOy8IjWGVXCl","executionInfo":{"status":"ok","timestamp":1676604638055,"user_tz":300,"elapsed":336,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["class Distiller(keras.Model):\n","    def __init__(self, student, teacher):\n","        super().__init__()\n","        self.teacher = teacher\n","        self.student = student\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super().compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            # Forward pass of student\n","            student_predictions = self.student(x, training=True)\n","\n","            # Compute losses\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","\n","            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n","            # The magnitudes of the gradients produced by the soft targets scale\n","            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n","            distillation_loss = (\n","                self.distillation_loss_fn(\n","                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n","                )\n","                * self.temperature**2\n","            )\n","\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n","\n","        # Compute gradients\n","        trainable_vars = self.student.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # Update the metrics configured in `compile()`.\n","        self.compiled_metrics.update_state(y, student_predictions)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update(\n","            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n","        )\n","        return results\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction = self.student(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss = self.student_loss_fn(y, y_prediction)\n","\n","        # Update the metrics.\n","        self.compiled_metrics.update_state(y, y_prediction)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update({\"student_loss\": student_loss})\n","        return results"],"metadata":{"id":"LiocM3jmXFFC","executionInfo":{"status":"ok","timestamp":1676604640621,"user_tz":300,"elapsed":419,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["# Train teacher as usual\n","history_callback = teacher_model.fit(cifar_train_data[0], cifar_train_data[1], validation_data=cifar_test_data, batch_size=32, epochs=12, verbose=1)\n","\n","# Train and evaluate teacher on data.\n","teacher_model.evaluate(cifar_test_data[0], cifar_test_data[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UhsPcJ-R1NM","executionInfo":{"status":"ok","timestamp":1676604656870,"user_tz":300,"elapsed":11059,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"64827dad-d24f-420c-85fd-ba6e3dbca435"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","94/94 [==============================] - 2s 12ms/step - loss: 2.0129 - accuracy: 0.4077 - val_loss: 1.7662 - val_accuracy: 0.5967\n","Epoch 2/12\n","94/94 [==============================] - 1s 10ms/step - loss: 1.3228 - accuracy: 0.7420 - val_loss: 1.2296 - val_accuracy: 0.7080\n","Epoch 3/12\n","94/94 [==============================] - 1s 6ms/step - loss: 0.8862 - accuracy: 0.8097 - val_loss: 0.9488 - val_accuracy: 0.7560\n","Epoch 4/12\n","94/94 [==============================] - 1s 5ms/step - loss: 0.6759 - accuracy: 0.8477 - val_loss: 0.8034 - val_accuracy: 0.7863\n","Epoch 5/12\n","94/94 [==============================] - 1s 7ms/step - loss: 0.5609 - accuracy: 0.8667 - val_loss: 0.7105 - val_accuracy: 0.7967\n","Epoch 6/12\n","94/94 [==============================] - 1s 7ms/step - loss: 0.4876 - accuracy: 0.8797 - val_loss: 0.6422 - val_accuracy: 0.8187\n","Epoch 7/12\n","94/94 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.8893 - val_loss: 0.6023 - val_accuracy: 0.8320\n","Epoch 8/12\n","94/94 [==============================] - 1s 7ms/step - loss: 0.3991 - accuracy: 0.9017 - val_loss: 0.5704 - val_accuracy: 0.8383\n","Epoch 9/12\n","94/94 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.9057 - val_loss: 0.5483 - val_accuracy: 0.8393\n","Epoch 10/12\n","94/94 [==============================] - 1s 7ms/step - loss: 0.3473 - accuracy: 0.9103 - val_loss: 0.5275 - val_accuracy: 0.8477\n","Epoch 11/12\n","94/94 [==============================] - 1s 7ms/step - loss: 0.3268 - accuracy: 0.9187 - val_loss: 0.5062 - val_accuracy: 0.8477\n","Epoch 12/12\n","94/94 [==============================] - 0s 5ms/step - loss: 0.3089 - accuracy: 0.9193 - val_loss: 0.4913 - val_accuracy: 0.8533\n","94/94 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8533\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.4912639260292053, 0.8533333539962769]"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["# Initialize and compile distiller\n","distiller = Distiller(student=student_model, teacher=teacher_model)\n","distiller.compile(\n","    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n","    metrics=[\"accuracy\"],\n","    student_loss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","callback=distiller.fit(cifar_train_data[0], cifar_train_data[1], validation_data=cifar_test_data, batch_size=32, epochs=12, verbose=1)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(cifar_test_data[0], cifar_test_data[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyAhzjOIT2mW","executionInfo":{"status":"ok","timestamp":1676604678219,"user_tz":300,"elapsed":11962,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"f91eb8e0-aebc-4940-c685-e2043d3c970f"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","94/94 [==============================] - 1s 8ms/step - accuracy: 0.1280 - student_loss: 2.2957 - distillation_loss: 0.0351 - val_accuracy: 0.1613 - val_student_loss: 2.2886\n","Epoch 2/12\n","94/94 [==============================] - 1s 6ms/step - accuracy: 0.2257 - student_loss: 2.2075 - distillation_loss: 0.0341 - val_accuracy: 0.2540 - val_student_loss: 2.2131\n","Epoch 3/12\n","94/94 [==============================] - 1s 7ms/step - accuracy: 0.3453 - student_loss: 2.1268 - distillation_loss: 0.0332 - val_accuracy: 0.3440 - val_student_loss: 2.1426\n","Epoch 4/12\n","94/94 [==============================] - 1s 6ms/step - accuracy: 0.4430 - student_loss: 2.0504 - distillation_loss: 0.0322 - val_accuracy: 0.4270 - val_student_loss: 2.0730\n","Epoch 5/12\n","94/94 [==============================] - 1s 8ms/step - accuracy: 0.5173 - student_loss: 1.9723 - distillation_loss: 0.0311 - val_accuracy: 0.4847 - val_student_loss: 2.0038\n","Epoch 6/12\n","94/94 [==============================] - 1s 6ms/step - accuracy: 0.5677 - student_loss: 1.8948 - distillation_loss: 0.0299 - val_accuracy: 0.5283 - val_student_loss: 1.9304\n","Epoch 7/12\n","94/94 [==============================] - 1s 6ms/step - accuracy: 0.6047 - student_loss: 1.8168 - distillation_loss: 0.0286 - val_accuracy: 0.5590 - val_student_loss: 1.8553\n","Epoch 8/12\n","94/94 [==============================] - 1s 6ms/step - accuracy: 0.6390 - student_loss: 1.7327 - distillation_loss: 0.0272 - val_accuracy: 0.5840 - val_student_loss: 1.7795\n","Epoch 9/12\n","94/94 [==============================] - 1s 6ms/step - accuracy: 0.6667 - student_loss: 1.6525 - distillation_loss: 0.0256 - val_accuracy: 0.6067 - val_student_loss: 1.7034\n","Epoch 10/12\n","94/94 [==============================] - 1s 8ms/step - accuracy: 0.6997 - student_loss: 1.5707 - distillation_loss: 0.0241 - val_accuracy: 0.6263 - val_student_loss: 1.6303\n","Epoch 11/12\n","94/94 [==============================] - 1s 11ms/step - accuracy: 0.7183 - student_loss: 1.4911 - distillation_loss: 0.0225 - val_accuracy: 0.6480 - val_student_loss: 1.5538\n","Epoch 12/12\n","94/94 [==============================] - 1s 11ms/step - accuracy: 0.7407 - student_loss: 1.4112 - distillation_loss: 0.0210 - val_accuracy: 0.6633 - val_student_loss: 1.4775\n","94/94 [==============================] - 0s 3ms/step - accuracy: 0.6633 - student_loss: 1.5220\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6633333563804626, 1.4774904251098633]"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["np.mean(callback.history['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eX2Ad01wM646","executionInfo":{"status":"ok","timestamp":1676604691701,"user_tz":300,"elapsed":501,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"8c95443c-791d-4710-c1bf-da70511959de"},"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5246666657427946"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","source":["**Membership Inference Attack**"],"metadata":{"id":"S0HNte6tB0n8"}},{"cell_type":"code","source":["import numpy as np\n","\n","from absl import app\n","from absl import flags\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from mia.estimators import ShadowModelBundle, AttackModelBundle, prepare_attack_data"],"metadata":{"id":"BLr06eg5B6Iu","executionInfo":{"status":"ok","timestamp":1676604694618,"user_tz":300,"elapsed":295,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["NUM_CLASSES = 10\n","\n","SHADOW_DATASET_SIZE = 1000\n","ATTACK_TEST_DATASET_SIZE = 5000\n","\n","num_shadows = 10\n","#num_shadows = 1\n"],"metadata":{"id":"qCuz1sy5B92l","executionInfo":{"status":"ok","timestamp":1676604696766,"user_tz":300,"elapsed":459,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["def target_model_fn():\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape=[28, 28, 1]),\n","        tf.keras.layers.Dense(300, activation=\"relu\"),\n","        tf.keras.layers.Dense(100, activation=\"relu\"),\n","        tf.keras.layers.Dense(10, activation=\"softmax\")\n","    ])\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","    model.compile(loss=loss,\n","              optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01),\n","              metrics=[\"accuracy\"])\n","    return model"],"metadata":{"id":"CQIbzsh-CABC","executionInfo":{"status":"ok","timestamp":1676604717467,"user_tz":300,"elapsed":278,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["def attack_model_fn():\n","    model = tf.keras.models.Sequential()\n","\n","    model.add(layers.Dense(64, activation=\"relu\", input_shape=(10,)))\n","    model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n","    model.add(layers.Dense(32, activation=\"relu\"))\n","    model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n","    model.add(layers.Dense(32, activation=\"relu\"))\n","    model.add(layers.Dense(1, activation=\"sigmoid\"))\n","    model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","    return model"],"metadata":{"id":"DXTQv6EKCIAo","executionInfo":{"status":"ok","timestamp":1676604722483,"user_tz":300,"elapsed":274,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["target_model = student_model"],"metadata":{"id":"O9kqSXn3CN1F","executionInfo":{"status":"ok","timestamp":1676604724406,"user_tz":300,"elapsed":286,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["# Train the shadow models.\n","smb = ShadowModelBundle(\n","    target_model_fn,\n","    shadow_dataset_size=SHADOW_DATASET_SIZE,\n","    num_models=num_shadows\n",")\n","\n","# Using cifar10 test set to train shadow models\n","attacker_X_train, attacker_X_test, attacker_y_train, attacker_y_test = train_test_split(\n","    cifar_test[0], cifar_test[1], test_size=0.5)\n","\n","print(attacker_X_train.shape, attacker_X_test.shape)\n","\n","print(\"Training the shadow models...\")\n","X_shadow, y_shadow = smb.fit_transform(\n","    attacker_X_train,\n","    attacker_y_train,\n","    fit_kwargs=dict(\n","        epochs=32,\n","        verbose=True,\n","        validation_data=(attacker_X_test, attacker_y_test)\n","    )\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"513UB7iCCR9f","executionInfo":{"status":"ok","timestamp":1676604962916,"user_tz":300,"elapsed":236614,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"0daee926-5aa1-45fb-dd8e-0d95ee294f80"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["(5000, 28, 28, 1) (5000, 28, 28, 1)\n","Training the shadow models...\n","Epoch 1/32\n","32/32 [==============================] - 2s 34ms/step - loss: 2.0122 - accuracy: 0.5300 - val_loss: 0.5078 - val_accuracy: 0.8456\n","Epoch 2/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.5070 - accuracy: 0.8340 - val_loss: 0.5238 - val_accuracy: 0.8372\n","Epoch 3/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.4048 - accuracy: 0.8730 - val_loss: 0.7171 - val_accuracy: 0.8042\n","Epoch 4/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.2864 - accuracy: 0.9160 - val_loss: 0.5321 - val_accuracy: 0.8714\n","Epoch 5/32\n","32/32 [==============================] - 1s 19ms/step - loss: 0.2100 - accuracy: 0.9380 - val_loss: 0.5803 - val_accuracy: 0.8796\n","Epoch 6/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.1781 - accuracy: 0.9520 - val_loss: 0.6847 - val_accuracy: 0.8696\n","Epoch 7/32\n","32/32 [==============================] - 1s 27ms/step - loss: 0.0935 - accuracy: 0.9700 - val_loss: 1.0612 - val_accuracy: 0.8472\n","Epoch 8/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.1359 - accuracy: 0.9700 - val_loss: 1.4118 - val_accuracy: 0.8096\n","Epoch 9/32\n","32/32 [==============================] - 1s 28ms/step - loss: 0.1129 - accuracy: 0.9690 - val_loss: 0.6010 - val_accuracy: 0.9040\n","Epoch 10/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0887 - accuracy: 0.9860 - val_loss: 1.0827 - val_accuracy: 0.8682\n","Epoch 11/32\n","32/32 [==============================] - 1s 33ms/step - loss: 0.1561 - accuracy: 0.9750 - val_loss: 0.9914 - val_accuracy: 0.8820\n","Epoch 12/32\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0618 - accuracy: 0.9850 - val_loss: 0.6341 - val_accuracy: 0.9122\n","Epoch 13/32\n","32/32 [==============================] - 2s 55ms/step - loss: 0.1601 - accuracy: 0.9780 - val_loss: 1.1058 - val_accuracy: 0.8838\n","Epoch 14/32\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0139 - accuracy: 0.9940 - val_loss: 0.9882 - val_accuracy: 0.8972\n","Epoch 15/32\n","32/32 [==============================] - 1s 34ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 2.3297 - val_accuracy: 0.8134\n","Epoch 16/32\n","32/32 [==============================] - 1s 34ms/step - loss: 0.2909 - accuracy: 0.9730 - val_loss: 1.6893 - val_accuracy: 0.8552\n","Epoch 17/32\n","32/32 [==============================] - 1s 34ms/step - loss: 0.0197 - accuracy: 0.9970 - val_loss: 1.1888 - val_accuracy: 0.8966\n","Epoch 18/32\n","32/32 [==============================] - 1s 33ms/step - loss: 0.0048 - accuracy: 0.9970 - val_loss: 1.0850 - val_accuracy: 0.9006\n","Epoch 19/32\n","32/32 [==============================] - 1s 19ms/step - loss: 0.1882 - accuracy: 0.9790 - val_loss: 1.0365 - val_accuracy: 0.9092\n","Epoch 20/32\n","32/32 [==============================] - 1s 21ms/step - loss: 0.0465 - accuracy: 0.9920 - val_loss: 1.0280 - val_accuracy: 0.8978\n","Epoch 21/32\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0896 - accuracy: 0.9840 - val_loss: 1.3312 - val_accuracy: 0.8844\n","Epoch 22/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1326 - accuracy: 0.9800 - val_loss: 1.3437 - val_accuracy: 0.8938\n","Epoch 23/32\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0612 - accuracy: 0.9890 - val_loss: 1.8487 - val_accuracy: 0.8686\n","Epoch 24/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0916 - accuracy: 0.9850 - val_loss: 1.7804 - val_accuracy: 0.8604\n","Epoch 25/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0653 - accuracy: 0.9890 - val_loss: 1.7434 - val_accuracy: 0.8878\n","Epoch 26/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0845 - accuracy: 0.9880 - val_loss: 1.7137 - val_accuracy: 0.8768\n","Epoch 27/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 1.4106 - val_accuracy: 0.8958\n","Epoch 28/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 1.5857 - val_accuracy: 0.8992\n","Epoch 29/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0523 - accuracy: 0.9880 - val_loss: 1.8210 - val_accuracy: 0.8890\n","Epoch 30/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0995 - accuracy: 0.9910 - val_loss: 1.9979 - val_accuracy: 0.8834\n","Epoch 31/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.9940 - val_loss: 1.4681 - val_accuracy: 0.9024\n","Epoch 32/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 1.9306 - val_accuracy: 0.8820\n","Epoch 1/32\n","32/32 [==============================] - 1s 18ms/step - loss: 2.0120 - accuracy: 0.5620 - val_loss: 0.9058 - val_accuracy: 0.6978\n","Epoch 2/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.5944 - accuracy: 0.8250 - val_loss: 0.7386 - val_accuracy: 0.7878\n","Epoch 3/32\n","32/32 [==============================] - 1s 26ms/step - loss: 0.3931 - accuracy: 0.8860 - val_loss: 0.6478 - val_accuracy: 0.8238\n","Epoch 4/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2490 - accuracy: 0.9250 - val_loss: 0.7132 - val_accuracy: 0.8280\n","Epoch 5/32\n","32/32 [==============================] - 1s 22ms/step - loss: 0.2344 - accuracy: 0.9390 - val_loss: 0.9255 - val_accuracy: 0.8008\n","Epoch 6/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1428 - accuracy: 0.9540 - val_loss: 0.6830 - val_accuracy: 0.8616\n","Epoch 7/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2067 - accuracy: 0.9530 - val_loss: 0.5709 - val_accuracy: 0.8902\n","Epoch 8/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0727 - accuracy: 0.9770 - val_loss: 0.6670 - val_accuracy: 0.8912\n","Epoch 9/32\n","32/32 [==============================] - 1s 22ms/step - loss: 0.1246 - accuracy: 0.9680 - val_loss: 0.7292 - val_accuracy: 0.8890\n","Epoch 10/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0639 - accuracy: 0.9850 - val_loss: 1.1252 - val_accuracy: 0.8552\n","Epoch 11/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1874 - accuracy: 0.9770 - val_loss: 0.8814 - val_accuracy: 0.8900\n","Epoch 12/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0580 - accuracy: 0.9870 - val_loss: 1.1225 - val_accuracy: 0.8830\n","Epoch 13/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.7761 - val_accuracy: 0.9006\n","Epoch 14/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.8058 - val_accuracy: 0.9112\n","Epoch 15/32\n","32/32 [==============================] - 0s 16ms/step - loss: 3.9364e-05 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.9068\n","Epoch 16/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1617 - accuracy: 0.9780 - val_loss: 1.1256 - val_accuracy: 0.8966\n","Epoch 17/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0349 - accuracy: 0.9930 - val_loss: 1.0536 - val_accuracy: 0.9030\n","Epoch 18/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 1.3946 - val_accuracy: 0.8920\n","Epoch 19/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1221 - accuracy: 0.9800 - val_loss: 1.4655 - val_accuracy: 0.8888\n","Epoch 20/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0365 - accuracy: 0.9940 - val_loss: 1.3468 - val_accuracy: 0.8924\n","Epoch 21/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 1.2279 - val_accuracy: 0.9058\n","Epoch 22/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0801 - accuracy: 0.9920 - val_loss: 1.1934 - val_accuracy: 0.9024\n","Epoch 23/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0610 - accuracy: 0.9930 - val_loss: 1.3257 - val_accuracy: 0.9052\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0458 - accuracy: 0.9910 - val_loss: 2.7572 - val_accuracy: 0.8318\n","Epoch 25/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0810 - accuracy: 0.9840 - val_loss: 2.9699 - val_accuracy: 0.8446\n","Epoch 26/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1114 - accuracy: 0.9840 - val_loss: 1.8023 - val_accuracy: 0.8986\n","Epoch 27/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9950 - val_loss: 1.8588 - val_accuracy: 0.8962\n","Epoch 28/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0917 - accuracy: 0.9880 - val_loss: 1.4643 - val_accuracy: 0.9090\n","Epoch 29/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0761 - accuracy: 0.9900 - val_loss: 1.2936 - val_accuracy: 0.9008\n","Epoch 30/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 1.4138 - val_accuracy: 0.9030\n","Epoch 31/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0719 - accuracy: 0.9880 - val_loss: 2.1320 - val_accuracy: 0.8726\n","Epoch 32/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0395 - accuracy: 0.9930 - val_loss: 2.1701 - val_accuracy: 0.8874\n","Epoch 1/32\n","32/32 [==============================] - 2s 37ms/step - loss: 1.8790 - accuracy: 0.5540 - val_loss: 1.2352 - val_accuracy: 0.6386\n","Epoch 2/32\n","32/32 [==============================] - 1s 22ms/step - loss: 0.5044 - accuracy: 0.8470 - val_loss: 0.4173 - val_accuracy: 0.8730\n","Epoch 3/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3429 - accuracy: 0.8970 - val_loss: 0.5769 - val_accuracy: 0.8506\n","Epoch 4/32\n","32/32 [==============================] - 1s 24ms/step - loss: 0.2458 - accuracy: 0.9340 - val_loss: 0.5682 - val_accuracy: 0.8484\n","Epoch 5/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1591 - accuracy: 0.9580 - val_loss: 1.1825 - val_accuracy: 0.7778\n","Epoch 6/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1995 - accuracy: 0.9500 - val_loss: 0.7639 - val_accuracy: 0.8694\n","Epoch 7/32\n","32/32 [==============================] - 1s 22ms/step - loss: 0.0932 - accuracy: 0.9800 - val_loss: 1.2379 - val_accuracy: 0.8400\n","Epoch 8/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2729 - accuracy: 0.9530 - val_loss: 0.7233 - val_accuracy: 0.8820\n","Epoch 9/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.6218 - val_accuracy: 0.9054\n","Epoch 10/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.9120\n","Epoch 11/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0559 - accuracy: 0.9940 - val_loss: 1.2497 - val_accuracy: 0.8646\n","Epoch 12/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.2011 - accuracy: 0.9650 - val_loss: 0.9310 - val_accuracy: 0.8776\n","Epoch 13/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0600 - accuracy: 0.9920 - val_loss: 1.0679 - val_accuracy: 0.8870\n","Epoch 14/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0863 - accuracy: 0.9880 - val_loss: 0.8437 - val_accuracy: 0.9034\n","Epoch 15/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0375 - accuracy: 0.9940 - val_loss: 0.9331 - val_accuracy: 0.8958\n","Epoch 16/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0740 - accuracy: 0.9900 - val_loss: 0.8759 - val_accuracy: 0.9102\n","Epoch 17/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0256 - accuracy: 0.9940 - val_loss: 1.1430 - val_accuracy: 0.9006\n","Epoch 18/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1005 - accuracy: 0.9820 - val_loss: 1.4421 - val_accuracy: 0.8900\n","Epoch 19/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0383 - accuracy: 0.9920 - val_loss: 1.2402 - val_accuracy: 0.9042\n","Epoch 20/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0797 - accuracy: 0.9870 - val_loss: 1.7603 - val_accuracy: 0.8746\n","Epoch 21/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9960 - val_loss: 1.8589 - val_accuracy: 0.8714\n","Epoch 22/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0635 - accuracy: 0.9890 - val_loss: 1.1761 - val_accuracy: 0.9074\n","Epoch 23/32\n","32/32 [==============================] - 0s 16ms/step - loss: 2.2387e-04 - accuracy: 1.0000 - val_loss: 2.3054 - val_accuracy: 0.8608\n","Epoch 24/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1833 - accuracy: 0.9810 - val_loss: 1.5388 - val_accuracy: 0.8992\n","Epoch 25/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1028 - accuracy: 0.9910 - val_loss: 1.4805 - val_accuracy: 0.8994\n","Epoch 26/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 1.5179 - val_accuracy: 0.8962\n","Epoch 27/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 1.7231 - val_accuracy: 0.8928\n","Epoch 28/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1111 - accuracy: 0.9950 - val_loss: 2.0353 - val_accuracy: 0.8868\n","Epoch 29/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0781 - accuracy: 0.9880 - val_loss: 1.8436 - val_accuracy: 0.8914\n","Epoch 30/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 1.5497 - val_accuracy: 0.9040\n","Epoch 31/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 1.6034 - val_accuracy: 0.9070\n","Epoch 32/32\n","32/32 [==============================] - 1s 31ms/step - loss: 2.4961e-07 - accuracy: 1.0000 - val_loss: 1.5949 - val_accuracy: 0.9076\n","Epoch 1/32\n","32/32 [==============================] - 2s 38ms/step - loss: 2.4541 - accuracy: 0.5930 - val_loss: 1.4667 - val_accuracy: 0.6778\n","Epoch 2/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.5545 - accuracy: 0.8190 - val_loss: 1.0393 - val_accuracy: 0.7220\n","Epoch 3/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.3286 - accuracy: 0.8920 - val_loss: 0.9604 - val_accuracy: 0.8090\n","Epoch 4/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.2601 - accuracy: 0.9130 - val_loss: 0.4204 - val_accuracy: 0.8834\n","Epoch 5/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1292 - accuracy: 0.9620 - val_loss: 0.8331 - val_accuracy: 0.8318\n","Epoch 6/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1398 - accuracy: 0.9510 - val_loss: 0.5853 - val_accuracy: 0.8960\n","Epoch 7/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0944 - accuracy: 0.9720 - val_loss: 1.0598 - val_accuracy: 0.8370\n","Epoch 8/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1232 - accuracy: 0.9670 - val_loss: 0.8000 - val_accuracy: 0.8886\n","Epoch 9/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 0.9870 - val_loss: 0.7684 - val_accuracy: 0.8894\n","Epoch 10/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 1.4079 - val_accuracy: 0.8472\n","Epoch 11/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1047 - accuracy: 0.9830 - val_loss: 0.8622 - val_accuracy: 0.8928\n","Epoch 12/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0747 - accuracy: 0.9840 - val_loss: 0.9030 - val_accuracy: 0.9008\n","Epoch 13/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0625 - accuracy: 0.9880 - val_loss: 1.0595 - val_accuracy: 0.8874\n","Epoch 14/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 1.0847 - val_accuracy: 0.8932\n","Epoch 15/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 1.0561 - val_accuracy: 0.9028\n","Epoch 16/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0215 - accuracy: 0.9990 - val_loss: 1.1964 - val_accuracy: 0.8976\n","Epoch 17/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1289 - accuracy: 0.9880 - val_loss: 1.3781 - val_accuracy: 0.8844\n","Epoch 18/32\n","32/32 [==============================] - 0s 15ms/step - loss: 4.5202e-04 - accuracy: 1.0000 - val_loss: 1.1607 - val_accuracy: 0.9034\n","Epoch 19/32\n","32/32 [==============================] - 0s 14ms/step - loss: 5.2356e-07 - accuracy: 1.0000 - val_loss: 1.1640 - val_accuracy: 0.9034\n","Epoch 20/32\n","32/32 [==============================] - 0s 16ms/step - loss: 2.2757e-07 - accuracy: 1.0000 - val_loss: 1.1763 - val_accuracy: 0.9036\n","Epoch 21/32\n","32/32 [==============================] - 0s 16ms/step - loss: 1.0812e-07 - accuracy: 1.0000 - val_loss: 1.2051 - val_accuracy: 0.9032\n","Epoch 22/32\n","32/32 [==============================] - 0s 14ms/step - loss: 4.0650e-08 - accuracy: 1.0000 - val_loss: 1.3535 - val_accuracy: 0.8992\n","Epoch 23/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2261 - accuracy: 0.9860 - val_loss: 1.4095 - val_accuracy: 0.9024\n","Epoch 24/32\n","32/32 [==============================] - 1s 29ms/step - loss: 1.6866e-05 - accuracy: 1.0000 - val_loss: 1.4342 - val_accuracy: 0.9050\n","Epoch 25/32\n","32/32 [==============================] - 1s 23ms/step - loss: 9.8333e-07 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.9070\n","Epoch 26/32\n","32/32 [==============================] - 1s 30ms/step - loss: 5.2929e-08 - accuracy: 1.0000 - val_loss: 1.3923 - val_accuracy: 0.9062\n","Epoch 27/32\n","32/32 [==============================] - 1s 29ms/step - loss: 2.9087e-08 - accuracy: 1.0000 - val_loss: 1.3934 - val_accuracy: 0.9068\n","Epoch 28/32\n","32/32 [==============================] - 1s 23ms/step - loss: 1.2875e-08 - accuracy: 1.0000 - val_loss: 1.3946 - val_accuracy: 0.9066\n","Epoch 29/32\n","32/32 [==============================] - 1s 29ms/step - loss: 5.8413e-09 - accuracy: 1.0000 - val_loss: 1.3972 - val_accuracy: 0.9070\n","Epoch 30/32\n","32/32 [==============================] - 1s 24ms/step - loss: 2.7418e-09 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.9072\n","Epoch 31/32\n","32/32 [==============================] - 1s 23ms/step - loss: 1.0729e-09 - accuracy: 1.0000 - val_loss: 1.3975 - val_accuracy: 0.9070\n","Epoch 32/32\n","32/32 [==============================] - 1s 22ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 1.3970 - val_accuracy: 0.9070\n","Epoch 1/32\n","32/32 [==============================] - 1s 20ms/step - loss: 1.8418 - accuracy: 0.5770 - val_loss: 0.6455 - val_accuracy: 0.7754\n","Epoch 2/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.5211 - accuracy: 0.8240 - val_loss: 0.4823 - val_accuracy: 0.8600\n","Epoch 3/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.3876 - accuracy: 0.8770 - val_loss: 1.0342 - val_accuracy: 0.7588\n","Epoch 4/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2220 - accuracy: 0.9300 - val_loss: 0.5847 - val_accuracy: 0.8636\n","Epoch 5/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2228 - accuracy: 0.9420 - val_loss: 0.4575 - val_accuracy: 0.8786\n","Epoch 6/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1529 - accuracy: 0.9680 - val_loss: 0.4927 - val_accuracy: 0.8816\n","Epoch 7/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1343 - accuracy: 0.9660 - val_loss: 0.9660 - val_accuracy: 0.8596\n","Epoch 8/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0422 - accuracy: 0.9850 - val_loss: 0.7102 - val_accuracy: 0.9008\n","Epoch 9/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1694 - accuracy: 0.9730 - val_loss: 1.6019 - val_accuracy: 0.8106\n","Epoch 10/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1294 - accuracy: 0.9700 - val_loss: 0.7835 - val_accuracy: 0.8958\n","Epoch 11/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0898 - accuracy: 0.9810 - val_loss: 1.1073 - val_accuracy: 0.8810\n","Epoch 12/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0790 - accuracy: 0.9850 - val_loss: 0.8816 - val_accuracy: 0.8990\n","Epoch 13/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0764 - accuracy: 0.9830 - val_loss: 1.0606 - val_accuracy: 0.8972\n","Epoch 14/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0342 - accuracy: 0.9910 - val_loss: 1.0080 - val_accuracy: 0.8994\n","Epoch 15/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.8830 - val_accuracy: 0.9024\n","Epoch 16/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1369 - accuracy: 0.9820 - val_loss: 1.3238 - val_accuracy: 0.8924\n","Epoch 17/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.2209 - accuracy: 0.9770 - val_loss: 1.4527 - val_accuracy: 0.8904\n","Epoch 18/32\n","32/32 [==============================] - 1s 26ms/step - loss: 0.0677 - accuracy: 0.9900 - val_loss: 1.2568 - val_accuracy: 0.8930\n","Epoch 19/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 1.8716 - val_accuracy: 0.8698\n","Epoch 20/32\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0877 - accuracy: 0.9890 - val_loss: 1.0737 - val_accuracy: 0.9110\n","Epoch 21/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0895 - accuracy: 0.9880 - val_loss: 1.3521 - val_accuracy: 0.8918\n","Epoch 22/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0857 - accuracy: 0.9830 - val_loss: 1.4030 - val_accuracy: 0.8916\n","Epoch 23/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0291 - accuracy: 0.9970 - val_loss: 1.2996 - val_accuracy: 0.9002\n","Epoch 24/32\n","32/32 [==============================] - 1s 30ms/step - loss: 1.9240e-04 - accuracy: 1.0000 - val_loss: 1.2136 - val_accuracy: 0.9048\n","Epoch 25/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0442 - accuracy: 0.9880 - val_loss: 1.7683 - val_accuracy: 0.8854\n","Epoch 26/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0547 - accuracy: 0.9900 - val_loss: 1.6590 - val_accuracy: 0.8950\n","Epoch 27/32\n","32/32 [==============================] - 0s 16ms/step - loss: 2.2818e-05 - accuracy: 1.0000 - val_loss: 1.5802 - val_accuracy: 0.9010\n","Epoch 28/32\n","32/32 [==============================] - 1s 16ms/step - loss: 3.9767e-07 - accuracy: 1.0000 - val_loss: 1.5740 - val_accuracy: 0.9012\n","Epoch 29/32\n","32/32 [==============================] - 0s 15ms/step - loss: 1.7547e-07 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.9014\n","Epoch 30/32\n","32/32 [==============================] - 0s 16ms/step - loss: 5.7459e-08 - accuracy: 1.0000 - val_loss: 1.5876 - val_accuracy: 0.9010\n","Epoch 31/32\n","32/32 [==============================] - 0s 15ms/step - loss: 2.5272e-08 - accuracy: 1.0000 - val_loss: 1.5868 - val_accuracy: 0.9008\n","Epoch 32/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.0252e-08 - accuracy: 1.0000 - val_loss: 1.5966 - val_accuracy: 0.9018\n","Epoch 1/32\n","32/32 [==============================] - 1s 19ms/step - loss: 2.2638 - accuracy: 0.5870 - val_loss: 1.0881 - val_accuracy: 0.6722\n","Epoch 2/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.5976 - accuracy: 0.8130 - val_loss: 0.7507 - val_accuracy: 0.7810\n","Epoch 3/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.3914 - accuracy: 0.8780 - val_loss: 0.4182 - val_accuracy: 0.8866\n","Epoch 4/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9340 - val_loss: 0.4277 - val_accuracy: 0.8922\n","Epoch 5/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1889 - accuracy: 0.9480 - val_loss: 0.4935 - val_accuracy: 0.8854\n","Epoch 6/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1386 - accuracy: 0.9580 - val_loss: 0.9151 - val_accuracy: 0.8290\n","Epoch 7/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0798 - accuracy: 0.9700 - val_loss: 0.8807 - val_accuracy: 0.8628\n","Epoch 8/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1048 - accuracy: 0.9770 - val_loss: 0.8250 - val_accuracy: 0.8828\n","Epoch 9/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1348 - accuracy: 0.9730 - val_loss: 1.0832 - val_accuracy: 0.8780\n","Epoch 10/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1366 - accuracy: 0.9790 - val_loss: 0.7250 - val_accuracy: 0.9062\n","Epoch 11/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 1.2878 - val_accuracy: 0.8684\n","Epoch 12/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0895 - accuracy: 0.9800 - val_loss: 0.9652 - val_accuracy: 0.8946\n","Epoch 13/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0619 - accuracy: 0.9880 - val_loss: 0.8920 - val_accuracy: 0.8992\n","Epoch 14/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.2224 - accuracy: 0.9590 - val_loss: 0.9761 - val_accuracy: 0.8826\n","Epoch 15/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.9075 - val_accuracy: 0.9144\n","Epoch 16/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.1254 - accuracy: 0.9880 - val_loss: 0.8865 - val_accuracy: 0.8974\n","Epoch 17/32\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0224 - accuracy: 0.9950 - val_loss: 1.2922 - val_accuracy: 0.8596\n","Epoch 18/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 1.0439 - val_accuracy: 0.9028\n","Epoch 19/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.2314 - val_accuracy: 0.8802\n","Epoch 20/32\n","32/32 [==============================] - 1s 23ms/step - loss: 0.1213 - accuracy: 0.9860 - val_loss: 1.0536 - val_accuracy: 0.9158\n","Epoch 21/32\n","32/32 [==============================] - 1s 29ms/step - loss: 1.1889e-05 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.9150\n","Epoch 22/32\n","32/32 [==============================] - 1s 30ms/step - loss: 3.4642e-07 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.9148\n","Epoch 23/32\n","32/32 [==============================] - 1s 29ms/step - loss: 1.1456e-07 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.9154\n","Epoch 24/32\n","32/32 [==============================] - 1s 30ms/step - loss: 3.0875e-08 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.9160\n","Epoch 25/32\n","32/32 [==============================] - 1s 30ms/step - loss: 1.1444e-08 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 0.9166\n","Epoch 26/32\n","32/32 [==============================] - 1s 30ms/step - loss: 5.8413e-09 - accuracy: 1.0000 - val_loss: 1.1379 - val_accuracy: 0.9168\n","Epoch 27/32\n","32/32 [==============================] - 1s 22ms/step - loss: 1.6689e-09 - accuracy: 1.0000 - val_loss: 1.1484 - val_accuracy: 0.9168\n","Epoch 28/32\n","32/32 [==============================] - 1s 24ms/step - loss: 9.5367e-10 - accuracy: 1.0000 - val_loss: 1.1464 - val_accuracy: 0.9170\n","Epoch 29/32\n","32/32 [==============================] - 1s 23ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 1.1518 - val_accuracy: 0.9166\n","Epoch 30/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.1921e-10 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.9172\n","Epoch 31/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.9176\n","Epoch 32/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.9180\n","Epoch 1/32\n","32/32 [==============================] - 3s 58ms/step - loss: 2.4064 - accuracy: 0.5560 - val_loss: 0.9143 - val_accuracy: 0.7234\n","Epoch 2/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.5317 - accuracy: 0.8380 - val_loss: 2.2326 - val_accuracy: 0.5942\n","Epoch 3/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.4634 - accuracy: 0.8570 - val_loss: 1.2277 - val_accuracy: 0.7258\n","Epoch 4/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.3048 - accuracy: 0.9100 - val_loss: 0.4805 - val_accuracy: 0.8768\n","Epoch 5/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1989 - accuracy: 0.9480 - val_loss: 0.5737 - val_accuracy: 0.8634\n","Epoch 6/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2149 - accuracy: 0.9340 - val_loss: 0.5329 - val_accuracy: 0.8774\n","Epoch 7/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1179 - accuracy: 0.9630 - val_loss: 1.2136 - val_accuracy: 0.8218\n","Epoch 8/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1675 - accuracy: 0.9540 - val_loss: 0.6972 - val_accuracy: 0.8766\n","Epoch 9/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1549 - accuracy: 0.9630 - val_loss: 1.4112 - val_accuracy: 0.8182\n","Epoch 10/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0870 - accuracy: 0.9800 - val_loss: 0.5738 - val_accuracy: 0.9058\n","Epoch 11/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0687 - accuracy: 0.9870 - val_loss: 0.6220 - val_accuracy: 0.9014\n","Epoch 12/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.8012 - val_accuracy: 0.8916\n","Epoch 13/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0704 - accuracy: 0.9870 - val_loss: 0.8233 - val_accuracy: 0.9006\n","Epoch 14/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 1.4091 - val_accuracy: 0.8638\n","Epoch 15/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1741 - accuracy: 0.9700 - val_loss: 0.8404 - val_accuracy: 0.9020\n","Epoch 16/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 0.9920 - val_loss: 1.1304 - val_accuracy: 0.8864\n","Epoch 17/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0376 - accuracy: 0.9910 - val_loss: 1.0690 - val_accuracy: 0.8880\n","Epoch 18/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0441 - accuracy: 0.9890 - val_loss: 1.2772 - val_accuracy: 0.8816\n","Epoch 19/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1327 - accuracy: 0.9740 - val_loss: 1.1213 - val_accuracy: 0.8882\n","Epoch 20/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 0.9910 - val_loss: 0.9891 - val_accuracy: 0.9042\n","Epoch 21/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0199 - accuracy: 0.9970 - val_loss: 0.9137 - val_accuracy: 0.9138\n","Epoch 22/32\n","32/32 [==============================] - 1s 31ms/step - loss: 1.4518e-04 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.9126\n","Epoch 23/32\n","32/32 [==============================] - 1s 31ms/step - loss: 1.7083e-06 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.9144\n","Epoch 24/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0901 - accuracy: 0.9920 - val_loss: 2.3493 - val_accuracy: 0.8470\n","Epoch 25/32\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0587 - accuracy: 0.9910 - val_loss: 1.4767 - val_accuracy: 0.8970\n","Epoch 26/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0955 - accuracy: 0.9820 - val_loss: 1.9036 - val_accuracy: 0.8728\n","Epoch 27/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0217 - accuracy: 0.9950 - val_loss: 1.3064 - val_accuracy: 0.9100\n","Epoch 28/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0622 - accuracy: 0.9940 - val_loss: 1.5106 - val_accuracy: 0.8920\n","Epoch 29/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0936 - accuracy: 0.9850 - val_loss: 1.6515 - val_accuracy: 0.8962\n","Epoch 30/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0678 - accuracy: 0.9900 - val_loss: 1.7764 - val_accuracy: 0.8858\n","Epoch 31/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 1.6509 - val_accuracy: 0.8998\n","Epoch 32/32\n","32/32 [==============================] - 1s 17ms/step - loss: 1.1844e-04 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.9138\n","Epoch 1/32\n","32/32 [==============================] - 1s 20ms/step - loss: 1.9802 - accuracy: 0.5640 - val_loss: 0.7273 - val_accuracy: 0.7502\n","Epoch 2/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.5792 - accuracy: 0.8150 - val_loss: 0.4962 - val_accuracy: 0.8492\n","Epoch 3/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.3863 - accuracy: 0.8870 - val_loss: 0.4674 - val_accuracy: 0.8720\n","Epoch 4/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2723 - accuracy: 0.9220 - val_loss: 0.4159 - val_accuracy: 0.8920\n","Epoch 5/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.2451 - accuracy: 0.9380 - val_loss: 1.2086 - val_accuracy: 0.8062\n","Epoch 6/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.2022 - accuracy: 0.9490 - val_loss: 0.6468 - val_accuracy: 0.8628\n","Epoch 7/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1856 - accuracy: 0.9580 - val_loss: 0.9202 - val_accuracy: 0.8380\n","Epoch 8/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0705 - accuracy: 0.9780 - val_loss: 0.6334 - val_accuracy: 0.8898\n","Epoch 9/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0884 - accuracy: 0.9740 - val_loss: 1.8923 - val_accuracy: 0.8216\n","Epoch 10/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1556 - accuracy: 0.9690 - val_loss: 0.9271 - val_accuracy: 0.8944\n","Epoch 11/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1471 - accuracy: 0.9760 - val_loss: 1.0727 - val_accuracy: 0.8806\n","Epoch 12/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 1.5815 - val_accuracy: 0.8644\n","Epoch 13/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1000 - accuracy: 0.9830 - val_loss: 0.8079 - val_accuracy: 0.9086\n","Epoch 14/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0581 - accuracy: 0.9900 - val_loss: 1.0600 - val_accuracy: 0.8998\n","Epoch 15/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0715 - accuracy: 0.9840 - val_loss: 1.0152 - val_accuracy: 0.9046\n","Epoch 16/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0411 - accuracy: 0.9910 - val_loss: 1.3279 - val_accuracy: 0.8786\n","Epoch 17/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0974 - accuracy: 0.9820 - val_loss: 1.2000 - val_accuracy: 0.8928\n","Epoch 18/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0359 - accuracy: 0.9900 - val_loss: 1.1165 - val_accuracy: 0.8950\n","Epoch 19/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.0203 - accuracy: 0.9970 - val_loss: 1.0722 - val_accuracy: 0.9118\n","Epoch 20/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1740 - accuracy: 0.9840 - val_loss: 1.1489 - val_accuracy: 0.9044\n","Epoch 21/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0313 - accuracy: 0.9920 - val_loss: 1.1912 - val_accuracy: 0.9082\n","Epoch 22/32\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0260 - accuracy: 0.9980 - val_loss: 1.1396 - val_accuracy: 0.9124\n","Epoch 23/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 1.4767 - val_accuracy: 0.8916\n","Epoch 24/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0471 - accuracy: 0.9930 - val_loss: 1.4559 - val_accuracy: 0.8990\n","Epoch 25/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0701 - accuracy: 0.9890 - val_loss: 1.4168 - val_accuracy: 0.9046\n","Epoch 26/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0911 - accuracy: 0.9960 - val_loss: 1.1160 - val_accuracy: 0.9134\n","Epoch 27/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.4188e-04 - accuracy: 1.0000 - val_loss: 1.1393 - val_accuracy: 0.9152\n","Epoch 28/32\n","32/32 [==============================] - 0s 15ms/step - loss: 2.6059e-07 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.9176\n","Epoch 29/32\n","32/32 [==============================] - 0s 15ms/step - loss: 9.3698e-08 - accuracy: 1.0000 - val_loss: 1.1242 - val_accuracy: 0.9180\n","Epoch 30/32\n","32/32 [==============================] - 0s 16ms/step - loss: 3.3975e-08 - accuracy: 1.0000 - val_loss: 1.1200 - val_accuracy: 0.9176\n","Epoch 31/32\n","32/32 [==============================] - 1s 16ms/step - loss: 1.4782e-08 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.9178\n","Epoch 32/32\n","32/32 [==============================] - 0s 15ms/step - loss: 6.1989e-09 - accuracy: 1.0000 - val_loss: 1.1162 - val_accuracy: 0.9182\n","Epoch 1/32\n","32/32 [==============================] - 1s 21ms/step - loss: 1.9754 - accuracy: 0.5560 - val_loss: 0.8731 - val_accuracy: 0.6864\n","Epoch 2/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.5431 - accuracy: 0.8290 - val_loss: 0.8935 - val_accuracy: 0.7420\n","Epoch 3/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.3924 - accuracy: 0.8850 - val_loss: 0.6625 - val_accuracy: 0.8206\n","Epoch 4/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.2320 - accuracy: 0.9310 - val_loss: 0.7002 - val_accuracy: 0.8238\n","Epoch 5/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1743 - accuracy: 0.9430 - val_loss: 0.5606 - val_accuracy: 0.8652\n","Epoch 6/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.1860 - accuracy: 0.9480 - val_loss: 0.4325 - val_accuracy: 0.9020\n","Epoch 7/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1348 - accuracy: 0.9590 - val_loss: 0.8341 - val_accuracy: 0.8638\n","Epoch 8/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1071 - accuracy: 0.9730 - val_loss: 0.8797 - val_accuracy: 0.8704\n","Epoch 9/32\n","32/32 [==============================] - 1s 25ms/step - loss: 0.1411 - accuracy: 0.9720 - val_loss: 0.5729 - val_accuracy: 0.9038\n","Epoch 10/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1223 - accuracy: 0.9830 - val_loss: 0.8051 - val_accuracy: 0.8850\n","Epoch 11/32\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0853 - accuracy: 0.9820 - val_loss: 0.6233 - val_accuracy: 0.9108\n","Epoch 12/32\n","32/32 [==============================] - 1s 25ms/step - loss: 0.0819 - accuracy: 0.9840 - val_loss: 1.5190 - val_accuracy: 0.8420\n","Epoch 13/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0474 - accuracy: 0.9870 - val_loss: 1.0483 - val_accuracy: 0.8684\n","Epoch 14/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.0743 - accuracy: 0.9880 - val_loss: 0.6892 - val_accuracy: 0.9182\n","Epoch 15/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.0238 - accuracy: 0.9980 - val_loss: 0.9736 - val_accuracy: 0.8896\n","Epoch 16/32\n","32/32 [==============================] - 1s 33ms/step - loss: 0.1393 - accuracy: 0.9810 - val_loss: 1.0528 - val_accuracy: 0.8894\n","Epoch 17/32\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 1.2803 - val_accuracy: 0.8732\n","Epoch 18/32\n","32/32 [==============================] - 0s 15ms/step - loss: 6.4703e-04 - accuracy: 1.0000 - val_loss: 0.9250 - val_accuracy: 0.9078\n","Epoch 19/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0518 - accuracy: 0.9900 - val_loss: 1.1826 - val_accuracy: 0.9124\n","Epoch 20/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.1331 - accuracy: 0.9830 - val_loss: 2.2128 - val_accuracy: 0.8700\n","Epoch 21/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0890 - accuracy: 0.9870 - val_loss: 1.3295 - val_accuracy: 0.8944\n","Epoch 22/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0315 - accuracy: 0.9960 - val_loss: 1.0475 - val_accuracy: 0.9134\n","Epoch 23/32\n","32/32 [==============================] - 0s 15ms/step - loss: 6.8687e-06 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.9166\n","Epoch 24/32\n","32/32 [==============================] - 0s 15ms/step - loss: 9.7279e-07 - accuracy: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.9176\n","Epoch 25/32\n","32/32 [==============================] - 1s 16ms/step - loss: 2.5832e-07 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.9176\n","Epoch 26/32\n","32/32 [==============================] - 0s 15ms/step - loss: 9.6678e-08 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.9178\n","Epoch 27/32\n","32/32 [==============================] - 0s 15ms/step - loss: 3.0041e-08 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.9184\n","Epoch 28/32\n","32/32 [==============================] - 0s 14ms/step - loss: 7.8678e-09 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.9178\n","Epoch 29/32\n","32/32 [==============================] - 0s 15ms/step - loss: 2.6226e-09 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.9188\n","Epoch 30/32\n","32/32 [==============================] - 1s 17ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 1.1070 - val_accuracy: 0.9190\n","Epoch 31/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.9196\n","Epoch 32/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1110 - val_accuracy: 0.9200\n","Epoch 1/32\n","32/32 [==============================] - 1s 24ms/step - loss: 2.0852 - accuracy: 0.5680 - val_loss: 0.5623 - val_accuracy: 0.8150\n","Epoch 2/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.4820 - accuracy: 0.8410 - val_loss: 0.6953 - val_accuracy: 0.7882\n","Epoch 3/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.3387 - accuracy: 0.8810 - val_loss: 1.1842 - val_accuracy: 0.7224\n","Epoch 4/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.2726 - accuracy: 0.9200 - val_loss: 0.5350 - val_accuracy: 0.8564\n","Epoch 5/32\n","32/32 [==============================] - 1s 29ms/step - loss: 0.1955 - accuracy: 0.9480 - val_loss: 0.5166 - val_accuracy: 0.8838\n","Epoch 6/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1886 - accuracy: 0.9400 - val_loss: 1.5579 - val_accuracy: 0.7632\n","Epoch 7/32\n","32/32 [==============================] - 1s 30ms/step - loss: 0.1688 - accuracy: 0.9560 - val_loss: 1.3333 - val_accuracy: 0.7948\n","Epoch 8/32\n","32/32 [==============================] - 1s 31ms/step - loss: 0.1495 - accuracy: 0.9650 - val_loss: 0.5052 - val_accuracy: 0.8998\n","Epoch 9/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0289 - accuracy: 0.9930 - val_loss: 0.6406 - val_accuracy: 0.8944\n","Epoch 10/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.1311 - accuracy: 0.9700 - val_loss: 0.8496 - val_accuracy: 0.8914\n","Epoch 11/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0559 - accuracy: 0.9850 - val_loss: 0.7082 - val_accuracy: 0.9024\n","Epoch 12/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.1034 - accuracy: 0.9800 - val_loss: 0.9922 - val_accuracy: 0.8850\n","Epoch 13/32\n","32/32 [==============================] - 1s 17ms/step - loss: 0.1208 - accuracy: 0.9760 - val_loss: 1.6150 - val_accuracy: 0.8374\n","Epoch 14/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0777 - accuracy: 0.9800 - val_loss: 1.5678 - val_accuracy: 0.8462\n","Epoch 15/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0668 - accuracy: 0.9870 - val_loss: 0.9255 - val_accuracy: 0.8966\n","Epoch 16/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9820 - val_loss: 1.1769 - val_accuracy: 0.8894\n","Epoch 17/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 1.9855 - val_accuracy: 0.8558\n","Epoch 18/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.1689 - accuracy: 0.9800 - val_loss: 1.0821 - val_accuracy: 0.8978\n","Epoch 19/32\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0793 - accuracy: 0.9890 - val_loss: 1.1245 - val_accuracy: 0.9038\n","Epoch 20/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0470 - accuracy: 0.9950 - val_loss: 1.8057 - val_accuracy: 0.8594\n","Epoch 21/32\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 1.6425 - val_accuracy: 0.8820\n","Epoch 22/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0547 - accuracy: 0.9900 - val_loss: 1.1295 - val_accuracy: 0.9084\n","Epoch 23/32\n","32/32 [==============================] - 1s 16ms/step - loss: 2.2432e-05 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.9102\n","Epoch 24/32\n","32/32 [==============================] - 0s 15ms/step - loss: 8.5492e-07 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.9108\n","Epoch 25/32\n","32/32 [==============================] - 0s 16ms/step - loss: 3.1566e-07 - accuracy: 1.0000 - val_loss: 1.1191 - val_accuracy: 0.9098\n","Epoch 26/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.0419e-07 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.9124\n","Epoch 27/32\n","32/32 [==============================] - 0s 16ms/step - loss: 2.7776e-08 - accuracy: 1.0000 - val_loss: 1.1262 - val_accuracy: 0.9128\n","Epoch 28/32\n","32/32 [==============================] - 1s 17ms/step - loss: 8.8215e-09 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.9134\n","Epoch 29/32\n","32/32 [==============================] - 1s 28ms/step - loss: 3.8147e-09 - accuracy: 1.0000 - val_loss: 1.1426 - val_accuracy: 0.9138\n","Epoch 30/32\n","32/32 [==============================] - 1s 30ms/step - loss: 1.5497e-09 - accuracy: 1.0000 - val_loss: 1.1490 - val_accuracy: 0.9138\n","Epoch 31/32\n","32/32 [==============================] - 1s 29ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.9138\n","Epoch 32/32\n","32/32 [==============================] - 1s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.9142\n"]}]},{"cell_type":"code","source":["# ShadowModelBundle returns data in the format suitable for the AttackModelBundle.\n","amb = AttackModelBundle(attack_model_fn, num_classes=NUM_CLASSES)\n","\n","# Fit the attack models.\n","print(\"Training the attack models...\")\n","amb.fit(X_shadow, y_shadow, fit_kwargs=dict(epochs=32, verbose=True)\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Duf01H4_CZ_Y","executionInfo":{"status":"ok","timestamp":1676605197281,"user_tz":300,"elapsed":67908,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"7cf7b269-f243-4bd2-8cce-2b6dfb1aa6c1"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the attack models...\n","Epoch 1/32\n","61/61 [==============================] - 1s 2ms/step - loss: 0.6938 - accuracy: 0.4908\n","Epoch 2/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5272\n","Epoch 3/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5092\n","Epoch 4/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5303\n","Epoch 5/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5062\n","Epoch 6/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.5303\n","Epoch 7/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5236\n","Epoch 8/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5349\n","Epoch 9/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5195\n","Epoch 10/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5236\n","Epoch 11/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5329\n","Epoch 12/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5180\n","Epoch 13/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5241\n","Epoch 14/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5231\n","Epoch 15/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5257\n","Epoch 16/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5231\n","Epoch 17/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5252\n","Epoch 18/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5287\n","Epoch 19/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5318\n","Epoch 20/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.5026\n","Epoch 21/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5334\n","Epoch 22/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5272\n","Epoch 23/32\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5236\n","Epoch 24/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.5231\n","Epoch 25/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5308\n","Epoch 26/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5313\n","Epoch 27/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.5364\n","Epoch 28/32\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5370\n","Epoch 29/32\n","61/61 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5298\n","Epoch 30/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5277\n","Epoch 31/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.5308\n","Epoch 32/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.5298\n","Epoch 1/32\n","75/75 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5250\n","Epoch 2/32\n","75/75 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5233\n","Epoch 3/32\n","75/75 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5023\n","Epoch 4/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5195\n","Epoch 5/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5090\n","Epoch 6/32\n","75/75 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5216\n","Epoch 7/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5115\n","Epoch 8/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5065\n","Epoch 9/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5166\n","Epoch 10/32\n","75/75 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5174\n","Epoch 11/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5132\n","Epoch 12/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5216\n","Epoch 13/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5090\n","Epoch 14/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.5136\n","Epoch 15/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5166\n","Epoch 16/32\n","75/75 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5170\n","Epoch 17/32\n","75/75 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5099\n","Epoch 18/32\n","75/75 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5006\n","Epoch 19/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5036\n","Epoch 20/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5204\n","Epoch 21/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5279\n","Epoch 22/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5149\n","Epoch 23/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5187\n","Epoch 24/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5187\n","Epoch 25/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5174\n","Epoch 26/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5178\n","Epoch 27/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5153\n","Epoch 28/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5166\n","Epoch 29/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5166\n","Epoch 30/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5162\n","Epoch 31/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5040\n","Epoch 32/32\n","75/75 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5162\n","Epoch 1/32\n","65/65 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5131\n","Epoch 2/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5351\n","Epoch 3/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.5326\n","Epoch 4/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5482\n","Epoch 5/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.5521\n","Epoch 6/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.5521\n","Epoch 7/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.5531\n","Epoch 8/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.5579\n","Epoch 9/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.5404\n","Epoch 10/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.5497\n","Epoch 11/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.5574\n","Epoch 12/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.5531\n","Epoch 13/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.5536\n","Epoch 14/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.5594\n","Epoch 15/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.5467\n","Epoch 16/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.5521\n","Epoch 17/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.5570\n","Epoch 18/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.5589\n","Epoch 19/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.5584\n","Epoch 20/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.5609\n","Epoch 21/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.5526\n","Epoch 22/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.5604\n","Epoch 23/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.5540\n","Epoch 24/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.5628\n","Epoch 25/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.5570\n","Epoch 26/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.5613\n","Epoch 27/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.5589\n","Epoch 28/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.5594\n","Epoch 29/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.5613\n","Epoch 30/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.5609\n","Epoch 31/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.5604\n","Epoch 32/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.5467\n","Epoch 1/32\n","66/66 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5050\n","Epoch 2/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5362\n","Epoch 3/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.5295\n","Epoch 4/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5343\n","Epoch 5/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5501\n","Epoch 6/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5612\n","Epoch 7/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.5496\n","Epoch 8/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5444\n","Epoch 9/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5434\n","Epoch 10/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5458\n","Epoch 11/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.5381\n","Epoch 12/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.5415\n","Epoch 13/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.5429\n","Epoch 14/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.5501\n","Epoch 15/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.5415\n","Epoch 16/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.5458\n","Epoch 17/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.5463\n","Epoch 18/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.5472\n","Epoch 19/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.5434\n","Epoch 20/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.5535\n","Epoch 21/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.5525\n","Epoch 22/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.5568\n","Epoch 23/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.5506\n","Epoch 24/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.5477\n","Epoch 25/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.5501\n","Epoch 26/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.5501\n","Epoch 27/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.5511\n","Epoch 28/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.5549\n","Epoch 29/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.5492\n","Epoch 30/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.5511\n","Epoch 31/32\n","66/66 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.5511\n","Epoch 32/32\n","66/66 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.5511\n","Epoch 1/32\n","61/61 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5005\n","Epoch 2/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5149\n","Epoch 3/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5164\n","Epoch 4/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5262\n","Epoch 5/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5411\n","Epoch 6/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5462\n","Epoch 7/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5467\n","Epoch 8/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5477\n","Epoch 9/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5416\n","Epoch 10/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5436\n","Epoch 11/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.5441\n","Epoch 12/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.5447\n","Epoch 13/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5375\n","Epoch 14/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.5462\n","Epoch 15/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.5575\n","Epoch 16/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.5416\n","Epoch 17/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.5447\n","Epoch 18/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.5462\n","Epoch 19/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.5416\n","Epoch 20/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.5416\n","Epoch 21/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.5539\n","Epoch 22/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.5457\n","Epoch 23/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.5498\n","Epoch 24/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.5488\n","Epoch 25/32\n","61/61 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.5539\n","Epoch 26/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.5503\n","Epoch 27/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.5503\n","Epoch 28/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.5472\n","Epoch 29/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.5503\n","Epoch 30/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.5585\n","Epoch 31/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.5503\n","Epoch 32/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.5508\n","Epoch 1/32\n","55/55 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5557\n","Epoch 2/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5817\n","Epoch 3/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.5747\n","Epoch 4/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.5851\n","Epoch 5/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.5972\n","Epoch 6/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.5903\n","Epoch 7/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6036\n","Epoch 8/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.5915\n","Epoch 9/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6013\n","Epoch 10/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6053\n","Epoch 11/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6036\n","Epoch 12/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.5984\n","Epoch 13/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6036\n","Epoch 14/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6042\n","Epoch 15/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6007\n","Epoch 16/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6018\n","Epoch 17/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6047\n","Epoch 18/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6065\n","Epoch 19/32\n","55/55 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6030\n","Epoch 20/32\n","55/55 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6036\n","Epoch 21/32\n","55/55 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6007\n","Epoch 22/32\n","55/55 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6065\n","Epoch 23/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.6030\n","Epoch 24/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6099\n","Epoch 25/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6047\n","Epoch 26/32\n","55/55 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6053\n","Epoch 27/32\n","55/55 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6088\n","Epoch 28/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6036\n","Epoch 29/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6082\n","Epoch 30/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6007\n","Epoch 31/32\n","55/55 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6053\n","Epoch 32/32\n","55/55 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6053\n","Epoch 1/32\n","62/62 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.5140\n","Epoch 2/32\n","62/62 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5467\n","Epoch 3/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5105\n","Epoch 4/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5242\n","Epoch 5/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5314\n","Epoch 6/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.5273\n","Epoch 7/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.5400\n","Epoch 8/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.5400\n","Epoch 9/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.5370\n","Epoch 10/32\n","62/62 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.5273\n","Epoch 11/32\n","62/62 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.5339\n","Epoch 12/32\n","62/62 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.5405\n","Epoch 13/32\n","62/62 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.5375\n","Epoch 14/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.5380\n","Epoch 15/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.5329\n","Epoch 16/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.5375\n","Epoch 17/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.5380\n","Epoch 18/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.5416\n","Epoch 19/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.5339\n","Epoch 20/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.5344\n","Epoch 21/32\n","62/62 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.5431\n","Epoch 22/32\n","62/62 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5395\n","Epoch 23/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.5411\n","Epoch 24/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5309\n","Epoch 25/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5339\n","Epoch 26/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.5400\n","Epoch 27/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.5431\n","Epoch 28/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.5441\n","Epoch 29/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.5380\n","Epoch 30/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.5349\n","Epoch 31/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.5334\n","Epoch 32/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5380\n","Epoch 1/32\n","63/63 [==============================] - 1s 2ms/step - loss: 0.6955 - accuracy: 0.5158\n","Epoch 2/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5183\n","Epoch 3/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5273\n","Epoch 4/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5288\n","Epoch 5/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5388\n","Epoch 6/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5383\n","Epoch 7/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5449\n","Epoch 8/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5353\n","Epoch 9/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5393\n","Epoch 10/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5419\n","Epoch 11/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5398\n","Epoch 12/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5409\n","Epoch 13/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5434\n","Epoch 14/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5554\n","Epoch 15/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5514\n","Epoch 16/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5318\n","Epoch 17/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.5393\n","Epoch 18/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5419\n","Epoch 19/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.5398\n","Epoch 20/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5464\n","Epoch 21/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5409\n","Epoch 22/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5383\n","Epoch 23/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5398\n","Epoch 24/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5388\n","Epoch 25/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5414\n","Epoch 26/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5444\n","Epoch 27/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.5409\n","Epoch 28/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5414\n","Epoch 29/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5444\n","Epoch 30/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5393\n","Epoch 31/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.5404\n","Epoch 32/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5454\n","Epoch 1/32\n","58/58 [==============================] - 1s 3ms/step - loss: 0.6863 - accuracy: 0.5198\n","Epoch 2/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.5696\n","Epoch 3/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5782\n","Epoch 4/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.5880\n","Epoch 5/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.5864\n","Epoch 6/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.5793\n","Epoch 7/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.5864\n","Epoch 8/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.5869\n","Epoch 9/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.5836\n","Epoch 10/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.5842\n","Epoch 11/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.5874\n","Epoch 12/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.5880\n","Epoch 13/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.5858\n","Epoch 14/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.5836\n","Epoch 15/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.5858\n","Epoch 16/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.5885\n","Epoch 17/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.5847\n","Epoch 18/32\n","58/58 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.5831\n","Epoch 19/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.5874\n","Epoch 20/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.5901\n","Epoch 21/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.5874\n","Epoch 22/32\n","58/58 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.5885\n","Epoch 23/32\n","58/58 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.5858\n","Epoch 24/32\n","58/58 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.5874\n","Epoch 25/32\n","58/58 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.5874\n","Epoch 26/32\n","58/58 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.5864\n","Epoch 27/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.5858\n","Epoch 28/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.5858\n","Epoch 29/32\n","58/58 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.5869\n","Epoch 30/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.5864\n","Epoch 31/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.5864\n","Epoch 32/32\n","58/58 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.5864\n","Epoch 1/32\n","64/64 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.5264\n","Epoch 2/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.5220\n","Epoch 3/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.5488\n","Epoch 4/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.5298\n","Epoch 5/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.5376\n","Epoch 6/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.5410\n","Epoch 7/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.5464\n","Epoch 8/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.5439\n","Epoch 9/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.5537\n","Epoch 10/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.5610\n","Epoch 11/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.5503\n","Epoch 12/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.5425\n","Epoch 13/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.5542\n","Epoch 14/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.5410\n","Epoch 15/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.5474\n","Epoch 16/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.5488\n","Epoch 17/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.5513\n","Epoch 18/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.5557\n","Epoch 19/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.5552\n","Epoch 20/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.5498\n","Epoch 21/32\n","64/64 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.5464\n","Epoch 22/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.5532\n","Epoch 23/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.5557\n","Epoch 24/32\n","64/64 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.5498\n","Epoch 25/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.5601\n","Epoch 26/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.5596\n","Epoch 27/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.5508\n","Epoch 28/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.5586\n","Epoch 29/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.5508\n","Epoch 30/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.5522\n","Epoch 31/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.5557\n","Epoch 32/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.5571\n"]}]},{"cell_type":"code","source":["target_data = cifar_train_fed_data[0]\n","attacker_data = cifar_test_fed_data[0]"],"metadata":{"id":"KAUOAUE0Ccjo","executionInfo":{"status":"ok","timestamp":1676605236205,"user_tz":300,"elapsed":342,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["#attacker_data = cifar_train_data"],"metadata":{"id":"qZ4SCSPsCeqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attack_test_data, real_membership_labels = prepare_attack_data(target_model, target_data, attacker_data)"],"metadata":{"id":"f0S_nc2VChT5","executionInfo":{"status":"ok","timestamp":1676605237724,"user_tz":300,"elapsed":484,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["def results(attack_guesses,real_membership_labels):\n","    pred_labels=attack_guesses\n","    true_labels=real_membership_labels\n","\n","    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n","    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n","\n","    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n","    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))\n","\n","    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n","    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n","\n","    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n","    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))\n","\n","    print ('TP: %i, FP: %i, TN: %i, FN: %i' % (TP,FP,TN,FN))\n","\n","    print(\"acc = \" + str((TP+TN)/(TP+TN+FP+FN)))\n","    print(\"precision = \" + str((TP)/(TP+FP)))\n","    print(\"recall = \" + str((TP)/(TP+FN)))\n","    \n","    acc= (TP+TN)/(TP+TN+FP+FN)\n","    prec=(TP)/(TP+FP)\n","    rec=(TP)/(TP+FN)\n","    return [acc,prec,rec]"],"metadata":{"id":"QempKD6FCjJ3","executionInfo":{"status":"ok","timestamp":1676605238704,"user_tz":300,"elapsed":6,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["attack_guesses = amb.predict(attack_test_data)\n","attack_precision = np.mean((attack_guesses == 1) == (real_membership_labels == 1))\n","\n","class_precision = []\n","\n","for c in range(NUM_CLASSES):\n","    #attack_test_data, real_membership_labels = prepare_attack_data(centralized_model, cifar_train_data, attacker_data)\n","    target_indices = [i for i, d in enumerate(target_data[1].argmax(axis=1)) if d == c]\n","    test_indices = [i for i, d in enumerate(attacker_data[1].argmax(axis=1)) if d == c]\n","\n","\n","    print(np.sum(attack_guesses[target_indices]==1) / (np.sum(attack_guesses[target_indices]) + np.sum(attack_guesses[SIZE:][test_indices])))\n","    \n","    class_precision.append(\n","            np.sum(attack_guesses[target_indices]==1) / (np.sum(attack_guesses[target_indices])\n","                                                     + np.sum(attack_guesses[SIZE:][test_indices])))\n","print(\"Average Accuracy: \", attack_precision)\n","\n","result=results(attack_guesses,real_membership_labels)\n"," \n","    #attack_accuracy_class[c].append(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZ5mAp0RCj9u","executionInfo":{"status":"ok","timestamp":1676605242209,"user_tz":300,"elapsed":1134,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"3a42c7bf-0ace-4ba6-a1d5-cf65df25a58e"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["nan\n","nan\n","nan\n","nan\n","nan\n","nan\n","nan\n","nan\n","nan\n","nan\n","Average Accuracy:  0.5\n","TP: 0, FP: 0, TN: 1000, FN: 1000\n","acc = 0.5\n","precision = nan\n","recall = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-111-787dd0fe2ce8>:12: RuntimeWarning: invalid value encountered in long_scalars\n","  print(np.sum(attack_guesses[target_indices]==1) / (np.sum(attack_guesses[target_indices]) + np.sum(attack_guesses[SIZE:][test_indices])))\n","<ipython-input-111-787dd0fe2ce8>:15: RuntimeWarning: invalid value encountered in long_scalars\n","  np.sum(attack_guesses[target_indices]==1) / (np.sum(attack_guesses[target_indices])\n","<ipython-input-110-483646540749>:20: RuntimeWarning: invalid value encountered in long_scalars\n","  print(\"precision = \" + str((TP)/(TP+FP)))\n","<ipython-input-110-483646540749>:24: RuntimeWarning: invalid value encountered in long_scalars\n","  prec=(TP)/(TP+FP)\n"]}]},{"cell_type":"markdown","source":["**MIA via Prediction Sensitivity**"],"metadata":{"id":"kbKDEsoGCn6_"}},{"cell_type":"code","execution_count":36,"metadata":{"id":"Ujiv0TziESPQ","executionInfo":{"status":"ok","timestamp":1676603915284,"user_tz":300,"elapsed":4403,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["import pickle\n","import argparse\n","\n","import numpy as np\n","import torch\n","from numpy import linalg as LA\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn.cluster import SpectralClustering"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1676603915287,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":300},"id":"anKyVFt4H8LP","outputId":"4f8fd585-fc07-4158-d065-be70dcea76ea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f5ba5af81d0>"]},"metadata":{},"execution_count":37}],"source":["np.random.seed(seed=14)\n","torch.manual_seed(14)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"uR6nQL2dH_DH","executionInfo":{"status":"ok","timestamp":1676603916625,"user_tz":300,"elapsed":10,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["target_model = student_model\n","#target_model = single_model0"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"8ao_HeM-IO-c","executionInfo":{"status":"ok","timestamp":1676603918857,"user_tz":300,"elapsed":271,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--n_sample', type=int, default=5000)\n","parser.add_argument('--n_attack', type=int, default=50)\n","parser.add_argument('--seed', type=int, default=140)\n","parser.add_argument('--neighbors', type=int, default=40)\n","parser.add_argument('--data_generate', type=bool, default=False)\n","attack_args = parser.parse_args(args=[])"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"A73f1_7gJcfT","executionInfo":{"status":"ok","timestamp":1676603920668,"user_tz":300,"elapsed":389,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["precisions = []\n","recalls = []\n","f1_scores = []"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1676603923486,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":300},"id":"TNUiUWYZJfCX","outputId":"81426047-9e4c-4fc1-da7e-6bc72b4e5d73"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f5ba5af81d0>"]},"metadata":{},"execution_count":41}],"source":["np.random.seed(seed=attack_args.seed)\n","torch.manual_seed(attack_args.seed)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"JwX1ZwpJLqi7","executionInfo":{"status":"ok","timestamp":1676603926455,"user_tz":300,"elapsed":404,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from collections import Counter\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26172,"status":"ok","timestamp":1676603957930,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":300},"id":"ty6LlBBURROc","outputId":"de0f870d-3917-4463-f055-78222af179c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/Proposal work\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/Proposal work'"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"WU1H99mQJjIC","executionInfo":{"status":"ok","timestamp":1676603964756,"user_tz":300,"elapsed":317,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["def data_reader(data_name = \"mnist\"):\n","    file_path = \"data/\"\n","    #data = pd.read_csv(file_path + 'mnist_train.csv', header=1)\n","    data = pd.read_csv(file_path + 'mnist_train.csv', header=1, skiprows=30000, nrows=29999)\n","    #data = pd.read_csv(file_path + 'fashion-mnist_train.csv', header=1)\n","    #data = pd.read_csv(file_path + 'fashion-mnist_train.csv', header=1, skiprows=30000, nrows=29999)\n","    #data = pd.read_csv(file_path + 'fashion-mnist_test.csv', header=0)\n","    #data = pd.read_csv(file_path + 'cifar_train.csv', header=1, skiprows=30000, nrows=29999)\n","    data = np.array(data)\n","    labels = data[:,0]\n","    data = data[:,1:]\n","        \n","    categorical_features = []\n","    \n","    data = data/data.max()\n","    oh_encoder = ColumnTransformer(\n","    [('oh_enc', OneHotEncoder(sparse=False), categorical_features),], \n","    remainder='passthrough' )\n","    oh_data = oh_encoder.fit_transform(data)\n","        \n","    #randomly select 10000 records as training data\n","    train_idx = np.random.choice(len(labels), 9999, replace = False)\n","    idx = range(len(labels))\n","    idx = np.array(idx)\n","    test_idx = list(set(idx).difference(set(train_idx)))\n","    test_idx = np.array(test_idx)\n","    \n","    assert test_idx.sum() + train_idx.sum() == idx.sum()\n","    \n","    X_train = data[train_idx,:]\n","    Y_train = labels[train_idx]\n","    \n","    X_test = data[test_idx,:]\n","    Y_test = labels[test_idx]\n","    \n","    orig_dataset = {\"X_train\":X_train,\n","               \"Y_train\":Y_train,\n","               \"X_test\":X_test,\n","               \"Y_test\":Y_test}\n","    \n","    X_train = oh_data[train_idx,:]\n","    \n","    X_test = oh_data[test_idx,:]\n","    \n","    oh_dataset = {\"X_train\":X_train,\n","               \"Y_train\":Y_train,\n","               \"X_test\":X_test,\n","               \"Y_test\":Y_test}\n","\n","    return orig_dataset, oh_dataset, oh_encoder"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"oUwJJKEeLzy5","executionInfo":{"status":"ok","timestamp":1676603979711,"user_tz":300,"elapsed":11521,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["orig_dataset, oh_dataset, OH_Encoder = data_reader(\"mnist\")"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"6QNtvok1_LUF","executionInfo":{"status":"ok","timestamp":1676603979715,"user_tz":300,"elapsed":70,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["class_label_for_count = np.unique(np.hstack([orig_dataset[\"Y_train\"], orig_dataset[\"Y_test\"]]))\n","n_class = len(class_label_for_count)\n","n_features = orig_dataset['X_train'].shape[1]"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"ioKqcQ3K_fZP","executionInfo":{"status":"ok","timestamp":1676603989966,"user_tz":300,"elapsed":327,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["y_attack = np.hstack(([np.ones(int(attack_args.n_attack/2)), np.zeros(int(attack_args.n_attack/2))]))\n","x_attack = np.zeros((int(attack_args.n_attack), n_features))"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"27B9EGTv_i8M","executionInfo":{"status":"ok","timestamp":1676603995376,"user_tz":300,"elapsed":533,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["Jacobian_matrix = np.zeros([attack_args.n_attack, n_class, n_features])"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"2VkIP4RD_pcA","executionInfo":{"status":"ok","timestamp":1676603996689,"user_tz":300,"elapsed":9,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["if attack_args.data_generate:\n","    output_x = np.zeros((attack_args.n_attack, n_features))\n","    output_y = y_attack\n","    classes = np.zeros((attack_args.n_attack, 1))"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"sJPuhlKz_961","executionInfo":{"status":"ok","timestamp":1676603999000,"user_tz":300,"elapsed":283,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["def fn_R_given_Selected(dataset, IN_or_OUT = 1):\n","    if(IN_or_OUT == 1):#IN_or_OUT == 1 meaning selecting R_given from training set\n","        idx = np.random.choice( len(dataset['Y_train']) )\n","        R_given = dataset['X_train'][idx,:]\n","        R_given_y = dataset['Y_train'][idx]\n","    elif(IN_or_OUT == 0):#IN_or_OUT == 0 meaning selecting R_given from testing set\n","        idx = np.random.choice( len(dataset['Y_test']) )\n","        R_given = dataset['X_test'][idx,:]\n","        R_given_y = dataset['Y_test'][idx]\n","    return R_given, R_given_y"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"Ew93UQtdAqWS","executionInfo":{"status":"ok","timestamp":1676604075974,"user_tz":300,"elapsed":461,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["def Target_Model_pred_fn(Target_Model, X_test):\n","    pred_proba = Target_Model.predict_proba(X_test)\n","    return pred_proba"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"pop4W0YrAPef","executionInfo":{"status":"ok","timestamp":1676604081389,"user_tz":300,"elapsed":294,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["categorical_list ={\n","    \"mnist\": [1,2,3,4,5,6,7,8,9,10],\n","}"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"U-xTRmmcADLZ","executionInfo":{"status":"ok","timestamp":1676604084612,"user_tz":300,"elapsed":396,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["def fn_Sample_Generator(R_given, dataset):\n","    if not dataset in categorical_list.keys():\n","        dataset = \"null\"\n","    epsilon = 1e-6\n","    R_given = R_given.reshape([1, -1])\n","    n_feature = R_given.shape[1]\n","    local_samples = np.repeat(R_given, repeats=n_feature, axis=0)\n","    for i in range(n_feature):\n","        if i in categorical_list[dataset]:\n","            continue\n","        local_samples[i][i] += epsilon\n","\n","    return local_samples"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"2e-Y9y2gA3r3","executionInfo":{"status":"ok","timestamp":1676604087253,"user_tz":300,"elapsed":476,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["def fn_Jacobian_Calculation(R_given, local_proba, n_features, n_class):\n","    epsilon = 1e-6\n","    jacobian = np.zeros([n_class, n_features])\n","\n","    for ii in range(n_class):\n","        jacobian[ii, :] = (local_proba[:, ii] - R_given[ii]) / epsilon\n","    return jacobian"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10179,"status":"ok","timestamp":1676604099048,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":300},"id":"NaYgLSL7_tjW","outputId":"299438e9-d3f5-483c-8710-34fbea63576c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n","  warnings.warn('`model.predict_proba()` is deprecated and '\n","WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (None, 784).\n"]}],"source":["for ii in range(attack_args.n_attack):\n","      R_x, R_y = fn_R_given_Selected(orig_dataset, IN_or_OUT=y_attack[ii])\n","      R_x_OH = OH_Encoder.transform(R_x.reshape(1, -1))\n","      x_attack[ii] = R_x\n","      local_samples = fn_Sample_Generator(R_x, \"mnist\")\n","      oh_local_samples = OH_Encoder.transform(local_samples)\n","      local_proba = Target_Model_pred_fn(target_model, oh_local_samples)\n","      R_local_proba = Target_Model_pred_fn(target_model, R_x_OH)\n","      Jacobian_matrix[ii] = fn_Jacobian_Calculation(R_local_proba[0], local_proba, n_features, n_class)\n","\n","      if attack_args.data_generate:\n","          output_x[ii] = R_x\n","          classes[ii] = R_y"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"hMNyqVZEBmVr","executionInfo":{"status":"ok","timestamp":1676604112212,"user_tz":300,"elapsed":489,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["Jacobian_norms = LA.norm(Jacobian_matrix, axis=(1, 2))"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"sF1ghDXZBpkt","executionInfo":{"status":"ok","timestamp":1676604117641,"user_tz":300,"elapsed":306,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[],"source":["split = 1\n","attack_cluster = SpectralClustering(n_clusters=6, n_jobs=-1, affinity='nearest_neighbors', n_neighbors=19)\n","y_attack_pred = attack_cluster.fit_predict(Jacobian_norms.reshape(-1, 1))\n","cluster_1 = np.where(y_attack_pred >= split)[0]\n","cluster_0 = np.where(y_attack_pred < split)[0]\n","y_attack_pred[cluster_1] = 1\n","y_attack_pred[cluster_0] = 0\n","cluster_1_mean_norm = Jacobian_norms[cluster_1].mean()\n","cluster_0_mean_norm = Jacobian_norms[cluster_0].mean()\n","if cluster_1_mean_norm > cluster_0_mean_norm:\n","  y_attack_pred = np.abs(y_attack_pred-1)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1676604120140,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":300},"id":"8_Uk38OPB9Eb","outputId":"3cab7d08-074c-498a-a6fd-a1f0728d8bd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.625 0.2 0.30303030303030304\n"]}],"source":["precision = precision_score(y_attack, y_attack_pred)\n","recall = recall_score(y_attack, y_attack_pred)\n","f1_score = 2*precision*recall/(precision+recall)\n","print(precision, recall, f1_score)\n","precisions.append(precision)\n","recalls.append(recall)\n","f1_scores.append(f1_score)"]}]}