{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":35224,"status":"ok","timestamp":1666354697254,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"oIFoyj3XeooO","outputId":"36ae9e30-4826-44ae-94ce-695889fb8449"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-privacy\n","  Downloading tensorflow_privacy-0.8.7-py3-none-any.whl (301 kB)\n","\u001b[K     |████████████████████████████████| 301 kB 18.3 MB/s \n","\u001b[?25hCollecting matplotlib~=3.3\n","  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[K     |████████████████████████████████| 11.2 MB 36.8 MB/s \n","\u001b[?25hCollecting tensorflow-privacy\n","  Downloading tensorflow_privacy-0.8.6-py3-none-any.whl (301 kB)\n","\u001b[K     |████████████████████████████████| 301 kB 44.4 MB/s \n","\u001b[?25h  Downloading tensorflow_privacy-0.8.5-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 46.7 MB/s \n","\u001b[?25h  Downloading tensorflow_privacy-0.8.4-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 44.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.9.0)\n","Requirement already satisfied: numpy~=1.21.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.21.6)\n","Collecting attrs~=21.4.0\n","  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 6.5 MB/s \n","\u001b[?25hCollecting tensorflow-datasets~=4.5.2\n","  Downloading tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 37.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-probability~=0.15 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.16.0)\n","Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.9.2)\n","Collecting absl-py~=1.0.0\n","  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n","\u001b[K     |████████████████████████████████| 126 kB 11.0 MB/s \n","\u001b[?25hRequirement already satisfied: dm-tree~=0.1.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.1.7)\n","Collecting matplotlib~=3.3.4\n","  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n","\u001b[K     |████████████████████████████████| 11.5 MB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn~=1.0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.0.2)\n","Collecting dp-accounting~=0.1.2\n","  Downloading dp_accounting-0.1.2-py3-none-any.whl (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 512 kB/s \n","\u001b[?25hCollecting pandas~=1.1.4\n","  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 43.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.7.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py~=1.0.0->tensorflow-privacy) (1.15.0)\n","Requirement already satisfied: mpmath~=1.2.1 in /usr/local/lib/python3.7/dist-packages (from dp-accounting~=0.1.2->tensorflow-privacy) (1.2.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib~=3.3.4->tensorflow-privacy) (4.1.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.4->tensorflow-privacy) (2022.4)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=1.0.2->tensorflow-privacy) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=1.0.2->tensorflow-privacy) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.0.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (14.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.3.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.4.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.12)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.27.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.49.1)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.9.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.6.3)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.17.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (57.4.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (21.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.14.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow-privacy) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.4->tensorflow-privacy) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2.23.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.4->tensorflow-privacy) (3.2.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (0.3.5.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.10.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (5.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (4.64.1)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15->tensorflow-privacy) (1.5.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15->tensorflow-privacy) (4.4.2)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.56.4)\n","Installing collected packages: absl-py, attrs, tensorflow-datasets, pandas, matplotlib, dp-accounting, tensorflow-privacy\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.3.0\n","    Uninstalling absl-py-1.3.0:\n","      Successfully uninstalled absl-py-1.3.0\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 22.1.0\n","    Uninstalling attrs-22.1.0:\n","      Successfully uninstalled attrs-22.1.0\n","  Attempting uninstall: tensorflow-datasets\n","    Found existing installation: tensorflow-datasets 4.6.0\n","    Uninstalling tensorflow-datasets-4.6.0:\n","      Successfully uninstalled tensorflow-datasets-4.6.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","Successfully installed absl-py-1.0.0 attrs-21.4.0 dp-accounting-0.1.2 matplotlib-3.3.4 pandas-1.1.5 tensorflow-datasets-4.5.2 tensorflow-privacy-0.8.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{}}],"source":["pip install tensorflow-privacy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9261,"status":"ok","timestamp":1666354728967,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"2dPiaB9t1vFq","outputId":"d116a8cf-959b-4e82-eb84-2c43a2655db5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_probability==0.12.2\n","  Downloading tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n","\u001b[K     |████████████████████████████████| 4.8 MB 24.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.12.2) (1.21.6)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.12.2) (1.15.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.12.2) (0.1.7)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.12.2) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.12.2) (1.5.0)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_probability==0.12.2) (0.4.0)\n","Installing collected packages: tensorflow-probability\n","  Attempting uninstall: tensorflow-probability\n","    Found existing installation: tensorflow-probability 0.16.0\n","    Uninstalling tensorflow-probability-0.16.0:\n","      Successfully uninstalled tensorflow-probability-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-privacy 0.8.4 requires tensorflow-probability~=0.15, but you have tensorflow-probability 0.12.2 which is incompatible.\u001b[0m\n","Successfully installed tensorflow-probability-0.12.2\n"]}],"source":["pip install tensorflow_probability==0.12.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1349209,"status":"ok","timestamp":1666356242354,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"MkIwKekTossL","outputId":"e8124a90-69e0-4f57-c713-66a6e58ab069"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.4.0\n","  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 30.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (2.9.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.21.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (6.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (1.7.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.0) (3.1.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.49.1)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (57.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (21.3)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[K     |████████████████████████████████| 578.0 MB 14 kB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[K     |████████████████████████████████| 438 kB 61.3 MB/s \n","\u001b[?25hCollecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[K     |████████████████████████████████| 511.7 MB 6.5 kB/s \n","\u001b[?25h  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[K     |████████████████████████████████| 511.7 MB 4.8 kB/s \n","\u001b[?25h  Downloading tensorflow-2.8.3-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n","\u001b[K     |████████████████████████████████| 497.9 MB 34 kB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.0.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.14.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (14.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n","Collecting tensorboard<2.9,>=2.8\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.15.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.17.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.0.1)\n","Collecting tensorflow>=2.2.0\n","  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220929150707-cp37-cp37m-linux_x86_64.whl (437.8 MB)\n","\u001b[K     |████████████████████████████████| 437.8 MB 33 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220822160911-cp37-cp37m-linux_x86_64.whl (437.8 MB)\n","\u001b[K     |████████████████████████████████| 437.8 MB 21 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220719082949-cp37-cp37m-linux_x86_64.whl (518.1 MB)\n","\u001b[K     |████████████████████████████████| 518.1 MB 25 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220714162028-cp37-cp37m-linux_x86_64.whl (518.1 MB)\n","\u001b[K     |████████████████████████████████| 518.1 MB 20 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220714152931-cp37-cp37m-linux_x86_64.whl (587.9 MB)\n","\u001b[K     |████████████████████████████████| 587.9 MB 9.3 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220629235552-cp37-cp37m-linux_x86_64.whl (668.6 MB)\n","\u001b[K     |████████████████████████████████| 668.6 MB 3.8 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220527125636-cp37-cp37m-linux_x86_64.whl (668.6 MB)\n","\u001b[K     |████████████████████████████████| 668.6 MB 1.0 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.2%2Bzzzcolab20220523105045-cp37-cp37m-linux_x86_64.whl (668.6 MB)\n","\u001b[K     |████████████████████████████████| 668.6 MB 2.4 kB/s \n","\u001b[?25h  Downloading tensorflow-2.8.2-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n","\u001b[K     |████████████████████████████████| 497.9 MB 16 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.1%2Bzzzcolab20220518083849-cp37-cp37m-linux_x86_64.whl (668.6 MB)\n","\u001b[K     |████████████████████████████████| 668.6 MB 6.9 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.1%2Bzzzcolab20220516111314-cp37-cp37m-linux_x86_64.whl (668.6 MB)\n","\u001b[K     |████████████████████████████████| 668.6 MB 17 kB/s \n","\u001b[?25h  Downloading tensorflow-2.8.1-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n","\u001b[K     |████████████████████████████████| 497.9 MB 17 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n","\u001b[K     |████████████████████████████████| 668.3 MB 18 kB/s \n","\u001b[?25h  Downloading tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n","\u001b[K     |████████████████████████████████| 497.5 MB 25 kB/s \n","\u001b[?25h  Downloading tensorflow-2.7.4-cp37-cp37m-manylinux2010_x86_64.whl (495.5 MB)\n","\u001b[K     |████████████████████████████████| 495.5 MB 13 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.3%2Bzzzcolab20220523111007-cp37-cp37m-linux_x86_64.whl (671.4 MB)\n","\u001b[K     |████████████████████████████████| 671.4 MB 14 kB/s \n","\u001b[?25h  Downloading tensorflow-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (495.4 MB)\n","\u001b[K     |████████████████████████████████| 495.4 MB 29 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.2%2Bzzzcolab20220516114640-cp37-cp37m-linux_x86_64.whl (671.4 MB)\n","\u001b[K     |████████████████████████████████| 671.4 MB 1.8 kB/s \n","\u001b[?25h  Downloading tensorflow-2.7.2-cp37-cp37m-manylinux2010_x86_64.whl (495.4 MB)\n","\u001b[K     |████████████████████████████████| 495.4 MB 32 kB/s \n","\u001b[?25h  Downloading tensorflow-2.7.1-cp37-cp37m-manylinux2010_x86_64.whl (495.0 MB)\n","\u001b[K     |████████████████████████████████| 495.0 MB 33 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.0%2Bzzzcolab20220506150900-cp37-cp37m-linux_x86_64.whl (665.5 MB)\n","\u001b[K     |████████████████████████████████| 665.5 MB 18 kB/s \n","\u001b[?25h  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n","\u001b[K     |████████████████████████████████| 489.6 MB 25 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.5%2Bzzzcolab20220523104206-cp37-cp37m-linux_x86_64.whl (570.3 MB)\n","\u001b[K     |████████████████████████████████| 570.3 MB 322 bytes/s \n","\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.37.1)\n","Collecting tensorflow-estimator<2.7,>=2.6.0\n","  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 50.1 MB/s \n","\u001b[?25hCollecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.4.0)\n","Collecting clang~=5.0\n","  Downloading clang-5.0.tar.gz (30 kB)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 38.0 MB/s \n","\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n","Collecting typing-extensions<3.11,>=3.7\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting tensorboard<2.7,>=2.6.0\n","  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 40.8 MB/s \n","\u001b[?25hCollecting numpy>=1.9.1\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 26.7 MB/s \n","\u001b[?25hCollecting termcolor~=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.6.5-cp37-cp37m-manylinux2010_x86_64.whl (464.2 MB)\n","\u001b[K     |████████████████████████████████| 464.2 MB 8.1 kB/s \n","\u001b[?25h  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.4%2Bzzzcolab20220516125453-cp37-cp37m-linux_x86_64.whl (570.3 MB)\n","\u001b[K     |████████████████████████████████| 570.3 MB 25 kB/s \n","\u001b[?25h  Downloading tensorflow-2.6.4-cp37-cp37m-manylinux2010_x86_64.whl (464.2 MB)\n","\u001b[K     |████████████████████████████████| 464.2 MB 18 kB/s \n","\u001b[?25h  Downloading tensorflow-2.6.3-cp37-cp37m-manylinux2010_x86_64.whl (463.8 MB)\n","\u001b[K     |████████████████████████████████| 463.8 MB 33 kB/s \n","\u001b[?25h  Downloading tensorflow-2.6.2-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n","\u001b[K     |████████████████████████████████| 458.3 MB 13 kB/s \n","\u001b[?25hCollecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Collecting tensorflow>=2.2.0\n","  Downloading tensorflow-2.6.1-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n","\u001b[K     |████████████████████████████████| 458.3 MB 13 kB/s \n","\u001b[?25hRequirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.9.1)\n","  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.0%2Bzzzcolab20220506153740-cp37-cp37m-linux_x86_64.whl (564.4 MB)\n","\u001b[K     |████████████████████████████████| 564.4 MB 2.6 kB/s \n","\u001b[?25h  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n","\u001b[K     |████████████████████████████████| 458.3 MB 11 kB/s \n","\u001b[?25h  Downloading tensorflow-2.5.3-cp37-cp37m-manylinux2010_x86_64.whl (460.3 MB)\n","\u001b[K     |████████████████████████████████| 460.3 MB 8.5 kB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0\n","  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 55.2 MB/s \n","\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 48.9 MB/s \n","\u001b[?25hCollecting grpcio~=1.34.0\n","  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 34.5 MB/s \n","\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.0) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (1.35.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->keras==2.4.0) (3.2.1)\n","Building wheels for collected packages: termcolor, wrapt\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=5e698e9665178602d26f13439e5047cbb137f65bb25a7d61a955ff9889b0db18\n","  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68712 sha256=efefda9d37d874bdefc0b3dd464f3dc602a43e8b8a6877158f5e19e1d0b4fec8\n","  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n","Successfully built termcolor wrapt\n","Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, keras-nightly, tensorflow, keras\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.49.1\n","    Uninstalling grpcio-1.49.1:\n","      Successfully uninstalled grpcio-1.49.1\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.0.0\n","    Uninstalling absl-py-1.0.0:\n","      Successfully uninstalled absl-py-1.0.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.0.1\n","    Uninstalling termcolor-2.0.1:\n","      Successfully uninstalled termcolor-2.0.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n","tensorflow-privacy 0.8.4 requires absl-py~=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n","tensorflow-privacy 0.8.4 requires numpy~=1.21.4, but you have numpy 1.19.5 which is incompatible.\n","tensorflow-privacy 0.8.4 requires tensorflow-probability~=0.15, but you have tensorflow-probability 0.12.2 which is incompatible.\n","jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","dp-accounting 0.1.2 requires absl-py~=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n","dp-accounting 0.1.2 requires numpy~=1.21.4, but you have numpy 1.19.5 which is incompatible.\n","cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n","Successfully installed absl-py-0.15.0 grpcio-1.34.1 keras-2.4.0 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.3 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","typing_extensions"]}}},"metadata":{}}],"source":["pip install keras==2.4.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4150,"status":"ok","timestamp":1666356529589,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"zvBRWBSatHYf","outputId":"bcf1531f-cd75-4842-f623-4a2e190a4d2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: Keras\n","Version: 2.4.0\n","Summary: Deep Learning for humans\n","Home-page: https://github.com/keras-team/keras\n","Author: Francois Chollet\n","Author-email: francois.chollet@gmail.com\n","License: MIT\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: tensorflow, numpy, pyyaml, scipy, h5py\n","Required-by: keras-vis\n"]}],"source":["pip show keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-4oTs9to5PL","outputId":"4bf1ebbb-9cfb-4ff7-cc4d-fa4f3e9edb9a","executionInfo":{"status":"ok","timestamp":1666356542746,"user_tz":240,"elapsed":12124,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mia\n","  Downloading mia-0.1.2.tar.gz (17 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mia) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mia) (1.7.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mia) (1.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from mia) (1.12.1+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mia) (4.64.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mia) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mia) (1.2.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->mia) (3.7.4.3)\n","Building wheels for collected packages: mia\n","  Building wheel for mia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mia: filename=mia-0.1.2-py3-none-any.whl size=11106 sha256=edda66a2d6899445aa28c489be73f3687c100b91923501beaa02d12b34a44d2e\n","  Stored in directory: /root/.cache/pip/wheels/11/cb/28/c0c2be5bebacd827e384b58ccfe4833ca3bffc1aa0086766d7\n","Successfully built mia\n","Installing collected packages: mia\n","Successfully installed mia-0.1.2\n"]}],"source":["pip install mia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T88zlQ1anlXk","executionInfo":{"status":"ok","timestamp":1666361025701,"user_tz":240,"elapsed":2849,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"}},"outputId":"6a2a7fb3-f461-4bdf-a4d6-c0694cf61100"},"outputs":[{"name":"stdout","output_type":"stream","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"]}],"source":["%reset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-aNzUHWA_0zt"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import random\n","import datetime\n","import tensorflow_privacy\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYgGOjrfqdrG"},"outputs":[],"source":["tf.random.set_seed(42)\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"6ViFmY1ZMjrI"},"source":["**Federated Learning Data Preparation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmI-lXuBTSWm"},"outputs":[],"source":["def load_mnist():\n","  \"\"\"Loads MNIST and preprocesses to combine training and validation data.\"\"\"\n","  train, test = tf.keras.datasets.mnist.load_data()\n","  #train, test = tf.keras.datasets.fashion_mnist.load_data()\n","  #train, test = tf.keras.datasets.cifar10.load_data()\n","  train_data, train_labels = train\n","  test_data, test_labels = test\n","\n","  train_data = np.array(train_data, dtype=np.float32) / 255\n","  test_data = np.array(test_data, dtype=np.float32) / 255\n","\n","  train_data = train_data.reshape((train_data.shape[0], 28, 28, 1))\n","  test_data = test_data.reshape((test_data.shape[0], 28, 28, 1))\n","  #train_data = train_data.reshape((train_data.shape[0], 32, 32, 3))\n","  #test_data = test_data.reshape((test_data.shape[0], 32, 32, 3))\n","\n","  train_labels = np.array(train_labels, dtype=np.int32)\n","  test_labels = np.array(test_labels, dtype=np.int32)\n","\n","  #train_labels = np.array(train_labels, dtype=np.int64)\n","  #test_labels = np.array(test_labels, dtype=np.int64)\n","\n","  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n","  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n","\n","  #assert train_data.min() == 0.\n","  #assert train_data.max() == 1.\n","  #assert test_data.min() == 0.\n","  #assert test_data.max() == 1.\n","\n","  return train_data, train_labels, test_data, test_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0ONgC-9TgO9"},"outputs":[],"source":["# Load training and test data.\n","train_data, train_labels, test_data, test_labels = load_mnist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MuGjkxe-WUxp"},"outputs":[],"source":["cifar_train = train_data, train_labels\n","cifar_test = test_data, test_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFtv_TxjDlj6"},"outputs":[],"source":["CLIENTS = 3\n","SIZE = 10000\n","\n","def get_data(source):   \n","    \n","    all_data = (np.array(source[0][:SIZE*CLIENTS]), source[1][:SIZE*CLIENTS]) \n","    \n","    split_data = []\n","    for s in range(CLIENTS):\n","        start = s*SIZE\n","        end = s*SIZE + SIZE\n","        split_data.append((all_data[0][start:end], all_data[1][start:end]))\n","    \n","    external_data = (np.array(source[0][SIZE*CLIENTS:]), source[1][SIZE*CLIENTS:]) \n","    \n","    return all_data, split_data, external_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9GcN1X-SGoE"},"outputs":[],"source":["CLIENTS = 3\n","SIZE = 1000\n","\n","def get_test_data(source):   \n","    \n","    all_data = (np.array(source[0][:SIZE*CLIENTS]), source[1][:SIZE*CLIENTS]) \n","    \n","    split_data = []\n","    for s in range(CLIENTS):\n","        start = s*SIZE\n","        end = s*SIZE + SIZE\n","        split_data.append((all_data[0][start:end], all_data[1][start:end]))\n","    \n","    external_data = (np.array(source[0][SIZE*CLIENTS:]), source[1][SIZE*CLIENTS:]) \n","    \n","    return all_data, split_data, external_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08iWxGFuDzUp"},"outputs":[],"source":["cifar_train_data, cifar_train_fed_data, attacker_data = get_data(cifar_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9AZWKhoeZSU"},"outputs":[],"source":["cifar_test_data, cifar_test_fed_data, externat_test_data = get_test_data(cifar_test)"]},{"cell_type":"markdown","metadata":{"id":"iBGH89GqNAwp"},"source":["**Creating Model with Keras**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_OpWFHW0FPL"},"outputs":[],"source":["class MCDropout(tf.keras.layers.Dropout):\n","    def call(self, inputs):\n","        return super().call(inputs, training=True)\n","\n","class MCAlphaDropout(tf.keras.layers.AlphaDropout):\n","    def call(self, inputs):\n","        return super().call(inputs, training=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LU2dpLj9q8P4"},"outputs":[],"source":["def create_compiled_keras_model():\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape=[28, 28, 1]),\n","        #tf.keras.layers.AlphaDropout(rate=0.2),\n","        tf.keras.layers.Dropout(0.2),\n","        #tf.keras.layers.GaussianNoise(0.2),\n","        #tf.keras.layers.GaussianDropout(0.2),\n","        tf.keras.layers.Dense(300, activation=\"relu\"),\n","        #tf.keras.layers.AlphaDropout(rate=0.2),\n","        tf.keras.layers.Dropout(0.2),\n","        #tf.keras.layers.GaussianNoise(0.2),\n","        #tf.keras.layers.GaussianDropout(0.2),\n","        tf.keras.layers.Dense(100, activation=\"relu\"),\n","        #tf.keras.layers.AlphaDropout(rate=0.2),\n","        tf.keras.layers.Dropout(0.2),\n","        #tf.keras.layers.GaussianNoise(0.2),\n","        #tf.keras.layers.GaussianDropout(0.2),\n","        tf.keras.layers.Dense(10, activation=\"softmax\")\n","    ])\n","    #mc_model = tf.keras.models.Sequential([\n","        #MCAlphaDropout(layer.rate) if isinstance(layer, tf.keras.layers.AlphaDropout) else layer\n","        #for layer in model.layers\n","    #])\n","    #mc_model = tf.keras.models.Sequential([\n","        #MCDropout(layer.rate) if isinstance(layer, tf.keras.layers.Dropout) else layer\n","        #for layer in model.layers\n","    #])\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","    model.compile(loss=loss,\n","              optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01),\n","              metrics=[\"accuracy\"])\n","    #return mc_model\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"dkknkTXkNUTp"},"source":["**Centralized Model - Non Federated**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1666361062336,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"QWf76JT37Xw6","outputId":"fc1f689a-1b22-4931-8383-da8f2242d153"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_442\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_442 (Flatten)        (None, 784)               0         \n","_________________________________________________________________\n","dropout_498 (Dropout)        (None, 784)               0         \n","_________________________________________________________________\n","dense_1326 (Dense)           (None, 300)               235500    \n","_________________________________________________________________\n","dropout_499 (Dropout)        (None, 300)               0         \n","_________________________________________________________________\n","dense_1327 (Dense)           (None, 100)               30100     \n","_________________________________________________________________\n","dropout_500 (Dropout)        (None, 100)               0         \n","_________________________________________________________________\n","dense_1328 (Dense)           (None, 10)                1010      \n","=================================================================\n","Total params: 266,610\n","Trainable params: 266,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["centralized_model = create_compiled_keras_model()\n","centralized_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5732,"status":"ok","timestamp":1665837393947,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"OHapL_XCGtX6","outputId":"dc925cb7-cf2d-4de6-a073-2bc40fe0c719"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/12\n","94/94 [==============================] - 1s 5ms/step - loss: 1.7876 - accuracy: 0.4663 - val_loss: 1.3758 - val_accuracy: 0.6423\n","Epoch 2/12\n","94/94 [==============================] - 0s 4ms/step - loss: 1.1520 - accuracy: 0.6770 - val_loss: 1.0013 - val_accuracy: 0.6943\n","Epoch 3/12\n","94/94 [==============================] - 0s 3ms/step - loss: 0.9053 - accuracy: 0.7260 - val_loss: 0.8481 - val_accuracy: 0.7280\n","Epoch 4/12\n","94/94 [==============================] - 0s 4ms/step - loss: 0.7879 - accuracy: 0.7510 - val_loss: 0.7841 - val_accuracy: 0.7280\n","Epoch 5/12\n","94/94 [==============================] - 0s 4ms/step - loss: 0.7190 - accuracy: 0.7670 - val_loss: 0.7122 - val_accuracy: 0.7483\n","Epoch 6/12\n","94/94 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.7853 - val_loss: 0.6818 - val_accuracy: 0.7657\n","Epoch 7/12\n","94/94 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.8000 - val_loss: 0.6742 - val_accuracy: 0.7687\n","Epoch 8/12\n","94/94 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.7947 - val_loss: 0.6313 - val_accuracy: 0.7823\n","Epoch 9/12\n","94/94 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.8100 - val_loss: 0.6346 - val_accuracy: 0.7783\n","Epoch 10/12\n","94/94 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.8163 - val_loss: 0.6122 - val_accuracy: 0.7850\n","Epoch 11/12\n","94/94 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.8227 - val_loss: 0.5920 - val_accuracy: 0.7977\n","Epoch 12/12\n","94/94 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8190 - val_loss: 0.6011 - val_accuracy: 0.7847\n"]}],"source":["history_callback = centralized_model.fit(cifar_train_data[0], cifar_train_data[1], validation_data=cifar_test_data, batch_size=32, epochs=12, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1665829953809,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"Ldo_UyYEGZwb","outputId":"b7467bee-3b85-4829-8d1c-20f7aec5e92e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cifar, Centralized, IDD, minibatch_size: 32\n","NFTrain = [2.1061220169067383, 0.7750603556632996, 0.6955212950706482, 0.6635895371437073, 0.5884738564491272, 0.5759220123291016, 0.529890775680542, 0.5316728353500366, 0.527821958065033, 0.4983668327331543, 0.4873162806034088, 0.4842219352722168]\n","NFTest = [0.7685554027557373, 1.0905771255493164, 0.7465343475341797, 0.7722450494766235, 0.6483358144760132, 0.7669934034347534, 0.8090450763702393, 0.6659829616546631, 0.9489931464195251, 0.8188542723655701, 1.0355780124664307, 0.8860523104667664]\n","NFAccuracy = [0.6896666884422302, 0.6690000295639038, 0.6983333230018616, 0.7269999980926514, 0.7753333449363708, 0.7726666927337646, 0.7646666765213013, 0.7950000166893005, 0.753333330154419, 0.7713333368301392, 0.7103333473205566, 0.7743333578109741]\n"]}],"source":["print(\"Cifar, Centralized, IDD, minibatch_size: 32\")\n","print(\"NFTrain = {}\".format(history_callback.history[\"loss\"]))\n","print(\"NFTest = {}\".format(history_callback.history[\"val_loss\"]))\n","print(\"NFAccuracy = {}\".format(history_callback.history[\"val_accuracy\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1665837405085,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"EGKnzYYmGcN9","outputId":"f890bac5-eb2d-455f-ec59-31899e1d920d"},"outputs":[{"data":{"text/plain":["0.7502777725458145"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback.history['val_accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1665837406827,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"MVehSoQzUWUX","outputId":"64eb0814-e69c-441c-98c4-6435ac3ae0bc"},"outputs":[{"data":{"text/plain":["0.7623901963233948"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback.history['val_loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1665837407703,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"mqUwkx9OUiqP","outputId":"faad66ec-c93c-4dea-c793-b500225033de"},"outputs":[{"data":{"text/plain":["0.7916185905536016"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback.history['loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665837409025,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"49EzZa3GUrUC","outputId":"c91286ca-e21c-4935-8014-86ec85b609a0"},"outputs":[{"data":{"text/plain":["0.7529444446166357"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback.history['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"BSgwybMwNf9B"},"source":["**Client Model 1**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3328,"status":"ok","timestamp":1665841439657,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"EFN9h_VEIxwA","outputId":"03672efb-7850-47c1-8445-d6577411b0df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/12\n","32/32 [==============================] - 1s 8ms/step - loss: 2.2561 - accuracy: 0.1590 - val_loss: 1.9696 - val_accuracy: 0.4040\n","Epoch 2/12\n","32/32 [==============================] - 0s 5ms/step - loss: 1.9216 - accuracy: 0.3540 - val_loss: 1.6736 - val_accuracy: 0.5580\n","Epoch 3/12\n","32/32 [==============================] - 0s 5ms/step - loss: 1.6835 - accuracy: 0.4720 - val_loss: 1.4526 - val_accuracy: 0.5850\n","Epoch 4/12\n","32/32 [==============================] - 0s 5ms/step - loss: 1.4996 - accuracy: 0.5050 - val_loss: 1.2688 - val_accuracy: 0.6450\n","Epoch 5/12\n","32/32 [==============================] - 0s 6ms/step - loss: 1.3578 - accuracy: 0.5670 - val_loss: 1.1368 - val_accuracy: 0.6500\n","Epoch 6/12\n","32/32 [==============================] - 0s 5ms/step - loss: 1.2356 - accuracy: 0.5840 - val_loss: 1.0692 - val_accuracy: 0.6330\n","Epoch 7/12\n","32/32 [==============================] - 0s 5ms/step - loss: 1.1588 - accuracy: 0.6080 - val_loss: 0.9730 - val_accuracy: 0.6810\n","Epoch 8/12\n","32/32 [==============================] - 0s 5ms/step - loss: 1.1134 - accuracy: 0.6220 - val_loss: 0.9305 - val_accuracy: 0.6830\n","Epoch 9/12\n","32/32 [==============================] - 0s 4ms/step - loss: 1.0839 - accuracy: 0.6190 - val_loss: 0.8764 - val_accuracy: 0.7090\n","Epoch 10/12\n","32/32 [==============================] - 0s 5ms/step - loss: 0.9978 - accuracy: 0.6600 - val_loss: 0.8603 - val_accuracy: 0.6880\n","Epoch 11/12\n","32/32 [==============================] - 0s 5ms/step - loss: 0.9506 - accuracy: 0.6600 - val_loss: 0.8253 - val_accuracy: 0.6960\n","Epoch 12/12\n","32/32 [==============================] - 0s 4ms/step - loss: 0.9200 - accuracy: 0.6860 - val_loss: 0.7957 - val_accuracy: 0.7130\n"]}],"source":["single_model0 = create_compiled_keras_model()\n","history_callback0 = single_model0.fit(cifar_train_fed_data[0][0], cifar_train_fed_data[0][1], validation_data=(cifar_test_fed_data[0][0],cifar_test_fed_data[0][1]), batch_size=32, epochs=12, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1664470088512,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"giu1xcP7JOxa","outputId":"386d901a-50dc-4f02-a469-5d56e67a8c2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cifar, Ind0, IDD, minibatch_size: 32\n","NFTrain = [1.9014602899551392, 1.3196611404418945, 1.1246240139007568, 0.9741830825805664, 0.9169560670852661, 0.849628210067749, 0.8097599148750305, 0.7811322808265686, 0.7579929232597351, 0.7231773138046265, 0.6796152591705322, 0.6731991767883301]\n","NFTest = [1.51430344581604, 1.3799093961715698, 1.1188116073608398, 1.0353909730911255, 0.9489855766296387, 0.9176365733146667, 0.9156594276428223, 0.8277726173400879, 0.8556028008460999, 0.8087301850318909, 0.7861469984054565, 0.8243096470832825]\n","NFAccuracy = [0.5, 0.5099999904632568, 0.5889999866485596, 0.6420000195503235, 0.6439999938011169, 0.6769999861717224, 0.6710000038146973, 0.7110000252723694, 0.699999988079071, 0.7039999961853027, 0.7149999737739563, 0.722000002861023]\n"]}],"source":["print(\"Cifar, Ind0, IDD, minibatch_size: 32\")\n","print(\"NFTrain = {}\".format(history_callback0.history[\"loss\"]))\n","print(\"NFTest = {}\".format(history_callback0.history[\"val_loss\"]))\n","print(\"NFAccuracy = {}\".format(history_callback0.history[\"val_accuracy\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181,"status":"ok","timestamp":1665839801139,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"MKleqUI6ZIW4","outputId":"9a3f7766-0b48-4247-b499-6fc32fd75f10"},"outputs":[{"data":{"text/plain":["0.6369166697065035"]},"execution_count":104,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback0.history['val_accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1665839802655,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"tB5b88EXZH4v","outputId":"1f4ab630-8514-47f3-c098-516bf7bea86b"},"outputs":[{"data":{"text/plain":["1.170647218823433"]},"execution_count":105,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback0.history['val_loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1665839803644,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"dwgZHHU0ZHUo","outputId":"1bf393de-63e4-4d5d-ab1c-f0197bc8c5da"},"outputs":[{"data":{"text/plain":["1.3771587858597438"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback0.history['loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1665839804890,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"R1ruJ8gGZJAP","outputId":"dd2811d2-dc3b-4d82-b2de-be9fc3d4fecf"},"outputs":[{"data":{"text/plain":["0.5380833360056082"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback0.history['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"tJVfAm69N0qa"},"source":["**Client Model 2**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5643,"status":"ok","timestamp":1664470149070,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"8_sITHFNJTEw","outputId":"109f0dd2-5b38-429f-a1ac-e250e247d5ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/12\n","32/32 [==============================] - 1s 17ms/step - loss: 1.9862 - accuracy: 0.3030 - val_loss: 1.6934 - val_accuracy: 0.4190\n","Epoch 2/12\n","32/32 [==============================] - 0s 10ms/step - loss: 1.3996 - accuracy: 0.5050 - val_loss: 1.2711 - val_accuracy: 0.5290\n","Epoch 3/12\n","32/32 [==============================] - 0s 9ms/step - loss: 1.1441 - accuracy: 0.5710 - val_loss: 1.1859 - val_accuracy: 0.5840\n","Epoch 4/12\n","32/32 [==============================] - 0s 11ms/step - loss: 1.0583 - accuracy: 0.6100 - val_loss: 1.0229 - val_accuracy: 0.6230\n","Epoch 5/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9812 - accuracy: 0.6500 - val_loss: 1.0171 - val_accuracy: 0.6200\n","Epoch 6/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8976 - accuracy: 0.6820 - val_loss: 0.9499 - val_accuracy: 0.6390\n","Epoch 7/12\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8569 - accuracy: 0.6950 - val_loss: 0.8976 - val_accuracy: 0.6790\n","Epoch 8/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8332 - accuracy: 0.7160 - val_loss: 0.8960 - val_accuracy: 0.6610\n","Epoch 9/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7875 - accuracy: 0.7140 - val_loss: 0.9658 - val_accuracy: 0.6530\n","Epoch 10/12\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7356 - accuracy: 0.7400 - val_loss: 0.8080 - val_accuracy: 0.7270\n","Epoch 11/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7157 - accuracy: 0.7390 - val_loss: 0.8357 - val_accuracy: 0.6950\n","Epoch 12/12\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7138 - accuracy: 0.7500 - val_loss: 0.7991 - val_accuracy: 0.6980\n"]}],"source":["single_model1 = create_compiled_keras_model()\n","history_callback1 = single_model1.fit(cifar_train_fed_data[1][0], cifar_train_fed_data[1][1], validation_data=(cifar_test_fed_data[1][0],cifar_test_fed_data[1][1]), batch_size=32, epochs=12, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194,"status":"ok","timestamp":1664470210103,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"J-i4wYwqJdwo","outputId":"8d203bab-e1f7-4909-b365-01fda663c601"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cifar, Ind1, IDD, minibatch_size: 32\n","NFTrain = [1.9861788749694824, 1.3996175527572632, 1.1440590620040894, 1.0583235025405884, 0.9812084436416626, 0.8976032733917236, 0.856910228729248, 0.8331658244132996, 0.7874655723571777, 0.7355572581291199, 0.7156816720962524, 0.7138233184814453]\n","NFTest = [1.69338858127594, 1.2710679769515991, 1.185943365097046, 1.0228586196899414, 1.0170984268188477, 0.9498873949050903, 0.8976246118545532, 0.896026611328125, 0.9657909274101257, 0.8079548478126526, 0.8356748819351196, 0.7990831732749939]\n","NFAccuracy = [0.4189999997615814, 0.5289999842643738, 0.5839999914169312, 0.6230000257492065, 0.6200000047683716, 0.6389999985694885, 0.6790000200271606, 0.6610000133514404, 0.652999997138977, 0.7269999980926514, 0.6949999928474426, 0.6980000138282776]\n"]}],"source":["print(\"Cifar, Ind1, IDD, minibatch_size: 32\")\n","print(\"NFTrain = {}\".format(history_callback1.history[\"loss\"]))\n","print(\"NFTest = {}\".format(history_callback1.history[\"val_loss\"]))\n","print(\"NFAccuracy = {}\".format(history_callback1.history[\"val_accuracy\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1664470212703,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"vgurJNQGdx1v","outputId":"e7315c8b-d8e6-4f19-b109-726606dbc356"},"outputs":[{"data":{"text/plain":["1.0091328819592793"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback1.history['loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175,"status":"ok","timestamp":1664470214714,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"910B_fLIdx-W","outputId":"7372932b-79cd-4a20-8959-5397522050bb"},"outputs":[{"data":{"text/plain":["1.0285332848628361"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback1.history['val_loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1664470217740,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"urY2nFRidyFu","outputId":"a92b9622-da21-4c09-84d4-01a5d4d0325f"},"outputs":[{"data":{"text/plain":["0.6272500033179919"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback1.history['val_accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1664470219819,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"3BR_9rdQdyNY","outputId":"5e57e289-1cb5-4bd0-df7c-7280838b5ed3"},"outputs":[{"data":{"text/plain":["0.6395833318432173"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback1.history['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"-YWPOn7rOJUR"},"source":["**CLient Model 3**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4740,"status":"ok","timestamp":1664470228029,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"Hd8KDNtrJj4I","outputId":"5ea87495-7c8b-4b46-b308-fbe848e8117c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/12\n","32/32 [==============================] - 1s 16ms/step - loss: 1.9497 - accuracy: 0.3100 - val_loss: 1.6837 - val_accuracy: 0.4100\n","Epoch 2/12\n","32/32 [==============================] - 0s 9ms/step - loss: 1.4305 - accuracy: 0.5110 - val_loss: 1.2988 - val_accuracy: 0.5490\n","Epoch 3/12\n","32/32 [==============================] - 0s 11ms/step - loss: 1.1889 - accuracy: 0.5630 - val_loss: 1.2001 - val_accuracy: 0.5630\n","Epoch 4/12\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0496 - accuracy: 0.6430 - val_loss: 1.0787 - val_accuracy: 0.6280\n","Epoch 5/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9396 - accuracy: 0.6730 - val_loss: 0.9904 - val_accuracy: 0.6520\n","Epoch 6/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8926 - accuracy: 0.6810 - val_loss: 0.9467 - val_accuracy: 0.6570\n","Epoch 7/12\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8664 - accuracy: 0.7010 - val_loss: 0.9092 - val_accuracy: 0.6810\n","Epoch 8/12\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8220 - accuracy: 0.7110 - val_loss: 0.8602 - val_accuracy: 0.6950\n","Epoch 9/12\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7894 - accuracy: 0.7090 - val_loss: 0.8822 - val_accuracy: 0.6980\n","Epoch 10/12\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8134 - accuracy: 0.7100 - val_loss: 0.8906 - val_accuracy: 0.6840\n","Epoch 11/12\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7558 - accuracy: 0.7310 - val_loss: 0.8564 - val_accuracy: 0.7030\n","Epoch 12/12\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7198 - accuracy: 0.7530 - val_loss: 0.7912 - val_accuracy: 0.7190\n"]}],"source":["single_model2 = create_compiled_keras_model()\n","history_callback2 = single_model2.fit(cifar_train_fed_data[2][0], cifar_train_fed_data[2][1], validation_data=(cifar_test_fed_data[2][0],cifar_test_fed_data[2][1]), batch_size=32, epochs=12, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1664470231157,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"pVOkWy0JJsFY","outputId":"f916c248-1c8d-4677-c57b-548c0acf7b43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cifar, Ind2, IDD, minibatch_size: 32\n","NFTrain = [1.9496519565582275, 1.4304847717285156, 1.1888787746429443, 1.0495784282684326, 0.9396016597747803, 0.892560601234436, 0.8664304614067078, 0.8220133781433105, 0.7894057035446167, 0.8134436011314392, 0.7558480501174927, 0.7197631597518921]\n","NFTest = [1.683748483657837, 1.298822045326233, 1.200112223625183, 1.078721046447754, 0.9904460906982422, 0.9466603398323059, 0.909193217754364, 0.8602168560028076, 0.8821780681610107, 0.8905953168869019, 0.8564413785934448, 0.7912454605102539]\n","NFAccuracy = [0.4099999964237213, 0.5490000247955322, 0.5630000233650208, 0.628000020980835, 0.6520000100135803, 0.6570000052452087, 0.6809999942779541, 0.6949999928474426, 0.6980000138282776, 0.6840000152587891, 0.703000009059906, 0.718999981880188]\n"]}],"source":["print(\"Cifar, Ind2, IDD, minibatch_size: 32\")\n","print(\"NFTrain = {}\".format(history_callback2.history[\"loss\"]))\n","print(\"NFTest = {}\".format(history_callback2.history[\"val_loss\"]))\n","print(\"NFAccuracy = {}\".format(history_callback2.history[\"val_accuracy\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":930,"status":"ok","timestamp":1664470235287,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"AaNcLMMkinaY","outputId":"0dde928f-4b79-47a8-8a0b-86d13409292e"},"outputs":[{"data":{"text/plain":["1.0181383788585663"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback2.history['loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1664470237597,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"rxs4kTRYiqCI","outputId":"f0c8ca75-2e71-4f65-a4be-a446103ebfd5"},"outputs":[{"data":{"text/plain":["1.032365043958028"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback2.history['val_loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1664470239521,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"Ve8Dla6xiqj2","outputId":"0e27ac20-497a-4fa9-c180-5e8ae267c47a"},"outputs":[{"data":{"text/plain":["0.6413333316644033"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback2.history['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1664470241804,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"1DnTA0TbirFO","outputId":"ddeb82d0-606e-4c97-c790-bfe501a79366"},"outputs":[{"data":{"text/plain":["0.6365833406647047"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(history_callback2.history['val_accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"ty4Vj-WmOnmp"},"source":["**Client 1, 2, 3 Average**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWI9vkA4JwmB"},"outputs":[],"source":["SingAvTrain = (np.array(history_callback0.history[\"loss\"]) \n"," + np.array(history_callback1.history[\"loss\"]) \n"," + np.array(history_callback2.history[\"loss\"])) / 3\n","SingAvTest = (np.array(history_callback0.history[\"val_loss\"]) \n"," + np.array(history_callback1.history[\"val_loss\"]) \n"," + np.array(history_callback2.history[\"val_loss\"])) / 3\n","SingAvAcc = (np.array(history_callback0.history[\"val_accuracy\"]) \n"," + np.array(history_callback1.history[\"val_accuracy\"]) \n"," + np.array(history_callback2.history[\"val_accuracy\"])) / 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1664470277132,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"S5qu0gEVJzJJ","outputId":"2a2d381f-3e7d-4fee-e0fc-6bb6a652ae29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cifar10, SingleAverage, IDD, minibatch_size: 32\n","SingAvTrain = [1.94576371 1.38325449 1.15252062 1.02736167 0.94592206 0.87993069\n"," 0.84436687 0.81210383 0.77828807 0.75739272 0.71704833 0.70226189]\n","SingAvTest = [1.63048017 1.31659981 1.16828907 1.04565688 0.98551003 0.93806144\n"," 0.90749242 0.86133869 0.9011906  0.83576012 0.82608775 0.80487943]\n","SingAvAcc = [0.443      0.52933333 0.57866667 0.63100002 0.63866667 0.65766666\n"," 0.67700001 0.68900001 0.68366667 0.705      0.70433333 0.713     ]\n"]}],"source":["print(\"Cifar10, SingleAverage, IDD, minibatch_size: 32\")\n","print(\"SingAvTrain = {}\".format(SingAvTrain))\n","print(\"SingAvTest = {}\".format(SingAvTest))\n","print(\"SingAvAcc = {}\".format(SingAvAcc))"]},{"cell_type":"markdown","metadata":{"id":"h47c_ApqOwhp"},"source":["**Ensemble Client 1, 2, 3**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILHH6f1HKNjs"},"outputs":[],"source":["probabilities0 = single_model0.predict(cifar_test_data[0], batch_size=32, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb-9qqd5KOg7"},"outputs":[],"source":["probabilities1 = single_model1.predict(cifar_test_data[0], batch_size=32, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJPcalgSKTSF"},"outputs":[],"source":["probabilities2 = single_model2.predict(cifar_test_data[0], batch_size=32, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRLUOvVdKXl7"},"outputs":[],"source":["probs = (probabilities0 + probabilities1 + probabilities2) / 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8X96hjtLI2q"},"outputs":[],"source":["val_loss = tf.keras.losses.categorical_crossentropy(cifar_test_data[1], probs, from_logits=False)\n","print(np.mean(val_loss.numpy()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xp8PF8wLLcY"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","y_pred = probs.argmax(axis=1)\n","y_true = cifar_test_data[1].argmax(axis=1)\n","\n","accuracy_score(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"dtGXllIBPF0d"},"source":["**Cyclic weights transfer**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":695},"executionInfo":{"elapsed":3004,"status":"error","timestamp":1665736486749,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"SiC0UYBpLdrc","outputId":"146b2f29-b75c-409a-c9bb-e49acc131c88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","4/4 [==============================] - 1s 96ms/step - loss: 2.2565 - accuracy: 0.2000 - val_loss: 2.0504 - val_accuracy: 0.4120\n","Epoch 2/2\n","4/4 [==============================] - 0s 37ms/step - loss: 1.9585 - accuracy: 0.4780 - val_loss: 1.8609 - val_accuracy: 0.5110\n","Epoch 1/2\n","4/4 [==============================] - 0s 50ms/step - loss: 1.7887 - accuracy: 0.5490 - val_loss: 1.7058 - val_accuracy: 0.5327\n","Epoch 2/2\n","4/4 [==============================] - 0s 35ms/step - loss: 1.6286 - accuracy: 0.5820 - val_loss: 1.5674 - val_accuracy: 0.5717\n","Epoch 1/2\n","4/4 [==============================] - 0s 41ms/step - loss: 1.5250 - accuracy: 0.5790 - val_loss: 1.4521 - val_accuracy: 0.6190\n","Epoch 2/2\n","4/4 [==============================] - 0s 33ms/step - loss: 1.4080 - accuracy: 0.6260 - val_loss: 1.3516 - val_accuracy: 0.6443\n","Epoch 1/2\n","1/4 [======>.......................] - ETA: 0s - loss: 1.3605 - accuracy: 0.6520"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-483-85501125bfa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLIENTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         cyc_history_callback = cyc_transfer_model.fit(cifar_train_fed_data[c][0], cifar_train_fed_data[c][1], \n\u001b[0;32m----> 9\u001b[0;31m                                                      validation_data=cifar_test_data, batch_size=250, epochs=2)\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mCycTrTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_history_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mCycTrTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_history_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1218\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1221\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3121\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["cyc_transfer_model = create_compiled_keras_model()\n","CycTrTrain = []\n","CycTrTest = []\n","CycTrAcc = []\n","\n","for r in range(6):\n","    for c in range(CLIENTS):\n","        cyc_history_callback = cyc_transfer_model.fit(cifar_train_fed_data[c][0], cifar_train_fed_data[c][1], \n","                                                     validation_data=cifar_test_data, batch_size=250, epochs=2)\n","        CycTrTrain.append(cyc_history_callback.history['loss'])\n","        CycTrTest.append(cyc_history_callback.history['val_loss'])\n","        CycTrAcc.append(cyc_history_callback.history['val_accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1II4QfwhLwoY"},"outputs":[],"source":["print(\"Cifar10, Cyclic Weight Transfer, IDD, minibatch_size: 32\")\n","print(\"CycTrTrain = {}\".format(CycTrTrain))\n","print(\"CyctTrTest = {}\".format(CycTrTest))\n","print(\"CycTrAccuracy = {}\".format(CycTrAcc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWoIcfTfjod_"},"outputs":[],"source":["np.mean(cyc_history_callback.history['val_loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbjplna6jokx"},"outputs":[],"source":["np.mean(cyc_history_callback.history['loss'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRRCQOw4jorS"},"outputs":[],"source":["np.mean(cyc_history_callback.history['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4N6sO1OTjoxV"},"outputs":[],"source":["np.mean(cyc_history_callback.history['val_accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"J9TwFWqoQ_4M"},"source":["**Federated Learning**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176270,"status":"ok","timestamp":1666362014424,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"tJ_C9_HNL8bx","outputId":"b9f727f1-49be-4b43-fda4-2931275006a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 2.1102 - accuracy: 0.2760\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 1.5771 - accuracy: 0.5670\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 1.1591 - accuracy: 0.6760\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.9265 - accuracy: 0.7440\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.7981 - accuracy: 0.7720\n","Epoch 6/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.7184 - accuracy: 0.7810\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.8000\n","Epoch 8/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.8200\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.5518 - accuracy: 0.8400\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.8450\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 2.0978 - accuracy: 0.2710\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 1.5962 - accuracy: 0.5390\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 1.1817 - accuracy: 0.6650\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.9237 - accuracy: 0.7320\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.8181 - accuracy: 0.7580\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.7990\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.6568 - accuracy: 0.8130\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.8270\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.8310\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.8530\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 2.0684 - accuracy: 0.2940\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 1.4823 - accuracy: 0.5990\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 1.0656 - accuracy: 0.7200\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.8865 - accuracy: 0.7590\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.7233 - accuracy: 0.7840\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.8160\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.8120\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.8420\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.8440\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.8530\n","Epoch 1/18\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["94/94 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8943\n","94/94 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.8360\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.5635 - accuracy: 0.8360\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.8560\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.8590\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8690\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.8790\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8760\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8740\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8850\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8890\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8950\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.5686 - accuracy: 0.8420\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.8330\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.8590\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8620\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.8630\n","Epoch 6/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8840\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8830\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8970\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.9060\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.9080\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.4928 - accuracy: 0.8450\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.8580\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8740\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8710\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8920\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3425 - accuracy: 0.8940\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8910\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8970\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.9090\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.9150\n","Epoch 2/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9283\n","94/94 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8637\n","Epoch 1/10\n","32/32 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8870\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8970\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8980\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3481 - accuracy: 0.9010\n","Epoch 5/10\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.9090\n","Epoch 6/10\n","32/32 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8940\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.9100\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.9150\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2736 - accuracy: 0.9180\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2805 - accuracy: 0.9250\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.4006 - accuracy: 0.8830\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8850\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.9020\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.9050\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3089 - accuracy: 0.9100\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3051 - accuracy: 0.9220\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.9070\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2757 - accuracy: 0.9200\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.9320\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9330\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.3274 - accuracy: 0.8950\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3228 - accuracy: 0.9040\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2744 - accuracy: 0.9180\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2995 - accuracy: 0.9130\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2701 - accuracy: 0.9140\n","Epoch 6/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.9230\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9210\n","Epoch 8/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.9240\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.9280\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2337 - accuracy: 0.9300\n","Epoch 3/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9417\n","94/94 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8770\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.3272 - accuracy: 0.9070\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.9260\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.9280\n","Epoch 4/10\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.9170\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.9280\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.9150\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2542 - accuracy: 0.9210\n","Epoch 8/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2175 - accuracy: 0.9350\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9360\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2239 - accuracy: 0.9350\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.3155 - accuracy: 0.9100\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.9140\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.9230\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2470 - accuracy: 0.9170\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2438 - accuracy: 0.9310\n","Epoch 6/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2438 - accuracy: 0.9390\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2577 - accuracy: 0.9280\n","Epoch 8/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2203 - accuracy: 0.9340\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2236 - accuracy: 0.9480\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2106 - accuracy: 0.9460\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.2468 - accuracy: 0.9250\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2530 - accuracy: 0.9300\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2084 - accuracy: 0.9400\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2311 - accuracy: 0.9310\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.9360\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.9430\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2006 - accuracy: 0.9410\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1987 - accuracy: 0.9420\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1730 - accuracy: 0.9440\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1858 - accuracy: 0.9470\n","Epoch 4/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9530\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8863\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.2729 - accuracy: 0.9210\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2337 - accuracy: 0.9370\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2331 - accuracy: 0.9420\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2270 - accuracy: 0.9340\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2153 - accuracy: 0.9380\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2032 - accuracy: 0.9320\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2102 - accuracy: 0.9350\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9460\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1778 - accuracy: 0.9510\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1821 - accuracy: 0.9480\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.2575 - accuracy: 0.9290\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2303 - accuracy: 0.9380\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2271 - accuracy: 0.9370\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2020 - accuracy: 0.9320\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 0.9480\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2016 - accuracy: 0.9450\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9410\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1811 - accuracy: 0.9490\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1842 - accuracy: 0.9540\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1732 - accuracy: 0.9580\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.1957 - accuracy: 0.9410\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.9460\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9550\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.9500\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9530\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.9540\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1603 - accuracy: 0.9520\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.9570\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1378 - accuracy: 0.9600\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1518 - accuracy: 0.9560\n","Epoch 5/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9600\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8917\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.2293 - accuracy: 0.9310\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1926 - accuracy: 0.9450\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1934 - accuracy: 0.9500\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9470\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1771 - accuracy: 0.9460\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9530\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1762 - accuracy: 0.9390\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1437 - accuracy: 0.9590\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1461 - accuracy: 0.9610\n","Epoch 10/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1504 - accuracy: 0.9620\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.2141 - accuracy: 0.9430\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.9500\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9520\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1672 - accuracy: 0.9480\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1675 - accuracy: 0.9590\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9520\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1803 - accuracy: 0.9490\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.9590\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9600\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.9650\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1594 - accuracy: 0.9570\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1713 - accuracy: 0.9560\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9640\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.9610\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1394 - accuracy: 0.9620\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9640\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.9590\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.9620\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9700\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1257 - accuracy: 0.9610\n","Epoch 6/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9687\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8950\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1935 - accuracy: 0.9440\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1598 - accuracy: 0.9530\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.9550\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1564 - accuracy: 0.9550\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9550\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9590\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9520\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1184 - accuracy: 0.9670\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1221 - accuracy: 0.9650\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9670\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1796 - accuracy: 0.9560\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9580\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1591 - accuracy: 0.9620\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1403 - accuracy: 0.9620\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1431 - accuracy: 0.9670\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1455 - accuracy: 0.9590\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.9570\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9640\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9650\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9720\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1325 - accuracy: 0.9670\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1431 - accuracy: 0.9620\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.9690\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9700\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9640\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9730\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.9680\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9760\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9800\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1053 - accuracy: 0.9700\n","Epoch 7/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9710\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8990\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1635 - accuracy: 0.9500\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1325 - accuracy: 0.9630\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9620\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1303 - accuracy: 0.9630\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9750\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9680\n","Epoch 7/10\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1271 - accuracy: 0.9620\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9790\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9700\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9740\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1512 - accuracy: 0.9610\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1306 - accuracy: 0.9660\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.9700\n","Epoch 4/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9700\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9750\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1251 - accuracy: 0.9690\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9670\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.9680\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.9700\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9800\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.1112 - accuracy: 0.9710\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9660\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9720\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9760\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9750\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9760\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9760\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9790\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9870\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0890 - accuracy: 0.9790\n","Epoch 8/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9737\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.9010\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1381 - accuracy: 0.9590\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1105 - accuracy: 0.9740\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.9720\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9690\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9790\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9760\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9700\n","Epoch 8/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9850\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9790\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.9820\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.1277 - accuracy: 0.9670\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9740\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.9720\n","Epoch 4/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0991 - accuracy: 0.9770\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9790\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9750\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9720\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9750\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0951 - accuracy: 0.9760\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.9840\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0947 - accuracy: 0.9760\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.9740\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0801 - accuracy: 0.9760\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9790\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9770\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0810 - accuracy: 0.9760\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9820\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9830\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9870\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9820\n","Epoch 9/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9797\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.9040\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.9640\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9760\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9740\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9730\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9840\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9820\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9770\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 0.9870\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9840\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0773 - accuracy: 0.9850\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.1084 - accuracy: 0.9730\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.9790\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0978 - accuracy: 0.9730\n","Epoch 4/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9820\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9840\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0932 - accuracy: 0.9800\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9740\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9780\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9790\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9850\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9820\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9780\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9850\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9810\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9820\n","Epoch 6/10\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0697 - accuracy: 0.9810\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9840\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9870\n","Epoch 9/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9910\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9860\n","Epoch 10/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9837\n","94/94 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.9047\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0988 - accuracy: 0.9700\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9810\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9790\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9820\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9850\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.9840\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9800\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9910\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9870\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9890\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0913 - accuracy: 0.9790\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 0.9840\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9810\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9890\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9860\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9820\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9800\n","Epoch 8/10\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0697 - accuracy: 0.9820\n","Epoch 9/10\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0697 - accuracy: 0.9840\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9870\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0699 - accuracy: 0.9820\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0740 - accuracy: 0.9830\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9880\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9840\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9850\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9850\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9890\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9900\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9930\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9880\n","Epoch 11/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9860\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.9053\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0839 - accuracy: 0.9790\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9860\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9850\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.9860\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.9880\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9890\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9830\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9950\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9890\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9900\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9800\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.9860\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.9830\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9900\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9890\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9860\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9830\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9850\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9850\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 0.9910\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 0.9870\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9870\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9930\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9860\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9870\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9880\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9950\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9930\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9960\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9900\n","Epoch 12/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9883\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.9073\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0715 - accuracy: 0.9830\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9880\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9880\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0582 - accuracy: 0.9880\n","Epoch 5/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9900\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9920\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9850\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9980\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9910\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9910\n","Epoch 1/10\n","32/32 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9830\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9890\n","Epoch 3/10\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9870\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9940\n","Epoch 5/10\n","32/32 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9920\n","Epoch 6/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9880\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9860\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0531 - accuracy: 0.9870\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9920\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9920\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0526 - accuracy: 0.9870\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9890\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 0.9960\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9900\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 0.9900\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9900\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9970\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.9930\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9960\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9930\n","Epoch 13/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9893\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.9067\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0609 - accuracy: 0.9880\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0476 - accuracy: 0.9900\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9900\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9910\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9950\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9940\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9860\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9980\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0405 - accuracy: 0.9920\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9930\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0558 - accuracy: 0.9860\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9920\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9910\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9960\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9940\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9910\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9890\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9880\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9930\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0423 - accuracy: 0.9930\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9900\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0470 - accuracy: 0.9920\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9960\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9940\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9950\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9930\n","Epoch 7/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9970\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9950\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9970\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9960\n","Epoch 14/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9910\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.9077\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0524 - accuracy: 0.9890\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9930\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9900\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9920\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9990\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9950\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9890\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9990\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9920\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9940\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0479 - accuracy: 0.9900\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0415 - accuracy: 0.9960\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9930\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9960\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9940\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9920\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.9920\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9900\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9970\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9940\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0400 - accuracy: 0.9910\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9920\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9960\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9950\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9970\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9950\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9970\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0372 - accuracy: 0.9950\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.9970\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9970\n","Epoch 15/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9913\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.9087\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0451 - accuracy: 0.9890\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9940\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9910\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9940\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9960\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9900\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9990\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9940\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9950\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9920\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9960\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9940\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9970\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9940\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9960\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9940\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9930\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9970\n","Epoch 10/10\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9960\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0351 - accuracy: 0.9940\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9930\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9970\n","Epoch 4/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9960\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9970\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9950\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9980\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9960\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 0.9980\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9970\n","Epoch 16/18\n","94/94 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9933\n","94/94 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.9093\n","Epoch 1/10\n","32/32 [==============================] - 1s 5ms/step - loss: 0.0392 - accuracy: 0.9930\n","Epoch 2/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9950\n","Epoch 3/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9930\n","Epoch 4/10\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9950\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0314 - accuracy: 0.9980\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9930\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9970\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9960\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9930\n","Epoch 2/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9980\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9960\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9970\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9940\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9960\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9950\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9930\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9990\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9960\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0310 - accuracy: 0.9950\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9960\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9970\n","Epoch 4/10\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9970\n","Epoch 5/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9980\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.9960\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9980\n","Epoch 8/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9970\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 0.9990\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9970\n","Epoch 17/18\n","94/94 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9940\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.9097\n","Epoch 1/10\n","32/32 [==============================] - 1s 6ms/step - loss: 0.0343 - accuracy: 0.9950\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9970\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9950\n","Epoch 4/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 0.9960\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 1.0000\n","Epoch 6/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9980\n","Epoch 7/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9940\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 1.0000\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9990\n","Epoch 10/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9970\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9940\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9990\n","Epoch 3/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9970\n","Epoch 4/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9980\n","Epoch 5/10\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9940\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9960\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9970\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9950\n","Epoch 9/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9990\n","Epoch 10/10\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9970\n","Epoch 1/10\n","32/32 [==============================] - 1s 7ms/step - loss: 0.0274 - accuracy: 0.9950\n","Epoch 2/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9970\n","Epoch 3/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9990\n","Epoch 4/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9980\n","Epoch 5/10\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9990\n","Epoch 6/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9960\n","Epoch 7/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9980\n","Epoch 8/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9970\n","Epoch 9/10\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 1.0000\n","Epoch 10/10\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9970\n","Epoch 18/18\n","94/94 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9943\n","94/94 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.9100\n"]}],"source":["initial_model = create_compiled_keras_model()\n","\n","FedTrain = []\n","FedTest = []\n","FedAcc = []\n","\n","for r in range(18):\n","    \n","    deltas = []\n","\n","    for c in range(CLIENTS):\n","\n","        federated_model = create_compiled_keras_model()\n","\n","        federated_model.set_weights(initial_model.get_weights())\n","\n","        #fed_history_callback = federated_model.fit(cifar_train_fed_data[c][0], cifar_train_fed_data[c][1], \n","         #                                      batch_size=250, epochs=10, verbose=1)\n","        fed_history_callback = federated_model.fit(cifar_train_fed_data[c][0], cifar_train_fed_data[c][1], \n","                                               batch_size=32, epochs=10, verbose=1)\n","        \n","        delta = np.array(initial_model.get_weights()) - np.array(federated_model.get_weights())\n","\n","        deltas.append(delta)\n","\n","    print('Epoch {}/18'.format(r+1))\n","    delt_av = (deltas[0] + deltas[1] + deltas[2]) / 3\n","    new_weights = np.array(initial_model.get_weights()) - delt_av\n","    initial_model.set_weights(new_weights)\n","    \n","    FedTrain.append(initial_model.evaluate(cifar_train_data[0], cifar_train_data[1])[0])\n","    validation = initial_model.evaluate(cifar_test_data[0], cifar_test_data[1])\n","    FedTest.append(validation[0])\n","    FedAcc.append(validation[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1665735308122,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"A_NGnWAEMFzY","outputId":"3cc61639-c464-454a-8ee0-1744d144ed94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cifar10, Federated Model, IDD, minibatch_size: 32\n","FedTrainE1B32 = [0.7653372287750244, 0.6447807550430298, 0.5594501495361328, 0.5159481763839722, 0.48933088779449463, 0.47777387499809265, 0.4527234435081482, 0.42836475372314453, 0.43077874183654785, 0.4214622676372528, 0.3945649266242981, 0.3840550482273102, 0.37192031741142273, 0.39494067430496216, 0.3889222741127014, 0.38954827189445496, 0.37211740016937256, 0.36124077439308167]\n","FedTestE1B32 = [0.8164638876914978, 0.6907883882522583, 0.6424153447151184, 0.6243432760238647, 0.6035233736038208, 0.5930613875389099, 0.5982313752174377, 0.5946306586265564, 0.5892373323440552, 0.6013940572738647, 0.6134033799171448, 0.615780234336853, 0.618308961391449, 0.6216452121734619, 0.6489428281784058, 0.636356770992279, 0.6571195721626282, 0.7057194113731384]\n","FedAccuracyE1B32 = [0.7089999914169312, 0.7526666522026062, 0.7736666798591614, 0.7839999794960022, 0.7916666865348816, 0.8033333420753479, 0.7903333306312561, 0.7983333468437195, 0.8056666851043701, 0.8019999861717224, 0.7976666688919067, 0.8009999990463257, 0.8080000281333923, 0.8083333373069763, 0.8050000071525574, 0.8090000152587891, 0.8013333082199097, 0.7973333597183228]\n"]}],"source":["print(\"Cifar10, Federated Model, IDD, minibatch_size: 32\")\n","print(\"FedTrainE1B32 = {}\".format(FedTrain))\n","print(\"FedTestE1B32 = {}\".format(FedTest))\n","print(\"FedAccuracyE1B32 = {}\".format(FedAcc))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1666361826997,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"_BMQk2yc1XSE","outputId":"e5c16bd8-1c22-47b7-abc0-a73fd4d5e820"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.10574339568201038"]},"metadata":{},"execution_count":82}],"source":["np.mean(FedTrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666361828467,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"8tfOPfqd1YCr","outputId":"6ec06cc1-3ca7-4c9d-8009-24b832337c52"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.36160406470298767"]},"metadata":{},"execution_count":83}],"source":["np.mean(FedTest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666361830516,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"gUrTs-G51Yk7","outputId":"a83eee45-d146-460b-e69b-43c9d25ef147"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8930555482705435"]},"metadata":{},"execution_count":84}],"source":["np.mean(FedAcc)"]},{"cell_type":"markdown","metadata":{"id":"YyBZwA5_REzZ"},"source":["**Membership Inference Attack**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gX6qOzPwx_G"},"outputs":[],"source":["import numpy as np\n","\n","from absl import app\n","from absl import flags\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from mia.estimators import ShadowModelBundle, AttackModelBundle, prepare_attack_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdKUQDjsxC-s"},"outputs":[],"source":["NUM_CLASSES = 10\n","\n","SHADOW_DATASET_SIZE = 1000\n","ATTACK_TEST_DATASET_SIZE = 5000\n","\n","num_shadows = 10\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5g9mhNCyw-Y"},"outputs":[],"source":["def target_model_fn():\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape=[28, 28, 1]),\n","        tf.keras.layers.Dropout(0.2),\n","        #tf.keras.layers.AlphaDropout(rate=0.2),\n","        #tf.keras.layers.GaussianNoise(0.2),\n","        #tf.keras.layers.GaussianDropout(0.2),\n","        tf.keras.layers.Dense(300, activation=\"relu\"),\n","        tf.keras.layers.Dropout(0.2),\n","        #tf.keras.layers.AlphaDropout(rate=0.2),\n","        #tf.keras.layers.GaussianNoise(0.2),\n","        #tf.keras.layers.GaussianDropout(0.2),\n","        tf.keras.layers.Dense(100, activation=\"relu\"),\n","        tf.keras.layers.Dropout(0.2),\n","        #tf.keras.layers.AlphaDropout(rate=0.2),\n","        #tf.keras.layers.GaussianNoise(0.2),\n","        #tf.keras.layers.GaussianDropout(0.2),\n","        tf.keras.layers.Dense(10, activation=\"softmax\")\n","    ])\n","    #mc_model = tf.keras.models.Sequential([\n","        #MCAlphaDropout(layer.rate) if isinstance(layer, tf.keras.layers.AlphaDropout) else layer\n","        #for layer in model.layers\n","    #])\n","    #mc_model = tf.keras.models.Sequential([\n","        #MCDropout(layer.rate) if isinstance(layer, tf.keras.layers.Dropout) else layer\n","        #for layer in model.layers\n","    #])\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","    model.compile(loss=loss,\n","              optimizer = tf.keras.optimizers.SGD(learning_rate=0.01),\n","              metrics=[\"accuracy\"])\n","    #return mc_model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTcWPScpHFOV"},"outputs":[],"source":["def attack_model_fn():\n","    model = tf.keras.models.Sequential()\n","\n","    model.add(layers.Dense(64, activation=\"relu\", input_shape=(10,)))\n","    model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n","    model.add(layers.Dense(32, activation=\"relu\"))\n","    model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n","    model.add(layers.Dense(32, activation=\"relu\"))\n","    model.add(layers.Dense(1, activation=\"sigmoid\"))\n","    model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuaROtyYz6Yv"},"outputs":[],"source":["#target_model = federated_model\n","target_model = single_model0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157640,"status":"ok","timestamp":1665840042230,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"-WSpBpeDyYUz","outputId":"f77de143-b1ba-41fe-9dac-25fbfd13e45b"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5000, 28, 28, 1) (5000, 28, 28, 1)\n","Training the shadow models...\n","Epoch 1/32\n","32/32 [==============================] - 1s 17ms/step - loss: 2.2018 - accuracy: 0.2310 - val_loss: 1.8801 - val_accuracy: 0.4726\n","Epoch 2/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.8636 - accuracy: 0.3970 - val_loss: 1.5972 - val_accuracy: 0.5144\n","Epoch 3/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.6096 - accuracy: 0.4850 - val_loss: 1.3609 - val_accuracy: 0.6028\n","Epoch 4/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.4680 - accuracy: 0.5070 - val_loss: 1.2137 - val_accuracy: 0.6050\n","Epoch 5/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.3363 - accuracy: 0.5570 - val_loss: 1.1072 - val_accuracy: 0.6544\n","Epoch 6/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2436 - accuracy: 0.5650 - val_loss: 1.0531 - val_accuracy: 0.6214\n","Epoch 7/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.1800 - accuracy: 0.5850 - val_loss: 0.9729 - val_accuracy: 0.6834\n","Epoch 8/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.1232 - accuracy: 0.6090 - val_loss: 0.9241 - val_accuracy: 0.7048\n","Epoch 9/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0491 - accuracy: 0.6390 - val_loss: 0.8836 - val_accuracy: 0.6990\n","Epoch 10/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0640 - accuracy: 0.6160 - val_loss: 0.8568 - val_accuracy: 0.7132\n","Epoch 11/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9992 - accuracy: 0.6430 - val_loss: 0.8356 - val_accuracy: 0.7108\n","Epoch 12/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9782 - accuracy: 0.6600 - val_loss: 0.8264 - val_accuracy: 0.7108\n","Epoch 13/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9615 - accuracy: 0.6470 - val_loss: 0.8194 - val_accuracy: 0.7214\n","Epoch 14/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.9181 - accuracy: 0.6780 - val_loss: 0.8058 - val_accuracy: 0.7222\n","Epoch 15/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9073 - accuracy: 0.6770 - val_loss: 0.7783 - val_accuracy: 0.7146\n","Epoch 16/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9000 - accuracy: 0.6880 - val_loss: 0.7700 - val_accuracy: 0.7320\n","Epoch 17/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8721 - accuracy: 0.6990 - val_loss: 0.7574 - val_accuracy: 0.7326\n","Epoch 18/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8329 - accuracy: 0.7090 - val_loss: 0.7492 - val_accuracy: 0.7256\n","Epoch 19/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8359 - accuracy: 0.7000 - val_loss: 0.7376 - val_accuracy: 0.7280\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8101 - accuracy: 0.7150 - val_loss: 0.7227 - val_accuracy: 0.7396\n","Epoch 21/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7870 - accuracy: 0.7380 - val_loss: 0.7109 - val_accuracy: 0.7396\n","Epoch 22/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7870 - accuracy: 0.7340 - val_loss: 0.7082 - val_accuracy: 0.7438\n","Epoch 23/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7797 - accuracy: 0.7380 - val_loss: 0.7163 - val_accuracy: 0.7308\n","Epoch 24/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7868 - accuracy: 0.7290 - val_loss: 0.7111 - val_accuracy: 0.7340\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7663 - accuracy: 0.7340 - val_loss: 0.7051 - val_accuracy: 0.7382\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7655 - accuracy: 0.7340 - val_loss: 0.7056 - val_accuracy: 0.7330\n","Epoch 27/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7767 - accuracy: 0.7350 - val_loss: 0.6916 - val_accuracy: 0.7486\n","Epoch 28/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7505 - accuracy: 0.7480 - val_loss: 0.6891 - val_accuracy: 0.7488\n","Epoch 29/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7253 - accuracy: 0.7560 - val_loss: 0.6872 - val_accuracy: 0.7488\n","Epoch 30/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7265 - accuracy: 0.7550 - val_loss: 0.6744 - val_accuracy: 0.7528\n","Epoch 31/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7250 - accuracy: 0.7630 - val_loss: 0.6628 - val_accuracy: 0.7592\n","Epoch 32/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7205 - accuracy: 0.7470 - val_loss: 0.6564 - val_accuracy: 0.7590\n","Epoch 1/32\n","32/32 [==============================] - 1s 16ms/step - loss: 2.2556 - accuracy: 0.1690 - val_loss: 1.9746 - val_accuracy: 0.4482\n","Epoch 2/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.9318 - accuracy: 0.3310 - val_loss: 1.6783 - val_accuracy: 0.5154\n","Epoch 3/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.6717 - accuracy: 0.4320 - val_loss: 1.4458 - val_accuracy: 0.5798\n","Epoch 4/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.5221 - accuracy: 0.4820 - val_loss: 1.2869 - val_accuracy: 0.5938\n","Epoch 5/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.3581 - accuracy: 0.5450 - val_loss: 1.1685 - val_accuracy: 0.6144\n","Epoch 6/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2979 - accuracy: 0.5320 - val_loss: 1.0776 - val_accuracy: 0.6426\n","Epoch 7/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.1948 - accuracy: 0.5860 - val_loss: 1.0345 - val_accuracy: 0.6352\n","Epoch 8/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1725 - accuracy: 0.5990 - val_loss: 0.9968 - val_accuracy: 0.6370\n","Epoch 9/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0847 - accuracy: 0.6120 - val_loss: 0.9404 - val_accuracy: 0.6514\n","Epoch 10/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0444 - accuracy: 0.6200 - val_loss: 0.9088 - val_accuracy: 0.6700\n","Epoch 11/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.0239 - accuracy: 0.6170 - val_loss: 0.8805 - val_accuracy: 0.6772\n","Epoch 12/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9673 - accuracy: 0.6530 - val_loss: 0.8547 - val_accuracy: 0.6826\n","Epoch 13/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9626 - accuracy: 0.6520 - val_loss: 0.8707 - val_accuracy: 0.6748\n","Epoch 14/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9550 - accuracy: 0.6700 - val_loss: 0.8306 - val_accuracy: 0.6848\n","Epoch 15/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9233 - accuracy: 0.6650 - val_loss: 0.8097 - val_accuracy: 0.6964\n","Epoch 16/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.9224 - accuracy: 0.6920 - val_loss: 0.7962 - val_accuracy: 0.7126\n","Epoch 17/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.9029 - accuracy: 0.6850 - val_loss: 0.7928 - val_accuracy: 0.6998\n","Epoch 18/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8658 - accuracy: 0.7090 - val_loss: 0.7740 - val_accuracy: 0.7120\n","Epoch 19/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8705 - accuracy: 0.6820 - val_loss: 0.7698 - val_accuracy: 0.7174\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8365 - accuracy: 0.7170 - val_loss: 0.7631 - val_accuracy: 0.7242\n","Epoch 21/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8118 - accuracy: 0.7240 - val_loss: 0.7625 - val_accuracy: 0.7164\n","Epoch 22/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8334 - accuracy: 0.6900 - val_loss: 0.7405 - val_accuracy: 0.7344\n","Epoch 23/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8129 - accuracy: 0.7120 - val_loss: 0.7431 - val_accuracy: 0.7248\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7594 - accuracy: 0.7380 - val_loss: 0.7249 - val_accuracy: 0.7312\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8029 - accuracy: 0.7210 - val_loss: 0.7176 - val_accuracy: 0.7456\n","Epoch 26/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7747 - accuracy: 0.7350 - val_loss: 0.7145 - val_accuracy: 0.7446\n","Epoch 27/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7465 - accuracy: 0.7470 - val_loss: 0.7111 - val_accuracy: 0.7384\n","Epoch 28/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7351 - accuracy: 0.7440 - val_loss: 0.7118 - val_accuracy: 0.7372\n","Epoch 29/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7328 - accuracy: 0.7420 - val_loss: 0.6920 - val_accuracy: 0.7496\n","Epoch 30/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7092 - accuracy: 0.7580 - val_loss: 0.6866 - val_accuracy: 0.7506\n","Epoch 31/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7320 - accuracy: 0.7440 - val_loss: 0.6903 - val_accuracy: 0.7444\n","Epoch 32/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7230 - accuracy: 0.7620 - val_loss: 0.6777 - val_accuracy: 0.7528\n","Epoch 1/32\n","32/32 [==============================] - 1s 13ms/step - loss: 2.2089 - accuracy: 0.1620 - val_loss: 1.9495 - val_accuracy: 0.4056\n","Epoch 2/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.9168 - accuracy: 0.3520 - val_loss: 1.6675 - val_accuracy: 0.5320\n","Epoch 3/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.6973 - accuracy: 0.4410 - val_loss: 1.4468 - val_accuracy: 0.5644\n","Epoch 4/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.4793 - accuracy: 0.5000 - val_loss: 1.2563 - val_accuracy: 0.6066\n","Epoch 5/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.3819 - accuracy: 0.5410 - val_loss: 1.1794 - val_accuracy: 0.6114\n","Epoch 6/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.2890 - accuracy: 0.5490 - val_loss: 1.0519 - val_accuracy: 0.6612\n","Epoch 7/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.1819 - accuracy: 0.6140 - val_loss: 0.9989 - val_accuracy: 0.6526\n","Epoch 8/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1574 - accuracy: 0.5980 - val_loss: 0.9645 - val_accuracy: 0.6600\n","Epoch 9/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0878 - accuracy: 0.5970 - val_loss: 0.9266 - val_accuracy: 0.6742\n","Epoch 10/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.0608 - accuracy: 0.6190 - val_loss: 0.8960 - val_accuracy: 0.6656\n","Epoch 11/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0285 - accuracy: 0.6390 - val_loss: 0.8716 - val_accuracy: 0.6876\n","Epoch 12/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0037 - accuracy: 0.6260 - val_loss: 0.8651 - val_accuracy: 0.6662\n","Epoch 13/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0070 - accuracy: 0.6260 - val_loss: 0.8284 - val_accuracy: 0.6916\n","Epoch 14/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9664 - accuracy: 0.6510 - val_loss: 0.8361 - val_accuracy: 0.6876\n","Epoch 15/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9209 - accuracy: 0.6660 - val_loss: 0.8023 - val_accuracy: 0.6982\n","Epoch 16/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.9333 - accuracy: 0.6680 - val_loss: 0.7984 - val_accuracy: 0.6994\n","Epoch 17/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9303 - accuracy: 0.6640 - val_loss: 0.7873 - val_accuracy: 0.7120\n","Epoch 18/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8933 - accuracy: 0.6950 - val_loss: 0.7686 - val_accuracy: 0.7172\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8711 - accuracy: 0.6920 - val_loss: 0.7591 - val_accuracy: 0.7202\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8441 - accuracy: 0.7020 - val_loss: 0.7745 - val_accuracy: 0.7130\n","Epoch 21/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8567 - accuracy: 0.6950 - val_loss: 0.7664 - val_accuracy: 0.7176\n","Epoch 22/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8301 - accuracy: 0.7070 - val_loss: 0.7519 - val_accuracy: 0.7354\n","Epoch 23/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8261 - accuracy: 0.7110 - val_loss: 0.7321 - val_accuracy: 0.7456\n","Epoch 24/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8091 - accuracy: 0.7370 - val_loss: 0.7260 - val_accuracy: 0.7322\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7850 - accuracy: 0.7230 - val_loss: 0.7305 - val_accuracy: 0.7408\n","Epoch 26/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.7906 - accuracy: 0.7250 - val_loss: 0.7117 - val_accuracy: 0.7484\n","Epoch 27/32\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7803 - accuracy: 0.7260 - val_loss: 0.7042 - val_accuracy: 0.7520\n","Epoch 28/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.7606 - accuracy: 0.7310 - val_loss: 0.6918 - val_accuracy: 0.7538\n","Epoch 29/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7636 - accuracy: 0.7510 - val_loss: 0.7015 - val_accuracy: 0.7502\n","Epoch 30/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7260 - accuracy: 0.7450 - val_loss: 0.6895 - val_accuracy: 0.7524\n","Epoch 31/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7344 - accuracy: 0.7470 - val_loss: 0.7128 - val_accuracy: 0.7410\n","Epoch 32/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7335 - accuracy: 0.7590 - val_loss: 0.6888 - val_accuracy: 0.7548\n","Epoch 1/32\n","32/32 [==============================] - 1s 13ms/step - loss: 2.2502 - accuracy: 0.1640 - val_loss: 1.9861 - val_accuracy: 0.3728\n","Epoch 2/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.9346 - accuracy: 0.3440 - val_loss: 1.6981 - val_accuracy: 0.4306\n","Epoch 3/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.7006 - accuracy: 0.4160 - val_loss: 1.4746 - val_accuracy: 0.5482\n","Epoch 4/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.5397 - accuracy: 0.4780 - val_loss: 1.3009 - val_accuracy: 0.6102\n","Epoch 5/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.4001 - accuracy: 0.5110 - val_loss: 1.1859 - val_accuracy: 0.5852\n","Epoch 6/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.3004 - accuracy: 0.5450 - val_loss: 1.0932 - val_accuracy: 0.6382\n","Epoch 7/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2262 - accuracy: 0.5760 - val_loss: 1.0337 - val_accuracy: 0.6440\n","Epoch 8/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1474 - accuracy: 0.6090 - val_loss: 0.9728 - val_accuracy: 0.6512\n","Epoch 9/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.1178 - accuracy: 0.6060 - val_loss: 0.9570 - val_accuracy: 0.6474\n","Epoch 10/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0557 - accuracy: 0.6240 - val_loss: 0.9132 - val_accuracy: 0.6732\n","Epoch 11/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9881 - accuracy: 0.6480 - val_loss: 0.8754 - val_accuracy: 0.6998\n","Epoch 12/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.0030 - accuracy: 0.6360 - val_loss: 0.8533 - val_accuracy: 0.6936\n","Epoch 13/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9793 - accuracy: 0.6540 - val_loss: 0.8553 - val_accuracy: 0.6840\n","Epoch 14/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9508 - accuracy: 0.6540 - val_loss: 0.8184 - val_accuracy: 0.7076\n","Epoch 15/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9286 - accuracy: 0.6830 - val_loss: 0.8135 - val_accuracy: 0.7004\n","Epoch 16/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8749 - accuracy: 0.6970 - val_loss: 0.7905 - val_accuracy: 0.7136\n","Epoch 17/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9059 - accuracy: 0.6840 - val_loss: 0.7813 - val_accuracy: 0.7106\n","Epoch 18/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8440 - accuracy: 0.7120 - val_loss: 0.7911 - val_accuracy: 0.7010\n","Epoch 19/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8557 - accuracy: 0.7030 - val_loss: 0.7882 - val_accuracy: 0.7026\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8457 - accuracy: 0.7030 - val_loss: 0.7557 - val_accuracy: 0.7212\n","Epoch 21/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8308 - accuracy: 0.7080 - val_loss: 0.7544 - val_accuracy: 0.7242\n","Epoch 22/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8147 - accuracy: 0.7090 - val_loss: 0.7292 - val_accuracy: 0.7384\n","Epoch 23/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8264 - accuracy: 0.7130 - val_loss: 0.7315 - val_accuracy: 0.7374\n","Epoch 24/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8139 - accuracy: 0.7170 - val_loss: 0.7204 - val_accuracy: 0.7430\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8002 - accuracy: 0.7220 - val_loss: 0.7127 - val_accuracy: 0.7390\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7674 - accuracy: 0.7280 - val_loss: 0.7244 - val_accuracy: 0.7376\n","Epoch 27/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7617 - accuracy: 0.7100 - val_loss: 0.6996 - val_accuracy: 0.7474\n","Epoch 28/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7368 - accuracy: 0.7400 - val_loss: 0.6939 - val_accuracy: 0.7442\n","Epoch 29/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7576 - accuracy: 0.7290 - val_loss: 0.6980 - val_accuracy: 0.7482\n","Epoch 30/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7165 - accuracy: 0.7310 - val_loss: 0.6928 - val_accuracy: 0.7414\n","Epoch 31/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7245 - accuracy: 0.7530 - val_loss: 0.6803 - val_accuracy: 0.7524\n","Epoch 32/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.7074 - accuracy: 0.7420 - val_loss: 0.6885 - val_accuracy: 0.7492\n","Epoch 1/32\n","32/32 [==============================] - 1s 16ms/step - loss: 2.1895 - accuracy: 0.1760 - val_loss: 1.9543 - val_accuracy: 0.4084\n","Epoch 2/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.9165 - accuracy: 0.3390 - val_loss: 1.6541 - val_accuracy: 0.5766\n","Epoch 3/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.6802 - accuracy: 0.4500 - val_loss: 1.4183 - val_accuracy: 0.6178\n","Epoch 4/32\n","32/32 [==============================] - 0s 11ms/step - loss: 1.4935 - accuracy: 0.4930 - val_loss: 1.2529 - val_accuracy: 0.6306\n","Epoch 5/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.3549 - accuracy: 0.5430 - val_loss: 1.1321 - val_accuracy: 0.6308\n","Epoch 6/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.3011 - accuracy: 0.5570 - val_loss: 1.0679 - val_accuracy: 0.6268\n","Epoch 7/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1625 - accuracy: 0.5850 - val_loss: 1.0018 - val_accuracy: 0.6496\n","Epoch 8/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1265 - accuracy: 0.5950 - val_loss: 0.9529 - val_accuracy: 0.6530\n","Epoch 9/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0961 - accuracy: 0.6190 - val_loss: 0.9115 - val_accuracy: 0.6694\n","Epoch 10/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0521 - accuracy: 0.6250 - val_loss: 0.8864 - val_accuracy: 0.6806\n","Epoch 11/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0116 - accuracy: 0.6430 - val_loss: 0.8671 - val_accuracy: 0.6768\n","Epoch 12/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.9874 - accuracy: 0.6610 - val_loss: 0.8523 - val_accuracy: 0.6798\n","Epoch 13/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9489 - accuracy: 0.6580 - val_loss: 0.8297 - val_accuracy: 0.6868\n","Epoch 14/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9703 - accuracy: 0.6440 - val_loss: 0.8201 - val_accuracy: 0.6906\n","Epoch 15/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9281 - accuracy: 0.6550 - val_loss: 0.7957 - val_accuracy: 0.7024\n","Epoch 16/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8915 - accuracy: 0.6810 - val_loss: 0.7809 - val_accuracy: 0.7042\n","Epoch 17/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8917 - accuracy: 0.6800 - val_loss: 0.7768 - val_accuracy: 0.7140\n","Epoch 18/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.8922 - accuracy: 0.6750 - val_loss: 0.7714 - val_accuracy: 0.7070\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8235 - accuracy: 0.7050 - val_loss: 0.7580 - val_accuracy: 0.7220\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8376 - accuracy: 0.7120 - val_loss: 0.7509 - val_accuracy: 0.7274\n","Epoch 21/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8372 - accuracy: 0.7000 - val_loss: 0.7354 - val_accuracy: 0.7254\n","Epoch 22/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8354 - accuracy: 0.6890 - val_loss: 0.7346 - val_accuracy: 0.7298\n","Epoch 23/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8009 - accuracy: 0.7070 - val_loss: 0.7269 - val_accuracy: 0.7354\n","Epoch 24/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8214 - accuracy: 0.7100 - val_loss: 0.7572 - val_accuracy: 0.7180\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7746 - accuracy: 0.7180 - val_loss: 0.7282 - val_accuracy: 0.7364\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7867 - accuracy: 0.7190 - val_loss: 0.7116 - val_accuracy: 0.7452\n","Epoch 27/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7705 - accuracy: 0.7070 - val_loss: 0.7072 - val_accuracy: 0.7384\n","Epoch 28/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7604 - accuracy: 0.7280 - val_loss: 0.7085 - val_accuracy: 0.7394\n","Epoch 29/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7524 - accuracy: 0.7150 - val_loss: 0.7032 - val_accuracy: 0.7488\n","Epoch 30/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7391 - accuracy: 0.7390 - val_loss: 0.6882 - val_accuracy: 0.7438\n","Epoch 31/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7633 - accuracy: 0.7270 - val_loss: 0.6820 - val_accuracy: 0.7480\n","Epoch 32/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7382 - accuracy: 0.7420 - val_loss: 0.6812 - val_accuracy: 0.7532\n","Epoch 1/32\n","32/32 [==============================] - 1s 12ms/step - loss: 2.2393 - accuracy: 0.1820 - val_loss: 1.9279 - val_accuracy: 0.4618\n","Epoch 2/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.9184 - accuracy: 0.3640 - val_loss: 1.6618 - val_accuracy: 0.5508\n","Epoch 3/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.6758 - accuracy: 0.4460 - val_loss: 1.4334 - val_accuracy: 0.6118\n","Epoch 4/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.5133 - accuracy: 0.5260 - val_loss: 1.2725 - val_accuracy: 0.6376\n","Epoch 5/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.3743 - accuracy: 0.5660 - val_loss: 1.1563 - val_accuracy: 0.6472\n","Epoch 6/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.2860 - accuracy: 0.5770 - val_loss: 1.0666 - val_accuracy: 0.6618\n","Epoch 7/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2235 - accuracy: 0.5810 - val_loss: 1.0113 - val_accuracy: 0.6648\n","Epoch 8/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.1609 - accuracy: 0.5940 - val_loss: 0.9800 - val_accuracy: 0.6610\n","Epoch 9/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1222 - accuracy: 0.6080 - val_loss: 0.9608 - val_accuracy: 0.6432\n","Epoch 10/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.0796 - accuracy: 0.6270 - val_loss: 0.9061 - val_accuracy: 0.6776\n","Epoch 11/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0158 - accuracy: 0.6440 - val_loss: 0.8775 - val_accuracy: 0.6846\n","Epoch 12/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9871 - accuracy: 0.6600 - val_loss: 0.8713 - val_accuracy: 0.6654\n","Epoch 13/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9753 - accuracy: 0.6690 - val_loss: 0.8446 - val_accuracy: 0.6944\n","Epoch 14/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.9410 - accuracy: 0.6770 - val_loss: 0.8254 - val_accuracy: 0.6916\n","Epoch 15/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9507 - accuracy: 0.6560 - val_loss: 0.8093 - val_accuracy: 0.6964\n","Epoch 16/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9378 - accuracy: 0.6770 - val_loss: 0.7995 - val_accuracy: 0.6964\n","Epoch 17/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9032 - accuracy: 0.6840 - val_loss: 0.7757 - val_accuracy: 0.7198\n","Epoch 18/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8887 - accuracy: 0.6930 - val_loss: 0.7730 - val_accuracy: 0.7096\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8543 - accuracy: 0.6930 - val_loss: 0.7577 - val_accuracy: 0.7228\n","Epoch 20/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8397 - accuracy: 0.7040 - val_loss: 0.7454 - val_accuracy: 0.7256\n","Epoch 21/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8446 - accuracy: 0.7030 - val_loss: 0.7613 - val_accuracy: 0.7034\n","Epoch 22/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8225 - accuracy: 0.7220 - val_loss: 0.7368 - val_accuracy: 0.7284\n","Epoch 23/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7957 - accuracy: 0.7090 - val_loss: 0.7167 - val_accuracy: 0.7394\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8009 - accuracy: 0.7070 - val_loss: 0.7500 - val_accuracy: 0.7212\n","Epoch 25/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8063 - accuracy: 0.7260 - val_loss: 0.7167 - val_accuracy: 0.7352\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7650 - accuracy: 0.7290 - val_loss: 0.7040 - val_accuracy: 0.7538\n","Epoch 27/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7935 - accuracy: 0.7180 - val_loss: 0.6954 - val_accuracy: 0.7504\n","Epoch 28/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7548 - accuracy: 0.7490 - val_loss: 0.6929 - val_accuracy: 0.7498\n","Epoch 29/32\n","32/32 [==============================] - 0s 10ms/step - loss: 0.7656 - accuracy: 0.7210 - val_loss: 0.6877 - val_accuracy: 0.7508\n","Epoch 30/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7480 - accuracy: 0.7210 - val_loss: 0.6759 - val_accuracy: 0.7600\n","Epoch 31/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.7223 - accuracy: 0.7510 - val_loss: 0.6912 - val_accuracy: 0.7504\n","Epoch 32/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7230 - accuracy: 0.7420 - val_loss: 0.6747 - val_accuracy: 0.7550\n","Epoch 1/32\n","32/32 [==============================] - 1s 17ms/step - loss: 2.1851 - accuracy: 0.2110 - val_loss: 1.9443 - val_accuracy: 0.4418\n","Epoch 2/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.8995 - accuracy: 0.3780 - val_loss: 1.6833 - val_accuracy: 0.5078\n","Epoch 3/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.6641 - accuracy: 0.4750 - val_loss: 1.4738 - val_accuracy: 0.5784\n","Epoch 4/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.5223 - accuracy: 0.5150 - val_loss: 1.3223 - val_accuracy: 0.5716\n","Epoch 5/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.3864 - accuracy: 0.5340 - val_loss: 1.2044 - val_accuracy: 0.6072\n","Epoch 6/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.2851 - accuracy: 0.5640 - val_loss: 1.1304 - val_accuracy: 0.6296\n","Epoch 7/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2161 - accuracy: 0.5800 - val_loss: 1.0618 - val_accuracy: 0.6450\n","Epoch 8/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.1725 - accuracy: 0.5820 - val_loss: 1.0324 - val_accuracy: 0.6184\n","Epoch 9/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0898 - accuracy: 0.6090 - val_loss: 0.9558 - val_accuracy: 0.6710\n","Epoch 10/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0508 - accuracy: 0.6300 - val_loss: 0.9276 - val_accuracy: 0.6710\n","Epoch 11/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0039 - accuracy: 0.6530 - val_loss: 0.9094 - val_accuracy: 0.6864\n","Epoch 12/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9987 - accuracy: 0.6620 - val_loss: 0.8947 - val_accuracy: 0.6728\n","Epoch 13/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.9472 - accuracy: 0.6750 - val_loss: 0.8619 - val_accuracy: 0.7014\n","Epoch 14/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9422 - accuracy: 0.6680 - val_loss: 0.8480 - val_accuracy: 0.7046\n","Epoch 15/32\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8911 - accuracy: 0.7000 - val_loss: 0.8170 - val_accuracy: 0.7090\n","Epoch 16/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9031 - accuracy: 0.6940 - val_loss: 0.8087 - val_accuracy: 0.6976\n","Epoch 17/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.8908 - accuracy: 0.6790 - val_loss: 0.7941 - val_accuracy: 0.7190\n","Epoch 18/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8571 - accuracy: 0.7000 - val_loss: 0.7865 - val_accuracy: 0.7188\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8316 - accuracy: 0.7100 - val_loss: 0.7756 - val_accuracy: 0.7204\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8180 - accuracy: 0.6980 - val_loss: 0.7914 - val_accuracy: 0.7024\n","Epoch 21/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8129 - accuracy: 0.7220 - val_loss: 0.7509 - val_accuracy: 0.7336\n","Epoch 22/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7997 - accuracy: 0.7290 - val_loss: 0.7538 - val_accuracy: 0.7164\n","Epoch 23/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7954 - accuracy: 0.7170 - val_loss: 0.7309 - val_accuracy: 0.7408\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7582 - accuracy: 0.7300 - val_loss: 0.7355 - val_accuracy: 0.7302\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7659 - accuracy: 0.7480 - val_loss: 0.7264 - val_accuracy: 0.7304\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7548 - accuracy: 0.7310 - val_loss: 0.7244 - val_accuracy: 0.7302\n","Epoch 27/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7341 - accuracy: 0.7590 - val_loss: 0.7057 - val_accuracy: 0.7496\n","Epoch 28/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7357 - accuracy: 0.7490 - val_loss: 0.7107 - val_accuracy: 0.7404\n","Epoch 29/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7238 - accuracy: 0.7430 - val_loss: 0.7007 - val_accuracy: 0.7454\n","Epoch 30/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7204 - accuracy: 0.7370 - val_loss: 0.6874 - val_accuracy: 0.7556\n","Epoch 31/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7064 - accuracy: 0.7550 - val_loss: 0.6951 - val_accuracy: 0.7444\n","Epoch 32/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7094 - accuracy: 0.7490 - val_loss: 0.6875 - val_accuracy: 0.7470\n","Epoch 1/32\n","32/32 [==============================] - 1s 12ms/step - loss: 2.1666 - accuracy: 0.1910 - val_loss: 1.9237 - val_accuracy: 0.4338\n","Epoch 2/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.8599 - accuracy: 0.3800 - val_loss: 1.6228 - val_accuracy: 0.5672\n","Epoch 3/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.6473 - accuracy: 0.4540 - val_loss: 1.3950 - val_accuracy: 0.5720\n","Epoch 4/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.4497 - accuracy: 0.5330 - val_loss: 1.2260 - val_accuracy: 0.6246\n","Epoch 5/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.2854 - accuracy: 0.5840 - val_loss: 1.1461 - val_accuracy: 0.5976\n","Epoch 6/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.2341 - accuracy: 0.5810 - val_loss: 1.0597 - val_accuracy: 0.6402\n","Epoch 7/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1315 - accuracy: 0.6230 - val_loss: 0.9781 - val_accuracy: 0.6660\n","Epoch 8/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.0777 - accuracy: 0.6290 - val_loss: 0.9661 - val_accuracy: 0.6420\n","Epoch 9/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0286 - accuracy: 0.6240 - val_loss: 0.9189 - val_accuracy: 0.6696\n","Epoch 10/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9982 - accuracy: 0.6520 - val_loss: 0.8705 - val_accuracy: 0.6934\n","Epoch 11/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.6580 - val_loss: 0.8554 - val_accuracy: 0.6938\n","Epoch 12/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9549 - accuracy: 0.6570 - val_loss: 0.8460 - val_accuracy: 0.6982\n","Epoch 13/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9427 - accuracy: 0.6700 - val_loss: 0.8250 - val_accuracy: 0.6986\n","Epoch 14/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.8708 - accuracy: 0.6840 - val_loss: 0.8170 - val_accuracy: 0.7004\n","Epoch 15/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8753 - accuracy: 0.7020 - val_loss: 0.7933 - val_accuracy: 0.7178\n","Epoch 16/32\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8799 - accuracy: 0.6930 - val_loss: 0.7962 - val_accuracy: 0.7138\n","Epoch 17/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.8829 - accuracy: 0.6830 - val_loss: 0.7991 - val_accuracy: 0.7138\n","Epoch 18/32\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8023 - accuracy: 0.7170 - val_loss: 0.7600 - val_accuracy: 0.7346\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8381 - accuracy: 0.6950 - val_loss: 0.7537 - val_accuracy: 0.7336\n","Epoch 20/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.7789 - accuracy: 0.7160 - val_loss: 0.7443 - val_accuracy: 0.7368\n","Epoch 21/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7795 - accuracy: 0.7300 - val_loss: 0.7688 - val_accuracy: 0.7226\n","Epoch 22/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7969 - accuracy: 0.7180 - val_loss: 0.7547 - val_accuracy: 0.7282\n","Epoch 23/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7982 - accuracy: 0.7030 - val_loss: 0.7212 - val_accuracy: 0.7408\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7795 - accuracy: 0.7170 - val_loss: 0.7357 - val_accuracy: 0.7434\n","Epoch 25/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7528 - accuracy: 0.7580 - val_loss: 0.7150 - val_accuracy: 0.7488\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7539 - accuracy: 0.7430 - val_loss: 0.7212 - val_accuracy: 0.7464\n","Epoch 27/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7294 - accuracy: 0.7430 - val_loss: 0.7353 - val_accuracy: 0.7356\n","Epoch 28/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.7197 - accuracy: 0.7420 - val_loss: 0.7217 - val_accuracy: 0.7292\n","Epoch 29/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7030 - accuracy: 0.7520 - val_loss: 0.7213 - val_accuracy: 0.7428\n","Epoch 30/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.7088 - accuracy: 0.7470 - val_loss: 0.6877 - val_accuracy: 0.7588\n","Epoch 31/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.7126 - accuracy: 0.7440 - val_loss: 0.6761 - val_accuracy: 0.7616\n","Epoch 32/32\n","32/32 [==============================] - 0s 15ms/step - loss: 0.6970 - accuracy: 0.7480 - val_loss: 0.6807 - val_accuracy: 0.7584\n","Epoch 1/32\n","32/32 [==============================] - 1s 20ms/step - loss: 2.2571 - accuracy: 0.1960 - val_loss: 1.9694 - val_accuracy: 0.3766\n","Epoch 2/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.9298 - accuracy: 0.3260 - val_loss: 1.6964 - val_accuracy: 0.4948\n","Epoch 3/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.6759 - accuracy: 0.4430 - val_loss: 1.4724 - val_accuracy: 0.5688\n","Epoch 4/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.5032 - accuracy: 0.5070 - val_loss: 1.3036 - val_accuracy: 0.6166\n","Epoch 5/32\n","32/32 [==============================] - 1s 16ms/step - loss: 1.3716 - accuracy: 0.5480 - val_loss: 1.1898 - val_accuracy: 0.6388\n","Epoch 6/32\n","32/32 [==============================] - 0s 15ms/step - loss: 1.2432 - accuracy: 0.5910 - val_loss: 1.0946 - val_accuracy: 0.6516\n","Epoch 7/32\n","32/32 [==============================] - 0s 15ms/step - loss: 1.1839 - accuracy: 0.6010 - val_loss: 1.0309 - val_accuracy: 0.6460\n","Epoch 8/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.1005 - accuracy: 0.6410 - val_loss: 0.9642 - val_accuracy: 0.6634\n","Epoch 9/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0619 - accuracy: 0.6350 - val_loss: 0.9601 - val_accuracy: 0.6466\n","Epoch 10/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.0305 - accuracy: 0.6370 - val_loss: 0.9238 - val_accuracy: 0.6606\n","Epoch 11/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9643 - accuracy: 0.6400 - val_loss: 0.8895 - val_accuracy: 0.6740\n","Epoch 12/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9608 - accuracy: 0.6620 - val_loss: 0.8612 - val_accuracy: 0.6894\n","Epoch 13/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9166 - accuracy: 0.6870 - val_loss: 0.8388 - val_accuracy: 0.6922\n","Epoch 14/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8811 - accuracy: 0.6740 - val_loss: 0.8471 - val_accuracy: 0.6852\n","Epoch 15/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8871 - accuracy: 0.6970 - val_loss: 0.8164 - val_accuracy: 0.7010\n","Epoch 16/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8713 - accuracy: 0.6920 - val_loss: 0.8161 - val_accuracy: 0.7078\n","Epoch 17/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8310 - accuracy: 0.7090 - val_loss: 0.7820 - val_accuracy: 0.7106\n","Epoch 18/32\n","32/32 [==============================] - 0s 10ms/step - loss: 0.8120 - accuracy: 0.7080 - val_loss: 0.7801 - val_accuracy: 0.7164\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8406 - accuracy: 0.7080 - val_loss: 0.7638 - val_accuracy: 0.7176\n","Epoch 20/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7830 - accuracy: 0.7330 - val_loss: 0.7536 - val_accuracy: 0.7224\n","Epoch 21/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7631 - accuracy: 0.7230 - val_loss: 0.7463 - val_accuracy: 0.7236\n","Epoch 22/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7559 - accuracy: 0.7320 - val_loss: 0.7325 - val_accuracy: 0.7302\n","Epoch 23/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7480 - accuracy: 0.7380 - val_loss: 0.7357 - val_accuracy: 0.7230\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7465 - accuracy: 0.7320 - val_loss: 0.7215 - val_accuracy: 0.7298\n","Epoch 25/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7345 - accuracy: 0.7390 - val_loss: 0.7152 - val_accuracy: 0.7324\n","Epoch 26/32\n","32/32 [==============================] - 0s 14ms/step - loss: 0.7033 - accuracy: 0.7550 - val_loss: 0.7324 - val_accuracy: 0.7278\n","Epoch 27/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7300 - accuracy: 0.7420 - val_loss: 0.7027 - val_accuracy: 0.7414\n","Epoch 28/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.6962 - accuracy: 0.7520 - val_loss: 0.7174 - val_accuracy: 0.7322\n","Epoch 29/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.7400 - val_loss: 0.7049 - val_accuracy: 0.7344\n","Epoch 30/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7300 - accuracy: 0.7330 - val_loss: 0.6984 - val_accuracy: 0.7420\n","Epoch 31/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.6687 - accuracy: 0.7450 - val_loss: 0.6990 - val_accuracy: 0.7340\n","Epoch 32/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.6704 - accuracy: 0.7600 - val_loss: 0.6969 - val_accuracy: 0.7378\n","Epoch 1/32\n","32/32 [==============================] - 1s 11ms/step - loss: 2.1936 - accuracy: 0.1990 - val_loss: 1.9403 - val_accuracy: 0.4602\n","Epoch 2/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.9317 - accuracy: 0.3520 - val_loss: 1.6605 - val_accuracy: 0.5222\n","Epoch 3/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.6818 - accuracy: 0.4320 - val_loss: 1.4345 - val_accuracy: 0.5604\n","Epoch 4/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.4915 - accuracy: 0.5060 - val_loss: 1.2665 - val_accuracy: 0.6112\n","Epoch 5/32\n","32/32 [==============================] - 0s 9ms/step - loss: 1.3817 - accuracy: 0.5210 - val_loss: 1.1536 - val_accuracy: 0.6424\n","Epoch 6/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.2891 - accuracy: 0.5450 - val_loss: 1.0958 - val_accuracy: 0.6096\n","Epoch 7/32\n","32/32 [==============================] - 0s 14ms/step - loss: 1.2065 - accuracy: 0.5990 - val_loss: 1.0131 - val_accuracy: 0.6550\n","Epoch 8/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.1378 - accuracy: 0.6090 - val_loss: 0.9890 - val_accuracy: 0.6432\n","Epoch 9/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0831 - accuracy: 0.6280 - val_loss: 0.9361 - val_accuracy: 0.6648\n","Epoch 10/32\n","32/32 [==============================] - 0s 13ms/step - loss: 1.0625 - accuracy: 0.6160 - val_loss: 0.8950 - val_accuracy: 0.6890\n","Epoch 11/32\n","32/32 [==============================] - 0s 8ms/step - loss: 1.0401 - accuracy: 0.6190 - val_loss: 0.8832 - val_accuracy: 0.6766\n","Epoch 12/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9879 - accuracy: 0.6380 - val_loss: 0.8562 - val_accuracy: 0.6876\n","Epoch 13/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9654 - accuracy: 0.6480 - val_loss: 0.8408 - val_accuracy: 0.6938\n","Epoch 14/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9906 - accuracy: 0.6400 - val_loss: 0.8515 - val_accuracy: 0.6936\n","Epoch 15/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.9309 - accuracy: 0.6670 - val_loss: 0.8072 - val_accuracy: 0.7120\n","Epoch 16/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.9210 - accuracy: 0.6540 - val_loss: 0.7862 - val_accuracy: 0.7190\n","Epoch 17/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.9022 - accuracy: 0.6720 - val_loss: 0.7912 - val_accuracy: 0.7178\n","Epoch 18/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8899 - accuracy: 0.6840 - val_loss: 0.8046 - val_accuracy: 0.6936\n","Epoch 19/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8560 - accuracy: 0.6980 - val_loss: 0.7633 - val_accuracy: 0.7200\n","Epoch 20/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8400 - accuracy: 0.7030 - val_loss: 0.7598 - val_accuracy: 0.7224\n","Epoch 21/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.8328 - accuracy: 0.6900 - val_loss: 0.7442 - val_accuracy: 0.7326\n","Epoch 22/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8414 - accuracy: 0.6960 - val_loss: 0.7382 - val_accuracy: 0.7356\n","Epoch 23/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.8310 - accuracy: 0.7060 - val_loss: 0.7284 - val_accuracy: 0.7426\n","Epoch 24/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7852 - accuracy: 0.7020 - val_loss: 0.7286 - val_accuracy: 0.7480\n","Epoch 25/32\n","32/32 [==============================] - 0s 8ms/step - loss: 0.7850 - accuracy: 0.7070 - val_loss: 0.7271 - val_accuracy: 0.7288\n","Epoch 26/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7735 - accuracy: 0.7210 - val_loss: 0.7138 - val_accuracy: 0.7452\n","Epoch 27/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7919 - accuracy: 0.7100 - val_loss: 0.7022 - val_accuracy: 0.7492\n","Epoch 28/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7652 - accuracy: 0.7260 - val_loss: 0.7145 - val_accuracy: 0.7360\n","Epoch 29/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7526 - accuracy: 0.7260 - val_loss: 0.7102 - val_accuracy: 0.7368\n","Epoch 30/32\n","32/32 [==============================] - 0s 9ms/step - loss: 0.7271 - accuracy: 0.7440 - val_loss: 0.7197 - val_accuracy: 0.7258\n","Epoch 31/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.7438 - accuracy: 0.7340 - val_loss: 0.7277 - val_accuracy: 0.7242\n","Epoch 32/32\n","32/32 [==============================] - 0s 13ms/step - loss: 0.6969 - accuracy: 0.7560 - val_loss: 0.6893 - val_accuracy: 0.7506\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n","  warnings.warn('`model.predict_proba()` is deprecated and '\n"]}],"source":["# Train the shadow models.\n","smb = ShadowModelBundle(\n","    target_model_fn,\n","    shadow_dataset_size=SHADOW_DATASET_SIZE,\n","    num_models=num_shadows\n",")\n","\n","# Using cifar10 test set to train shadow models\n","attacker_X_train, attacker_X_test, attacker_y_train, attacker_y_test = train_test_split(\n","    cifar_test[0], cifar_test[1], test_size=0.5)\n","\n","print(attacker_X_train.shape, attacker_X_test.shape)\n","\n","print(\"Training the shadow models...\")\n","X_shadow, y_shadow = smb.fit_transform(\n","    attacker_X_train,\n","    attacker_y_train,\n","    fit_kwargs=dict(\n","        epochs=32,\n","        verbose=True,\n","        validation_data=(attacker_X_test, attacker_y_test)\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41436,"status":"ok","timestamp":1665840101597,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"jHaU_HBZyd_0","outputId":"9052cb62-1d09-4a15-ab22-d69c7fe8f40e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the attack models...\n","Epoch 1/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5026\n","Epoch 2/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5194\n","Epoch 3/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4993\n","Epoch 4/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4945\n","Epoch 5/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5088\n","Epoch 6/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5093\n","Epoch 7/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5160\n","Epoch 8/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5088\n","Epoch 9/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5189\n","Epoch 10/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5323\n","Epoch 11/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5218\n","Epoch 12/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5323\n","Epoch 13/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5328\n","Epoch 14/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5371\n","Epoch 15/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5285\n","Epoch 16/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5409\n","Epoch 17/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5428\n","Epoch 18/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5251\n","Epoch 19/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5361\n","Epoch 20/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5371\n","Epoch 21/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5294\n","Epoch 22/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5399\n","Epoch 23/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5323\n","Epoch 24/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5371\n","Epoch 25/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5318\n","Epoch 26/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5375\n","Epoch 27/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5356\n","Epoch 28/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5395\n","Epoch 29/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5375\n","Epoch 30/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5366\n","Epoch 31/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5442\n","Epoch 32/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5418\n","Epoch 1/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4995\n","Epoch 2/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5143\n","Epoch 3/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5084\n","Epoch 4/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5182\n","Epoch 5/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5138\n","Epoch 6/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5241\n","Epoch 7/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5157\n","Epoch 8/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5133\n","Epoch 9/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5211\n","Epoch 10/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5261\n","Epoch 11/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5074\n","Epoch 12/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5152\n","Epoch 13/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5123\n","Epoch 14/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5300\n","Epoch 15/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5118\n","Epoch 16/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5133\n","Epoch 17/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5123\n","Epoch 18/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5113\n","Epoch 19/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5197\n","Epoch 20/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5143\n","Epoch 21/32\n","64/64 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.4946\n","Epoch 22/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5039\n","Epoch 23/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5221\n","Epoch 24/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5157\n","Epoch 25/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5192\n","Epoch 26/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5093\n","Epoch 27/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5162\n","Epoch 28/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5256\n","Epoch 29/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5157\n","Epoch 30/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5251\n","Epoch 31/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5221\n","Epoch 32/32\n","64/64 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5187\n","Epoch 1/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5031\n","Epoch 2/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5297\n","Epoch 3/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5312\n","Epoch 4/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5368\n","Epoch 5/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5286\n","Epoch 6/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5383\n","Epoch 7/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5383\n","Epoch 8/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5506\n","Epoch 9/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5378\n","Epoch 10/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5419\n","Epoch 11/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5317\n","Epoch 12/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5470\n","Epoch 13/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5404\n","Epoch 14/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5486\n","Epoch 15/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5440\n","Epoch 16/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5481\n","Epoch 17/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5368\n","Epoch 18/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5358\n","Epoch 19/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5527\n","Epoch 20/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5435\n","Epoch 21/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5583\n","Epoch 22/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5470\n","Epoch 23/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5486\n","Epoch 24/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5440\n","Epoch 25/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5521\n","Epoch 26/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5322\n","Epoch 27/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5470\n","Epoch 28/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5501\n","Epoch 29/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5455\n","Epoch 30/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5557\n","Epoch 31/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5481\n","Epoch 32/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5481\n","Epoch 1/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5216\n","Epoch 2/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5036\n","Epoch 3/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5197\n","Epoch 4/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5287\n","Epoch 5/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5163\n","Epoch 6/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5116\n","Epoch 7/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5163\n","Epoch 8/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5083\n","Epoch 9/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5069\n","Epoch 10/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5178\n","Epoch 11/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5216\n","Epoch 12/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5329\n","Epoch 13/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5287\n","Epoch 14/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5343\n","Epoch 15/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5107\n","Epoch 16/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5178\n","Epoch 17/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5144\n","Epoch 18/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5258\n","Epoch 19/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.4983\n","Epoch 20/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5277\n","Epoch 21/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5149\n","Epoch 22/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5097\n","Epoch 23/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5216\n","Epoch 24/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5130\n","Epoch 25/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5220\n","Epoch 26/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5201\n","Epoch 27/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5244\n","Epoch 28/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5414\n","Epoch 29/32\n","66/66 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5021\n","Epoch 30/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5192\n","Epoch 31/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5225\n","Epoch 32/32\n","66/66 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5381\n","Epoch 1/32\n","62/62 [==============================] - 1s 1ms/step - loss: 0.6927 - accuracy: 0.5159\n","Epoch 2/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5220\n","Epoch 3/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5271\n","Epoch 4/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5443\n","Epoch 5/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5468\n","Epoch 6/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5387\n","Epoch 7/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5524\n","Epoch 8/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5508\n","Epoch 9/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5554\n","Epoch 10/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5326\n","Epoch 11/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5438\n","Epoch 12/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5417\n","Epoch 13/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5448\n","Epoch 14/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5438\n","Epoch 15/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5362\n","Epoch 16/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5498\n","Epoch 17/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5382\n","Epoch 18/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5559\n","Epoch 19/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5463\n","Epoch 20/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5432\n","Epoch 21/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5539\n","Epoch 22/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5513\n","Epoch 23/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5443\n","Epoch 24/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5559\n","Epoch 25/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5518\n","Epoch 26/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5524\n","Epoch 27/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5493\n","Epoch 28/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.5478\n","Epoch 29/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5518\n","Epoch 30/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5529\n","Epoch 31/32\n","62/62 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.5377\n","Epoch 32/32\n","62/62 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5402\n","Epoch 1/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5211\n","Epoch 2/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5460\n","Epoch 3/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5564\n","Epoch 4/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5471\n","Epoch 5/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5590\n","Epoch 6/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5663\n","Epoch 7/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5523\n","Epoch 8/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5569\n","Epoch 9/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5523\n","Epoch 10/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5673\n","Epoch 11/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5642\n","Epoch 12/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5601\n","Epoch 13/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5653\n","Epoch 14/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5595\n","Epoch 15/32\n","61/61 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5606\n","Epoch 16/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5679\n","Epoch 17/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5647\n","Epoch 18/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5533\n","Epoch 19/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5647\n","Epoch 20/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5637\n","Epoch 21/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5647\n","Epoch 22/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5611\n","Epoch 23/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5689\n","Epoch 24/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5668\n","Epoch 25/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5694\n","Epoch 26/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5621\n","Epoch 27/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5653\n","Epoch 28/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5564\n","Epoch 29/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5658\n","Epoch 30/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5653\n","Epoch 31/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5590\n","Epoch 32/32\n","61/61 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5642\n","Epoch 1/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5173\n","Epoch 2/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5088\n","Epoch 3/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5103\n","Epoch 4/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5389\n","Epoch 5/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5389\n","Epoch 6/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5424\n","Epoch 7/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5349\n","Epoch 8/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5575\n","Epoch 9/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5419\n","Epoch 10/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5439\n","Epoch 11/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5389\n","Epoch 12/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5500\n","Epoch 13/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5450\n","Epoch 14/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5505\n","Epoch 15/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5439\n","Epoch 16/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5565\n","Epoch 17/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5450\n","Epoch 18/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5439\n","Epoch 19/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5399\n","Epoch 20/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6857 - accuracy: 0.5485\n","Epoch 21/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5520\n","Epoch 22/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.5565\n","Epoch 23/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5615\n","Epoch 24/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.5475\n","Epoch 25/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5485\n","Epoch 26/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5540\n","Epoch 27/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5480\n","Epoch 28/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5655\n","Epoch 29/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5595\n","Epoch 30/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5660\n","Epoch 31/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.5540\n","Epoch 32/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5595\n","Epoch 1/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5169\n","Epoch 2/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5110\n","Epoch 3/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5217\n","Epoch 4/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5228\n","Epoch 5/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5089\n","Epoch 6/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5255\n","Epoch 7/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5201\n","Epoch 8/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5239\n","Epoch 9/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5255\n","Epoch 10/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5266\n","Epoch 11/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5282\n","Epoch 12/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5260\n","Epoch 13/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5303\n","Epoch 14/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5250\n","Epoch 15/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5201\n","Epoch 16/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5266\n","Epoch 17/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5255\n","Epoch 18/32\n","59/59 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5276\n","Epoch 19/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5314\n","Epoch 20/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5228\n","Epoch 21/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5244\n","Epoch 22/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5212\n","Epoch 23/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5228\n","Epoch 24/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5266\n","Epoch 25/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5212\n","Epoch 26/32\n","59/59 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5196\n","Epoch 27/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5287\n","Epoch 28/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5255\n","Epoch 29/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5293\n","Epoch 30/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5266\n","Epoch 31/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5287\n","Epoch 32/32\n","59/59 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5314\n","Epoch 1/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.4945\n","Epoch 2/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.4990\n","Epoch 3/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5220\n","Epoch 4/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5110\n","Epoch 5/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.4850\n","Epoch 6/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5060\n","Epoch 7/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5165\n","Epoch 8/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4920\n","Epoch 9/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5125\n","Epoch 10/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5271\n","Epoch 11/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5095\n","Epoch 12/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4960\n","Epoch 13/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5140\n","Epoch 14/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5050\n","Epoch 15/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5070\n","Epoch 16/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5200\n","Epoch 17/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5140\n","Epoch 18/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5100\n","Epoch 19/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.4950\n","Epoch 20/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5005\n","Epoch 21/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5015\n","Epoch 22/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5105\n","Epoch 23/32\n","63/63 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5155\n","Epoch 24/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5105\n","Epoch 25/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5000\n","Epoch 26/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4965\n","Epoch 27/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5005\n","Epoch 28/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5165\n","Epoch 29/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5150\n","Epoch 30/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5215\n","Epoch 31/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5020\n","Epoch 32/32\n","63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5120\n","Epoch 1/32\n","65/65 [==============================] - 1s 1ms/step - loss: 0.6944 - accuracy: 0.5078\n","Epoch 2/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5224\n","Epoch 3/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5107\n","Epoch 4/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4985\n","Epoch 5/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5063\n","Epoch 6/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5180\n","Epoch 7/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5180\n","Epoch 8/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5010\n","Epoch 9/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5175\n","Epoch 10/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5219\n","Epoch 11/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5243\n","Epoch 12/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5219\n","Epoch 13/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5175\n","Epoch 14/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5219\n","Epoch 15/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5126\n","Epoch 16/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5175\n","Epoch 17/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5287\n","Epoch 18/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5253\n","Epoch 19/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5214\n","Epoch 20/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5214\n","Epoch 21/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5228\n","Epoch 22/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5228\n","Epoch 23/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5243\n","Epoch 24/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5204\n","Epoch 25/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5292\n","Epoch 26/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5155\n","Epoch 27/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5146\n","Epoch 28/32\n","65/65 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5185\n","Epoch 29/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5190\n","Epoch 30/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5228\n","Epoch 31/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5209\n","Epoch 32/32\n","65/65 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5029\n"]}],"source":["# ShadowModelBundle returns data in the format suitable for the AttackModelBundle.\n","amb = AttackModelBundle(attack_model_fn, num_classes=NUM_CLASSES)\n","\n","# Fit the attack models.\n","print(\"Training the attack models...\")\n","amb.fit(X_shadow, y_shadow, fit_kwargs=dict(epochs=32, verbose=True)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bndyZoniH20y"},"outputs":[],"source":["target_data = cifar_train_fed_data[0]\n","attacker_data = cifar_test_fed_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBS5eK7yzQW7"},"outputs":[],"source":["#attack_test_data, real_membership_labels = prepare_attack_data(federated_model, cifar_train_data, attacker_data)\n","attack_test_data, real_membership_labels = prepare_attack_data(target_model, target_data, attacker_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Gd-jDh_rynH"},"outputs":[],"source":["def results(attack_guesses,real_membership_labels):\n","    pred_labels=attack_guesses\n","    true_labels=real_membership_labels\n","\n","    # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n","    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n","\n","    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n","    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))\n","\n","    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n","    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n","\n","    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n","    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))\n","\n","    print ('TP: %i, FP: %i, TN: %i, FN: %i' % (TP,FP,TN,FN))\n","\n","    print(\"acc = \" + str((TP+TN)/(TP+TN+FP+FN)))\n","    print(\"precision = \" + str((TP)/(TP+FP)))\n","    print(\"recall = \" + str((TP)/(TP+FN)))\n","    \n","    acc= (TP+TN)/(TP+TN+FP+FN)\n","    prec=(TP)/(TP+FP)\n","    rec=(TP)/(TP+FN)\n","    return [acc,prec,rec]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1142,"status":"ok","timestamp":1665840113814,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"PJ0MOngQzRE8","outputId":"2bb2704d-d25c-4f90-c547-96c209bb26f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5027932960893855\n","1.0\n","0.4074074074074074\n","0.48148148148148145\n","0.4594594594594595\n","0.6666666666666666\n","0.5344827586206896\n","0.5502392344497608\n","0.45454545454545453\n","0.5059523809523809\n","Average Accuracy:  0.5055\n","TP: 451, FP: 440, TN: 560, FN: 549\n","acc = 0.5055\n","precision = 0.5061728395061729\n","recall = 0.451\n"]}],"source":["attack_guesses = amb.predict(attack_test_data)\n","attack_precision = np.mean((attack_guesses == 1) == (real_membership_labels == 1))\n","\n","class_precision = []\n","\n","for c in range(NUM_CLASSES):\n","    #attack_test_data, real_membership_labels = prepare_attack_data(centralized_model, cifar_train_data, attacker_data)\n","    target_indices = [i for i, d in enumerate(target_data[1].argmax(axis=1)) if d == c]\n","    test_indices = [i for i, d in enumerate(attacker_data[1].argmax(axis=1)) if d == c]\n","\n","\n","    print(np.sum(attack_guesses[target_indices]==1) / (np.sum(attack_guesses[target_indices]) + np.sum(attack_guesses[SIZE:][test_indices])))\n","    \n","    class_precision.append(\n","            np.sum(attack_guesses[target_indices]==1) / (np.sum(attack_guesses[target_indices])\n","                                                     + np.sum(attack_guesses[SIZE:][test_indices])))\n","print(\"Average Accuracy: \", attack_precision)\n","\n","result=results(attack_guesses,real_membership_labels)\n"," \n","    #attack_accuracy_class[c].append(result)"]},{"cell_type":"markdown","metadata":{"id":"c4cMdr4gEOJC"},"source":["**MIA via Prediction Sensitivity**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ujiv0TziESPQ"},"outputs":[],"source":["import pickle\n","import argparse\n","\n","import numpy as np\n","import torch\n","from numpy import linalg as LA\n","from sklearn.metrics import precision_score, recall_score\n","from sklearn.cluster import SpectralClustering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1666195376044,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"anKyVFt4H8LP","outputId":"16016597-9afa-4527-c3d8-27648431941f"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fafa93b85d0>"]},"execution_count":149,"metadata":{},"output_type":"execute_result"}],"source":["np.random.seed(seed=14)\n","torch.manual_seed(14)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uR6nQL2dH_DH"},"outputs":[],"source":["target_model = federated_model\n","#target_model = single_model0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ao_HeM-IO-c"},"outputs":[],"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--n_sample', type=int, default=5000)\n","parser.add_argument('--n_attack', type=int, default=50)\n","parser.add_argument('--seed', type=int, default=140)\n","parser.add_argument('--neighbors', type=int, default=40)\n","parser.add_argument('--data_generate', type=bool, default=False)\n","attack_args = parser.parse_args(args=[])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A73f1_7gJcfT"},"outputs":[],"source":["precisions = []\n","recalls = []\n","f1_scores = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1666195381595,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"TNUiUWYZJfCX","outputId":"fedb5496-4984-47f8-fdfc-3a891bc45679"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fafa93b85d0>"]},"execution_count":153,"metadata":{},"output_type":"execute_result"}],"source":["np.random.seed(seed=attack_args.seed)\n","torch.manual_seed(attack_args.seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwX1ZwpJLqi7"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from collections import Counter\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23204,"status":"ok","timestamp":1666188174604,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"ty6LlBBURROc","outputId":"d2a565a2-605e-4f8d-e614-079bf4319286"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/Proposal work\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/Proposal work'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WU1H99mQJjIC"},"outputs":[],"source":["def data_reader(data_name = \"mnist\"):\n","    file_path = \"data/\"\n","    #data = pd.read_csv(file_path + 'mnist_train.csv', header=1)\n","    #data = pd.read_csv(file_path + 'fashion-mnist_train.csv', header=1)\n","    data = pd.read_csv(file_path + 'fashion-mnist_train.csv', header=1, skiprows=30000, nrows=29999)\n","    #data = pd.read_csv(file_path + 'fashion-mnist_test.csv', header=0)\n","    data = np.array(data)\n","    labels = data[:,0]\n","    data = data[:,1:]\n","        \n","    categorical_features = []\n","    \n","    data = data/data.max()\n","    oh_encoder = ColumnTransformer(\n","    [('oh_enc', OneHotEncoder(sparse=False), categorical_features),], \n","    remainder='passthrough' )\n","    oh_data = oh_encoder.fit_transform(data)\n","        \n","    #randomly select 10000 records as training data\n","    train_idx = np.random.choice(len(labels), 9999, replace = False)\n","    idx = range(len(labels))\n","    idx = np.array(idx)\n","    test_idx = list(set(idx).difference(set(train_idx)))\n","    test_idx = np.array(test_idx)\n","    \n","    assert test_idx.sum() + train_idx.sum() == idx.sum()\n","    \n","    X_train = data[train_idx,:]\n","    Y_train = labels[train_idx]\n","    \n","    X_test = data[test_idx,:]\n","    Y_test = labels[test_idx]\n","    \n","    orig_dataset = {\"X_train\":X_train,\n","               \"Y_train\":Y_train,\n","               \"X_test\":X_test,\n","               \"Y_test\":Y_test}\n","    \n","    X_train = oh_data[train_idx,:]\n","    \n","    X_test = oh_data[test_idx,:]\n","    \n","    oh_dataset = {\"X_train\":X_train,\n","               \"Y_train\":Y_train,\n","               \"X_test\":X_test,\n","               \"Y_test\":Y_test}\n","\n","    return orig_dataset, oh_dataset, oh_encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUwJJKEeLzy5"},"outputs":[],"source":["orig_dataset, oh_dataset, OH_Encoder = data_reader(\"mnist\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6QNtvok1_LUF"},"outputs":[],"source":["class_label_for_count = np.unique(np.hstack([orig_dataset[\"Y_train\"], orig_dataset[\"Y_test\"]]))\n","n_class = len(class_label_for_count)\n","n_features = orig_dataset['X_train'].shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ioKqcQ3K_fZP"},"outputs":[],"source":["y_attack = np.hstack(([np.ones(int(attack_args.n_attack/2)), np.zeros(int(attack_args.n_attack/2))]))\n","x_attack = np.zeros((int(attack_args.n_attack), n_features))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27B9EGTv_i8M"},"outputs":[],"source":["Jacobian_matrix = np.zeros([attack_args.n_attack, n_class, n_features])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VkIP4RD_pcA"},"outputs":[],"source":["if attack_args.data_generate:\n","    output_x = np.zeros((attack_args.n_attack, n_features))\n","    output_y = y_attack\n","    classes = np.zeros((attack_args.n_attack, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJPuhlKz_961"},"outputs":[],"source":["def fn_R_given_Selected(dataset, IN_or_OUT = 1):\n","    if(IN_or_OUT == 1):#IN_or_OUT == 1 meaning selecting R_given from training set\n","        idx = np.random.choice( len(dataset['Y_train']) )\n","        R_given = dataset['X_train'][idx,:]\n","        R_given_y = dataset['Y_train'][idx]\n","    elif(IN_or_OUT == 0):#IN_or_OUT == 0 meaning selecting R_given from testing set\n","        idx = np.random.choice( len(dataset['Y_test']) )\n","        R_given = dataset['X_test'][idx,:]\n","        R_given_y = dataset['Y_test'][idx]\n","    return R_given, R_given_y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ew93UQtdAqWS"},"outputs":[],"source":["def Target_Model_pred_fn(Target_Model, X_test):\n","    pred_proba = Target_Model.predict_proba(X_test)\n","    return pred_proba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pop4W0YrAPef"},"outputs":[],"source":["categorical_list ={\n","    \"mnist\": [1,2,3,4,5,6,7,8,9,10],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-xTRmmcADLZ"},"outputs":[],"source":["def fn_Sample_Generator(R_given, dataset):\n","    if not dataset in categorical_list.keys():\n","        dataset = \"null\"\n","    epsilon = 1e-6\n","    R_given = R_given.reshape([1, -1])\n","    n_feature = R_given.shape[1]\n","    local_samples = np.repeat(R_given, repeats=n_feature, axis=0)\n","    for i in range(n_feature):\n","        if i in categorical_list[dataset]:\n","            continue\n","        local_samples[i][i] += epsilon\n","\n","    return local_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e-Y9y2gA3r3"},"outputs":[],"source":["def fn_Jacobian_Calculation(R_given, local_proba, n_features, n_class):\n","    epsilon = 1e-6\n","    jacobian = np.zeros([n_class, n_features])\n","\n","    for ii in range(n_class):\n","        jacobian[ii, :] = (local_proba[:, ii] - R_given[ii]) / epsilon\n","    return jacobian"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9144,"status":"ok","timestamp":1666195421003,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"NaYgLSL7_tjW","outputId":"96c88b20-328f-46e1-c86d-d43a9a92c4de"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n","  warnings.warn('`model.predict_proba()` is deprecated and '\n","WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_166_input'), name='flatten_166_input', description=\"created by layer 'flatten_166_input'\"), but it was called on an input with incompatible shape (None, 784).\n"]}],"source":["for ii in range(attack_args.n_attack):\n","      R_x, R_y = fn_R_given_Selected(orig_dataset, IN_or_OUT=y_attack[ii])\n","      R_x_OH = OH_Encoder.transform(R_x.reshape(1, -1))\n","      x_attack[ii] = R_x\n","      local_samples = fn_Sample_Generator(R_x, \"mnist\")\n","      oh_local_samples = OH_Encoder.transform(local_samples)\n","      local_proba = Target_Model_pred_fn(target_model, oh_local_samples)\n","      R_local_proba = Target_Model_pred_fn(target_model, R_x_OH)\n","      Jacobian_matrix[ii] = fn_Jacobian_Calculation(R_local_proba[0], local_proba, n_features, n_class)\n","\n","      if attack_args.data_generate:\n","          output_x[ii] = R_x\n","          classes[ii] = R_y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMNyqVZEBmVr"},"outputs":[],"source":["Jacobian_norms = LA.norm(Jacobian_matrix, axis=(1, 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sF1ghDXZBpkt"},"outputs":[],"source":["split = 1\n","attack_cluster = SpectralClustering(n_clusters=6, n_jobs=-1, affinity='nearest_neighbors', n_neighbors=19)\n","y_attack_pred = attack_cluster.fit_predict(Jacobian_norms.reshape(-1, 1))\n","cluster_1 = np.where(y_attack_pred >= split)[0]\n","cluster_0 = np.where(y_attack_pred < split)[0]\n","y_attack_pred[cluster_1] = 1\n","y_attack_pred[cluster_0] = 0\n","cluster_1_mean_norm = Jacobian_norms[cluster_1].mean()\n","cluster_0_mean_norm = Jacobian_norms[cluster_0].mean()\n","if cluster_1_mean_norm > cluster_0_mean_norm:\n","  y_attack_pred = np.abs(y_attack_pred-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":650,"status":"ok","timestamp":1666195425310,"user":{"displayName":"Saroj Dayal","userId":"17554496406606940001"},"user_tz":240},"id":"8_Uk38OPB9Eb","outputId":"44076c75-5452-4367-802e-7c88e4e93bc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5 0.96 0.6575342465753424\n"]}],"source":["precision = precision_score(y_attack, y_attack_pred)\n","recall = recall_score(y_attack, y_attack_pred)\n","f1_score = 2*precision*recall/(precision+recall)\n","print(precision, recall, f1_score)\n","precisions.append(precision)\n","recalls.append(recall)\n","f1_scores.append(f1_score)"]},{"cell_type":"markdown","source":["## **Membership Inference Attacks From First Principles**"],"metadata":{"id":"w6RGCX7unCub"}},{"cell_type":"code","source":[],"metadata":{"id":"BltPGI1enNAz"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}